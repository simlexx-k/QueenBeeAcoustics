{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aea456e",
   "metadata": {
    "papermill": {
     "duration": 0.007726,
     "end_time": "2025-12-28T18:11:31.567871",
     "exception": false,
     "start_time": "2025-12-28T18:11:31.560145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Kaggle Cloud Ops: Queen Bee Acoustics + Makueni Apiary Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed121e8",
   "metadata": {
    "papermill": {
     "duration": 0.006398,
     "end_time": "2025-12-28T18:11:31.580968",
     "exception": false,
     "start_time": "2025-12-28T18:11:31.574570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This unified notebook stitches together:\n",
    "\n",
    "1. **Queen Bee acoustic detection (CNN + hyperparameter tuning)**\n",
    "2. **Makueni Apiary intelligence workflows (weather, NDVI, telemetry, hive stress ML)**\n",
    "\n",
    "> **Kaggle usage:** Attach the `harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen` dataset plus any `content/main-data` exports as Kaggle data sources. All intermediate files are written under `content/` so the same notebook also works locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655a16d",
   "metadata": {
    "papermill": {
     "duration": 0.006562,
     "end_time": "2025-12-28T18:11:31.594013",
     "exception": false,
     "start_time": "2025-12-28T18:11:31.587451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## BeeUnity System Blueprint\n",
    "\n",
    "BeeUnity couples two complementary sensing/analytics tracks inside a single reproducible notebook.\n",
    "\n",
    "- **Acoustic intelligence (Sections §3-15)** ingests the Kaggle beehive audio corpus, generates mel spectrograms, and trains/ tunes a convolutional network for multi-class queen state detection. The outputs are calibrated probabilities + decision thresholds that can be streamed into downstream alerting or fusion models.\n",
    "- **Makueni apiary intelligence (Sections §17 onwards)** orchestrates weather/NDVI staging, hive log synthesis, and two tiers of ML models (sklearn HistGradientBoosting + PyTorch temporal CNN/GRU) to estimate hive stress / occupancy risk.\n",
    "\n",
    "Every block includes deterministic filesystem staging and writes intermediate products to `/kaggle/working` or `content/` so the research report can quote exact metrics while Kaggle submissions remain GPU safe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff1932a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:11:31.608852Z",
     "iopub.status.busy": "2025-12-28T18:11:31.608620Z",
     "iopub.status.idle": "2025-12-28T18:11:35.984639Z",
     "shell.execute_reply": "2025-12-28T18:11:35.983685Z"
    },
    "papermill": {
     "duration": 4.385115,
     "end_time": "2025-12-28T18:11:35.986480",
     "exception": false,
     "start_time": "2025-12-28T18:11:31.601365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q earthengine-api ipyleaflet ipywidgets keras-tuner librosa tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fca1d5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:11:36.001258Z",
     "iopub.status.busy": "2025-12-28T18:11:36.000787Z",
     "iopub.status.idle": "2025-12-28T18:13:28.991976Z",
     "shell.execute_reply": "2025-12-28T18:13:28.991347Z"
    },
    "papermill": {
     "duration": 113.007244,
     "end_time": "2025-12-28T18:13:29.000496",
     "exception": false,
     "start_time": "2025-12-28T18:11:35.993252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] Staged beehive-audio-dataset-with-queen-and-without-queen -> /kaggle/working/content/beehive_audio\n",
      "[setup] Staged makueni-ndvi-2008-2025-csv -> /kaggle/working/content/main-data\n",
      "CONTENT_ROOT -> /kaggle/working/content\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DEFAULT_CONTENT = PROJECT_ROOT / \"content\"\n",
    "KAGGLE_WORKING = Path(\"/kaggle/working\")\n",
    "\n",
    "if DEFAULT_CONTENT.exists():\n",
    "    CONTENT_ROOT = DEFAULT_CONTENT.resolve()\n",
    "else:\n",
    "    CONTENT_ROOT = (KAGGLE_WORKING / \"content\").resolve()\n",
    "    CONTENT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ[\"MERGED_CONTENT_ROOT\"] = str(CONTENT_ROOT)\n",
    "MAIN_DATA_DIR = (CONTENT_ROOT / \"main-data\")\n",
    "MAIN_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "KAGGLE_INPUT_ROOT = Path(\"/kaggle/input\")\n",
    "\n",
    "def _stage_dataset(keyword, target_subdir):\n",
    "    if not KAGGLE_INPUT_ROOT.exists():\n",
    "        return None\n",
    "    matches = [p for p in KAGGLE_INPUT_ROOT.iterdir() if keyword in p.name.lower()]\n",
    "    if not matches:\n",
    "        print(f\"[setup] Kaggle input dataset containing '{keyword}' not found.\")\n",
    "        return None\n",
    "    source = matches[0]\n",
    "    target = CONTENT_ROOT / target_subdir\n",
    "    shutil.rmtree(target, ignore_errors=True)\n",
    "    shutil.copytree(source, target, dirs_exist_ok=True)\n",
    "    print(f\"[setup] Staged {source.name} -> {target}\")\n",
    "    return target\n",
    "\n",
    "def _maybe_stage(keyword, subdir):\n",
    "    try:\n",
    "        _stage_dataset(keyword, subdir)\n",
    "    except Exception as exc:\n",
    "        print(f\"[setup] Skipping auto-stage for {keyword}: {exc}\")\n",
    "\n",
    "_maybe_stage(\"beehive\", \"beehive_audio\")\n",
    "_maybe_stage(\"makueni\", \"main-data\")\n",
    "\n",
    "print(f\"CONTENT_ROOT -> {CONTENT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcd3ec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:13:29.014827Z",
     "iopub.status.busy": "2025-12-28T18:13:29.014344Z",
     "iopub.status.idle": "2025-12-28T18:13:49.306825Z",
     "shell.execute_reply": "2025-12-28T18:13:49.305980Z"
    },
    "papermill": {
     "duration": 20.301491,
     "end_time": "2025-12-28T18:13:49.308451",
     "exception": false,
     "start_time": "2025-12-28T18:13:29.006960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-28 18:13:32.997824: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766945613.182572      24 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766945613.235266      24 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1766945613.692780      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766945613.692816      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766945613.692818      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766945613.692821      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figures and tables to /kaggle/working/artifacts/figures\n"
     ]
    }
   ],
   "source": [
    "import calendar\n",
    "import datetime as dt\n",
    "import gc\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras_tuner as kt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    RocCurveDisplay\n",
    ")\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import requests\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "CONTENT_ROOT = Path(os.environ[\"MERGED_CONTENT_ROOT\"])\n",
    "MAIN_DATA_DIR = CONTENT_ROOT / \"main-data\"\n",
    "from pathlib import Path\n",
    "FIGURE_DIR = Path('artifacts/figures')\n",
    "FIGURE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Saving figures and tables to', FIGURE_DIR.resolve())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b1462f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:13:49.323656Z",
     "iopub.status.busy": "2025-12-28T18:13:49.323196Z",
     "iopub.status.idle": "2025-12-28T18:13:49.328037Z",
     "shell.execute_reply": "2025-12-28T18:13:49.327348Z"
    },
    "papermill": {
     "duration": 0.013778,
     "end_time": "2025-12-28T18:13:49.329449",
     "exception": false,
     "start_time": "2025-12-28T18:13:49.315671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figures and tables to /kaggle/working/artifacts/figures\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "FIGURE_DIR = Path('artifacts/figures')\n",
    "FIGURE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Saving figures and tables to', FIGURE_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46ce0d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:13:49.344187Z",
     "iopub.status.busy": "2025-12-28T18:13:49.343606Z",
     "iopub.status.idle": "2025-12-28T18:13:49.347627Z",
     "shell.execute_reply": "2025-12-28T18:13:49.346975Z"
    },
    "papermill": {
     "duration": 0.012799,
     "end_time": "2025-12-28T18:13:49.348885",
     "exception": false,
     "start_time": "2025-12-28T18:13:49.336086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figures and tables to /kaggle/working/figures\n"
     ]
    }
   ],
   "source": [
    "FIGURE_DIR = Path('/kaggle/working/figures')\n",
    "FIGURE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Saving figures and tables to', FIGURE_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9379b",
   "metadata": {
    "papermill": {
     "duration": 0.006659,
     "end_time": "2025-12-28T18:13:49.362249",
     "exception": false,
     "start_time": "2025-12-28T18:13:49.355590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Queen Bee Acoustic Detection Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d40f7b",
   "metadata": {
    "papermill": {
     "duration": 0.00677,
     "end_time": "2025-12-28T18:13:49.375867",
     "exception": false,
     "start_time": "2025-12-28T18:13:49.369097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Acoustic Dataset Staging & Lineage\n",
    "\n",
    "The queen-bee classifier is trained from the Kaggle dataset `harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen`. We avoid copying raw WAVs into writable storage unless needed; instead, `_discover_audio_dataset` crawls the mounted `/kaggle/input` tree, validates the folder structure, and exposes canonical paths for the `QueenBee Present`, `QueenBee Absent`, and `External Noise` subsets. This guarantees that every spectrogram (and therefore every model checkpoint) can be traced back to a known dataset version, satisfying the reproducibility requirement in the BeeUnity methodology.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e354fd3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:13:49.390583Z",
     "iopub.status.busy": "2025-12-28T18:13:49.390009Z",
     "iopub.status.idle": "2025-12-28T18:13:53.900252Z",
     "shell.execute_reply": "2025-12-28T18:13:53.899482Z"
    },
    "papermill": {
     "duration": 4.519273,
     "end_time": "2025-12-28T18:13:53.901914",
     "exception": false,
     "start_time": "2025-12-28T18:13:49.382641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio dataset root (read-only): /kaggle/input/beehive-audio-dataset-with-queen-and-without-queen/Dataset\n",
      "Spectrogram cache (writable): /kaggle/working/spectrograms\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def _discover_audio_dataset(content_root: Path) -> Path:\n",
    "    search_root = Path(\"/kaggle/input/beehive-audio-dataset-with-queen-and-without-queen\")\n",
    "    if not search_root.exists():\n",
    "        raise FileNotFoundError(\n",
    "            \"Dataset not staged. Attach Kaggle dataset \"\n",
    "            \"'harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen'.\"\n",
    "        )\n",
    "\n",
    "    for candidate in sorted(search_root.rglob(\"Dataset\")):\n",
    "        if (candidate / \"Bee Hive Audios\").exists():\n",
    "            return candidate\n",
    "\n",
    "    raise FileNotFoundError(\"Could not locate 'Dataset/Bee Hive Audios'.\")\n",
    "\n",
    "# Discover dataset (READ-ONLY)\n",
    "AUDIO_DATASET_ROOT = _discover_audio_dataset(None)\n",
    "\n",
    "BEEHIVE_AUDIO_DIR = next(AUDIO_DATASET_ROOT.glob(\"**/Bee Hive Audios\"))\n",
    "QUEEN_PRESENT_DIR = BEEHIVE_AUDIO_DIR / \"QueenBee Present\"\n",
    "QUEEN_ABSENT_DIR = BEEHIVE_AUDIO_DIR / \"QueenBee Absent\"\n",
    "EXTERNAL_DIR = AUDIO_DATASET_ROOT / \"External Noise\"\n",
    "\n",
    "# WRITEABLE spectrogram directory\n",
    "SPECTROGRAM_DIR = Path(\"/kaggle/working/spectrograms\")\n",
    "SPECTROGRAM_PRESENT = SPECTROGRAM_DIR / \"present\"\n",
    "SPECTROGRAM_ABSENT = SPECTROGRAM_DIR / \"absent\"\n",
    "SPECTROGRAM_EXTERNAL = SPECTROGRAM_DIR / \"external\"\n",
    "\n",
    "for path in [SPECTROGRAM_PRESENT, SPECTROGRAM_ABSENT, SPECTROGRAM_EXTERNAL]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Audio dataset root (read-only):\", AUDIO_DATASET_ROOT)\n",
    "print(\"Spectrogram cache (writable):\", SPECTROGRAM_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d20fa787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:13:53.917094Z",
     "iopub.status.busy": "2025-12-28T18:13:53.916877Z",
     "iopub.status.idle": "2025-12-28T18:13:54.014287Z",
     "shell.execute_reply": "2025-12-28T18:13:54.013570Z"
    },
    "papermill": {
     "duration": 0.106405,
     "end_time": "2025-12-28T18:13:54.015737",
     "exception": false,
     "start_time": "2025-12-28T18:13:53.909332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU via _DefaultDistributionStrategy\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu_resolver)\n",
    "    ACCELERATOR = \"TPU\"\n",
    "except (ValueError, tf.errors.NotFoundError):\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            try:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            except Exception:\n",
    "                pass\n",
    "        # Default to single-replica strategy for Kaggle GPU stability\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        ACCELERATOR = \"GPU\"\n",
    "    else:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        ACCELERATOR = \"CPU\"\n",
    "\n",
    "print(f\"Using {ACCELERATOR} via {strategy.__class__.__name__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92676ae9",
   "metadata": {
    "papermill": {
     "duration": 0.006809,
     "end_time": "2025-12-28T18:13:54.029813",
     "exception": false,
     "start_time": "2025-12-28T18:13:54.023004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Audio Conditioning & Spectrogram Cache\n",
    "\n",
    "To stabilize CNN training we transform each WAV into a fixed 3-second mono clip sampled at 22.05 kHz. The `preprocess_and_save_spectrogram` routine trims silence, enforces constant-length padding, normalizes amplitude, and renders a 128×128 mel-spectrogram using librosa. Spectrograms land under `/kaggle/working/spectrograms/<class>/` and the generators only touch PNGs, eliminating expensive audio decoding during model fit. Progress-aware helpers (e.g., `_compute_progress`) let reruns skip already materialized windows so Kaggle GPU runtime stays within budget.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eda4905b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:13:54.044402Z",
     "iopub.status.busy": "2025-12-28T18:13:54.044165Z",
     "iopub.status.idle": "2025-12-28T18:13:54.058124Z",
     "shell.execute_reply": "2025-12-28T18:13:54.057559Z"
    },
    "papermill": {
     "duration": 0.022968,
     "end_time": "2025-12-28T18:13:54.059469",
     "exception": false,
     "start_time": "2025-12-28T18:13:54.036501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Memory(location=None)]: Flushing completely the cache\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "DURATION = 3\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "librosa.cache.clear()\n",
    "plt.switch_backend(\"Agg\")\n",
    "\n",
    "def preprocess_and_save_spectrogram(audio_path: Path, output_image_path: Path, sr=SAMPLE_RATE, duration=DURATION):\n",
    "    try:\n",
    "        y, _ = librosa.load(audio_path, sr=sr)\n",
    "        y, _ = librosa.effects.trim(y)\n",
    "        y = librosa.to_mono(y) if y.ndim > 1 else y\n",
    "        y = librosa.util.normalize(y)\n",
    "\n",
    "        expected_samples = sr * duration\n",
    "        if len(y) < expected_samples:\n",
    "            y = np.pad(y, (0, expected_samples - len(y)), mode=\"constant\")\n",
    "        else:\n",
    "            y = y[:expected_samples]\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n",
    "        mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "        plt.figure(figsize=(2, 2), dpi=64)\n",
    "        librosa.display.specshow(mel_db, sr=sr, cmap=\"magma\")\n",
    "        plt.axis(\"off\")\n",
    "        output_image_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(output_image_path, bbox_inches=\"tight\", pad_inches=0)\n",
    "        plt.close()\n",
    "    except Exception as exc:\n",
    "        print(f\"[spectrogram] Failed on {audio_path}: {exc}\")\n",
    "\n",
    "def _compute_progress(files, output_dir: Path):\n",
    "    total = len(files)\n",
    "    processed = sum((output_dir / f\"{Path(f).stem}.png\").exists() for f in files)\n",
    "    return total, processed\n",
    "\n",
    "def process_audio_folder(input_dir: Path, output_dir: Path, desc: str):\n",
    "    if not input_dir.exists():\n",
    "        print(f\"[spectrogram] {input_dir} missing, skipping {desc}.\")\n",
    "        return\n",
    "    wav_files = sorted([f for f in input_dir.iterdir() if f.suffix.lower() == \".wav\"])\n",
    "    total, processed = _compute_progress([f.name for f in wav_files], output_dir)\n",
    "    with tqdm(total=total, initial=processed, desc=desc, unit=\"file\") as pbar:\n",
    "        for wav_path in wav_files:\n",
    "            out_path = output_dir / f\"{wav_path.stem}.png\"\n",
    "            if out_path.exists():\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            preprocess_and_save_spectrogram(wav_path, out_path)\n",
    "            gc.collect()\n",
    "            pbar.update(1)\n",
    "\n",
    "def process_external_folder(input_dir: Path, output_dir: Path):\n",
    "    if not input_dir.exists():\n",
    "        print(\"[spectrogram] External noise folder missing, skipping.\")\n",
    "        return\n",
    "    audio_paths = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        audio_paths += [Path(root) / f for f in files if f.lower().endswith(\".wav\")]\n",
    "    with tqdm(total=len(audio_paths), desc=\"External noise\", unit=\"file\") as pbar:\n",
    "        for wav_path in audio_paths:\n",
    "            out_path = output_dir / f\"{wav_path.stem}.png\"\n",
    "            if out_path.exists():\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            preprocess_and_save_spectrogram(wav_path, out_path)\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c7f7d4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:13:54.074286Z",
     "iopub.status.busy": "2025-12-28T18:13:54.074044Z",
     "iopub.status.idle": "2025-12-28T18:53:38.731888Z",
     "shell.execute_reply": "2025-12-28T18:53:38.731237Z"
    },
    "papermill": {
     "duration": 2384.667177,
     "end_time": "2025-12-28T18:53:38.733660",
     "exception": false,
     "start_time": "2025-12-28T18:13:54.066483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QueenBee Present: 100%|██████████| 4000/4000 [25:00<00:00,  2.67file/s]\n",
      "QueenBee Absent: 100%|██████████| 2000/2000 [12:16<00:00,  2.72file/s]\n",
      "External noise: 100%|██████████| 2000/2000 [02:25<00:00, 13.70file/s]\n"
     ]
    }
   ],
   "source": [
    "process_audio_folder(QUEEN_PRESENT_DIR, SPECTROGRAM_PRESENT, \"QueenBee Present\")\n",
    "process_audio_folder(QUEEN_ABSENT_DIR, SPECTROGRAM_ABSENT, \"QueenBee Absent\")\n",
    "process_external_folder(EXTERNAL_DIR, SPECTROGRAM_EXTERNAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c37047c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:53:39.293515Z",
     "iopub.status.busy": "2025-12-28T18:53:39.292903Z",
     "iopub.status.idle": "2025-12-28T18:53:39.386067Z",
     "shell.execute_reply": "2025-12-28T18:53:39.385351Z"
    },
    "papermill": {
     "duration": 0.352238,
     "end_time": "2025-12-28T18:53:39.387547",
     "exception": false,
     "start_time": "2025-12-28T18:53:39.035309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'present': 4000, 'absent': 2000, 'external': 2000}\n"
     ]
    }
   ],
   "source": [
    "def count_pngs(folder: Path):\n",
    "    return len([f for f in folder.glob(\"*.png\")])\n",
    "\n",
    "class_labels = [\"present\", \"absent\", \"external\"]\n",
    "counts = [\n",
    "    count_pngs(SPECTROGRAM_PRESENT),\n",
    "    count_pngs(SPECTROGRAM_ABSENT),\n",
    "    count_pngs(SPECTROGRAM_EXTERNAL),\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = plt.bar(class_labels, counts, color=[\"sienna\", \"peru\", \"gray\"], edgecolor=\"black\")\n",
    "plt.ylim(0, max(counts) * 1.1 if counts else 10)\n",
    "plt.title(\"Spectrogram Count per Class\")\n",
    "plt.ylabel(\"Images\")\n",
    "for bar in bars:\n",
    "    y = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, y + max(1, y ** 0.5), int(y), ha=\"center\", va=\"bottom\")\n",
    "plt.show()\n",
    "\n",
    "print(dict(zip(class_labels, counts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9319ac",
   "metadata": {
    "papermill": {
     "duration": 0.249815,
     "end_time": "2025-12-28T18:53:39.963563",
     "exception": false,
     "start_time": "2025-12-28T18:53:39.713748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Stratified DataFrames, Augmentation, and Class Weights\n",
    "\n",
    "The original ImageDataGenerator split approach caused leakage between validation/test folds. We now build a pandas catalog of every spectrogram file, stratify it into train/val/test via `train_test_split`, and feed `flow_from_dataframe` generators. Light-weight augmentations (flip + shifts) only touch the training subset. Class imbalance (present:absent:external = 4000:2000:2000) is mitigated through `compute_class_weight` and a custom `SparseClassRecall` metric that explicitly tracks recall on the underrepresented `absent` class; both feed into every Keras fit/tuning call so the notebook’s metrics align with the research objective of catching queen loss events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b01925e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:53:40.473368Z",
     "iopub.status.busy": "2025-12-28T18:53:40.472545Z",
     "iopub.status.idle": "2025-12-28T18:53:40.608513Z",
     "shell.execute_reply": "2025-12-28T18:53:40.607812Z"
    },
    "papermill": {
     "duration": 0.393254,
     "end_time": "2025-12-28T18:53:40.609965",
     "exception": false,
     "start_time": "2025-12-28T18:53:40.216711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4800 validated image filenames belonging to 3 classes.\n",
      "Found 1600 validated image filenames belonging to 3 classes.\n",
      "Found 1600 validated image filenames belonging to 3 classes.\n",
      "Class indices: {'absent': 0, 'external': 1, 'present': 2}\n",
      "Class weights: {0: np.float64(1.3333333333333333), 1: np.float64(1.3333333333333333), 2: np.float64(0.6666666666666666)}\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (128, 128)\n",
    "BASE_BATCH_SIZE = 32\n",
    "BATCH_SIZE = BASE_BATCH_SIZE  # Keep per-device batch size stable on Kaggle\n",
    "SEED = 42\n",
    "\n",
    "spectro_records = []\n",
    "for class_dir in sorted(SPECTROGRAM_DIR.iterdir()):\n",
    "    if class_dir.is_dir():\n",
    "        label = class_dir.name\n",
    "        for img_path in class_dir.glob(\"*.png\"):\n",
    "            spectro_records.append({\"filepath\": str(img_path), \"label\": label})\n",
    "\n",
    "if not spectro_records:\n",
    "    raise RuntimeError(\"No spectrograms were generated; run preprocessing above first.\")\n",
    "\n",
    "spectro_df = pd.DataFrame(spectro_records)\n",
    "CLASS_NAMES = sorted(spectro_df[\"label\"].unique())\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    spectro_df,\n",
    "    test_size=0.4,\n",
    "    stratify=spectro_df[\"label\"],\n",
    "    random_state=SEED\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df[\"label\"],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05\n",
    ")\n",
    "eval_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    classes=CLASS_NAMES,\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_gen = eval_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    classes=CLASS_NAMES,\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_gen = eval_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    classes=CLASS_NAMES,\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "raw_class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.array(CLASS_NAMES),\n",
    "    y=train_df[\"label\"]\n",
    ")\n",
    "CLASS_WEIGHTS = {\n",
    "    train_gen.class_indices[label]: weight for label, weight in zip(CLASS_NAMES, raw_class_weights)\n",
    "}\n",
    "print(\"Class indices:\", train_gen.class_indices)\n",
    "print(\"Class weights:\", CLASS_WEIGHTS)\n",
    "\n",
    "ABSENT_CLASS_INDEX = train_gen.class_indices[\"absent\"]\n",
    "\n",
    "class SparseClassRecall(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_id, name=\"sparse_class_recall\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.class_id = class_id\n",
    "        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n",
    "        self.false_negatives = self.add_weight(name=\"fn\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(tf.reshape(y_true, [-1]), tf.int32)\n",
    "        y_pred = tf.cast(tf.argmax(y_pred, axis=-1), tf.int32)\n",
    "        class_mask = tf.cast(tf.equal(y_true, self.class_id), self.dtype)\n",
    "        pred_mask = tf.cast(tf.equal(y_pred, self.class_id), self.dtype)\n",
    "        if sample_weight is None:\n",
    "            weights = tf.ones_like(class_mask)\n",
    "        else:\n",
    "            weights = tf.cast(tf.reshape(sample_weight, [-1]), self.dtype)\n",
    "            weights = tf.broadcast_to(weights, tf.shape(class_mask))\n",
    "        weighted_mask = class_mask * weights\n",
    "        tp = tf.reduce_sum(pred_mask * weighted_mask)\n",
    "        fn = tf.reduce_sum((1.0 - pred_mask) * weighted_mask)\n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"class_id\": int(self.class_id)})\n",
    "        return config\n",
    "\n",
    "    def result(self):\n",
    "        return tf.math.divide_no_nan(self.true_positives, self.true_positives + self.false_negatives)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.true_positives.assign(0.0)\n",
    "        self.false_negatives.assign(0.0)\n",
    "\n",
    "def make_absent_recall(name=\"recall_absent\"):\n",
    "    return SparseClassRecall(class_id=ABSENT_CLASS_INDEX, name=name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddc6094",
   "metadata": {
    "papermill": {
     "duration": 0.250376,
     "end_time": "2025-12-28T18:53:41.109515",
     "exception": false,
     "start_time": "2025-12-28T18:53:40.859139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Baseline CNN Training Plan\n",
    "\n",
    "The baseline network is intentionally compact so it trains quickly on Kaggle GPUs yet captures salient spectral patterns: three Conv-BN-Pool stages followed by GAP and a 64-unit dense head. Training runs under the selected `strategy` with class weights + early stopping keyed to `val_recall_absent` to bias the model toward correctly flagging queen-absent clips. This baseline establishes the minimum viable performance before hyperparameter search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cd995a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:53:41.683236Z",
     "iopub.status.busy": "2025-12-28T18:53:41.682532Z",
     "iopub.status.idle": "2025-12-28T18:59:20.991829Z",
     "shell.execute_reply": "2025-12-28T18:59:20.991121Z"
    },
    "papermill": {
     "duration": 339.977174,
     "end_time": "2025-12-28T18:59:21.407413",
     "exception": false,
     "start_time": "2025-12-28T18:53:41.430239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1766948021.968312      24 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1766948021.972169      24 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1766948025.971070      88 service.cc:152] XLA service 0x78ca9c006a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1766948025.971118      88 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1766948025.971125      88 service.cc:160]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1766948026.473725      88 cuda_dnn.cc:529] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  3/150\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 78ms/step - accuracy: 0.2604 - loss: 1.4310 - recall_absent: 0.3235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1766948030.795818      88 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 143ms/step - accuracy: 0.6859 - loss: 0.7223 - recall_absent: 0.6510 - val_accuracy: 0.5000 - val_loss: 1.3512 - val_recall_absent: 0.0000e+00\n",
      "Epoch 2/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 138ms/step - accuracy: 0.8792 - loss: 0.3100 - recall_absent: 0.8797 - val_accuracy: 0.5175 - val_loss: 2.3872 - val_recall_absent: 0.0000e+00\n",
      "Epoch 3/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9388 - loss: 0.1857 - recall_absent: 0.9271 - val_accuracy: 0.5462 - val_loss: 3.9077 - val_recall_absent: 0.0000e+00\n",
      "Epoch 4/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9435 - loss: 0.1595 - recall_absent: 0.9383 - val_accuracy: 0.7287 - val_loss: 0.7258 - val_recall_absent: 0.0700\n",
      "Epoch 5/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 136ms/step - accuracy: 0.9620 - loss: 0.1067 - recall_absent: 0.9633 - val_accuracy: 0.2681 - val_loss: 5.2111 - val_recall_absent: 0.0000e+00\n",
      "Epoch 6/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 136ms/step - accuracy: 0.9529 - loss: 0.1408 - recall_absent: 0.9406 - val_accuracy: 0.4494 - val_loss: 1.7868 - val_recall_absent: 0.0000e+00\n",
      "Epoch 7/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 138ms/step - accuracy: 0.9727 - loss: 0.0844 - recall_absent: 0.9720 - val_accuracy: 0.2763 - val_loss: 3.7892 - val_recall_absent: 0.0975\n",
      "Epoch 8/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 138ms/step - accuracy: 0.9702 - loss: 0.0869 - recall_absent: 0.9750 - val_accuracy: 0.2500 - val_loss: 13.6397 - val_recall_absent: 0.0000e+00\n",
      "Epoch 9/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 138ms/step - accuracy: 0.9686 - loss: 0.0893 - recall_absent: 0.9706 - val_accuracy: 0.2869 - val_loss: 3.7752 - val_recall_absent: 0.0950\n",
      "Epoch 10/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9723 - loss: 0.0722 - recall_absent: 0.9658 - val_accuracy: 0.3931 - val_loss: 3.6379 - val_recall_absent: 0.5725\n",
      "Epoch 11/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9761 - loss: 0.0744 - recall_absent: 0.9807 - val_accuracy: 0.3069 - val_loss: 3.6070 - val_recall_absent: 0.2050\n",
      "Epoch 12/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 138ms/step - accuracy: 0.9764 - loss: 0.0641 - recall_absent: 0.9749 - val_accuracy: 0.5038 - val_loss: 1.6450 - val_recall_absent: 0.0600\n",
      "Epoch 13/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 136ms/step - accuracy: 0.9691 - loss: 0.0737 - recall_absent: 0.9710 - val_accuracy: 0.8494 - val_loss: 0.4302 - val_recall_absent: 0.9850\n",
      "Epoch 14/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9752 - loss: 0.0703 - recall_absent: 0.9809 - val_accuracy: 0.2512 - val_loss: 6.4645 - val_recall_absent: 0.0025\n",
      "Epoch 15/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 136ms/step - accuracy: 0.9816 - loss: 0.0637 - recall_absent: 0.9785 - val_accuracy: 0.9156 - val_loss: 0.2445 - val_recall_absent: 0.6750\n",
      "Epoch 16/20\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 136ms/step - accuracy: 0.9791 - loss: 0.0488 - recall_absent: 0.9780 - val_accuracy: 0.2500 - val_loss: 18.0678 - val_recall_absent: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_baseline_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\", input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", make_absent_recall()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "with strategy.scope():\n",
    "    baseline_model = build_baseline_model()\n",
    "\n",
    "baseline_callbacks = [\n",
    "    EarlyStopping(monitor=\"val_recall_absent\", mode=\"max\", patience=3, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=20,\n",
    "    class_weight=CLASS_WEIGHTS,\n",
    "    callbacks=baseline_callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca90b3",
   "metadata": {
    "papermill": {
     "duration": 0.345707,
     "end_time": "2025-12-28T18:59:22.100201",
     "exception": false,
     "start_time": "2025-12-28T18:59:21.754494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### KerasTuner Hyperband Search & Fine-Tune\n",
    "\n",
    "Hyperparameter tuning explores filter widths, dense units, dropout, and optimizer choice via `kt.Hyperband`, again optimizing `val_recall_absent`. The tuner runs outside the distribution `strategy` scope (per TensorFlow guidance) while the search/ fine-tune phases inherit the same class weights + early stopping regime as the baseline. The best trial is persisted as a `.keras` artifact under `/kaggle/working` for downstream deployment / report inclusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea1d888d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:59:22.870608Z",
     "iopub.status.busy": "2025-12-28T18:59:22.870050Z",
     "iopub.status.idle": "2025-12-28T19:46:44.493081Z",
     "shell.execute_reply": "2025-12-28T19:46:44.492399Z"
    },
    "papermill": {
     "duration": 2842.052811,
     "end_time": "2025-12-28T19:46:44.494695",
     "exception": false,
     "start_time": "2025-12-28T18:59:22.441884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 02m 35s]\n",
      "val_recall_absent: 0.9900000095367432\n",
      "\n",
      "Best val_recall_absent So Far: 1.0\n",
      "Total elapsed time: 00h 45m 08s\n",
      "Epoch 1/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 144ms/step - accuracy: 0.8868 - loss: 0.2848 - recall_absent: 0.8721 - val_accuracy: 0.3556 - val_loss: 2.5734 - val_recall_absent: 0.9775\n",
      "Epoch 2/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 140ms/step - accuracy: 0.9278 - loss: 0.1983 - recall_absent: 0.9221 - val_accuracy: 0.7081 - val_loss: 0.8287 - val_recall_absent: 0.9550\n",
      "Epoch 3/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 139ms/step - accuracy: 0.9528 - loss: 0.1359 - recall_absent: 0.9406 - val_accuracy: 0.4394 - val_loss: 2.5531 - val_recall_absent: 0.9975\n",
      "Epoch 4/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 139ms/step - accuracy: 0.9543 - loss: 0.1244 - recall_absent: 0.9501 - val_accuracy: 0.4906 - val_loss: 2.3552 - val_recall_absent: 0.9600\n",
      "Epoch 5/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 142ms/step - accuracy: 0.9606 - loss: 0.1090 - recall_absent: 0.9695 - val_accuracy: 0.6400 - val_loss: 1.2787 - val_recall_absent: 0.8850\n",
      "Epoch 6/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 141ms/step - accuracy: 0.9602 - loss: 0.0961 - recall_absent: 0.9720 - val_accuracy: 0.2500 - val_loss: 5.4523 - val_recall_absent: 0.0000e+00\n",
      "Saved tuned model to /kaggle/working/queenbee_final_tuned_model.keras\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from pathlib import Path\n",
    "\n",
    "def build_tunable_model(hp):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(\n",
    "            hp.Choice(\"conv1\", [32, 64]), 3,\n",
    "            activation=\"relu\", padding=\"same\",\n",
    "            input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(hp.Choice(\"conv2\", [64, 128]), 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(hp.Choice(\"conv3\", [128, 256]), 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(hp.Int(\"dense_units\", 64, 128, step=32), activation=\"relu\"),\n",
    "        layers.Dropout(hp.Float(\"dropout\", 0.3, 0.6, step=0.1)),\n",
    "        layers.Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=hp.Choice(\"optimizer\", [\"adam\", \"nadam\"]),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", make_absent_recall()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Strategy ONLY for tuner creation\n",
    "with strategy.scope():\n",
    "    tuner = kt.Hyperband(\n",
    "        build_tunable_model,\n",
    "        objective=kt.Objective(\"val_recall_absent\", direction=\"max\"),\n",
    "        max_epochs=15,\n",
    "        factor=3,\n",
    "        directory=\"/kaggle/working/queenbee_tuning\",\n",
    "        project_name=\"queenbee_cnn\"\n",
    "    )\n",
    "\n",
    "stopper = EarlyStopping(\n",
    "    monitor=\"val_recall_absent\",\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Search OUTSIDE strategy scope\n",
    "tuner.search(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=15,\n",
    "    class_weight=CLASS_WEIGHTS,\n",
    "    callbacks=[stopper]\n",
    ")\n",
    "\n",
    "# NO strategy scope here\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "fine_tune_history = best_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=15,\n",
    "    class_weight=CLASS_WEIGHTS,\n",
    "    callbacks=[stopper]\n",
    ")\n",
    "\n",
    "# Writable save path\n",
    "best_model_path = Path(\"/kaggle/working/queenbee_final_tuned_model.keras\")\n",
    "best_model.save(best_model_path)\n",
    "\n",
    "print(\"Saved tuned model to\", best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2af3725a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:46:45.328372Z",
     "iopub.status.busy": "2025-12-28T19:46:45.328048Z",
     "iopub.status.idle": "2025-12-28T19:46:45.551184Z",
     "shell.execute_reply": "2025-12-28T19:46:45.550374Z"
    },
    "papermill": {
     "duration": 0.604923,
     "end_time": "2025-12-28T19:46:45.552843",
     "exception": false,
     "start_time": "2025-12-28T19:46:44.947920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_for_eval = load_model(\n",
    "    best_model_path,\n",
    "    custom_objects={\"SparseClassRecall\": SparseClassRecall}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771251a",
   "metadata": {
    "papermill": {
     "duration": 0.458259,
     "end_time": "2025-12-28T19:46:46.391618",
     "exception": false,
     "start_time": "2025-12-28T19:46:45.933359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Probability Calibration & Threshold Selection\n",
    "\n",
    "Raw softmax scores tend to collapse onto the majority `present` class. After loading the tuned CNN we perform two evaluation modes: standard argmax and calibrated predictions. Validation probabilities drive per-class precision-recall curves, from which we select F1-optimal thresholds. Those calibrated thresholds are then applied to the held-out test generator, yielding confusion matrices, detailed classification reports, and macro ROC/PR AUC metrics that the manuscript can cite when describing queen-state detection performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04fe30e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:46:47.147533Z",
     "iopub.status.busy": "2025-12-28T19:46:47.147051Z",
     "iopub.status.idle": "2025-12-28T19:46:51.262892Z",
     "shell.execute_reply": "2025-12-28T19:46:51.262217Z"
    },
    "papermill": {
     "duration": 4.494665,
     "end_time": "2025-12-28T19:46:51.264561",
     "exception": false,
     "start_time": "2025-12-28T19:46:46.769896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n",
      "Calibrated probability thresholds:\n",
      "  absent: 0.909\n",
      "  external: 0.404\n",
      "  present: 0.004\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mode</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argmax</td>\n",
       "      <td>0.436875</td>\n",
       "      <td>0.425681</td>\n",
       "      <td>0.582500</td>\n",
       "      <td>0.439087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calibrated</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.756600</td>\n",
       "      <td>0.724167</td>\n",
       "      <td>0.687496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mode  Accuracy  Macro Precision  Macro Recall  Macro F1\n",
       "0      Argmax  0.436875         0.425681      0.582500  0.439087\n",
       "1  Calibrated  0.660000         0.756600      0.724167  0.687496"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved acoustic metrics table -> /kaggle/working/figures/acoustic_metrics_table.csv\n",
      "Saved acoustic confusion matrix -> /kaggle/working/figures/acoustic_confusion_matrix.png\n",
      "Calibrated classification report:               precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.43      0.91      0.58       400\n",
      "    external       0.95      0.80      0.86       400\n",
      "     present       0.89      0.47      0.61       800\n",
      "\n",
      "    accuracy                           0.66      1600\n",
      "   macro avg       0.76      0.72      0.69      1600\n",
      "weighted avg       0.79      0.66      0.67      1600\n",
      "\n",
      "ROC-AUC: 0.8513 | PR-AUC: 0.7169\n",
      "Saved acoustic AUC summary -> /kaggle/working/figures/acoustic_auc_summary.json\n"
     ]
    }
   ],
   "source": [
    "def run_inference(model, generator):\n",
    "    generator.reset()\n",
    "    y_prob = model.predict(generator, verbose=1)\n",
    "    y_true = generator.classes\n",
    "    return y_prob, y_true\n",
    "\n",
    "\n",
    "def derive_thresholds(y_true, y_prob, class_names):\n",
    "    y_true_oh = tf.keras.utils.to_categorical(y_true, num_classes=len(class_names))\n",
    "    thresholds = {}\n",
    "    for idx, name in enumerate(class_names):\n",
    "        precision, recall, thresh = precision_recall_curve(y_true_oh[:, idx], y_prob[:, idx])\n",
    "        if thresh.size == 0:\n",
    "            thresholds[name] = 0.5\n",
    "            continue\n",
    "        f1 = 2 * precision * recall / np.clip(precision + recall, 1e-8, None)\n",
    "        best_idx = np.nanargmax(f1)\n",
    "        thresholds[name] = float(thresh[min(best_idx, len(thresh) - 1)])\n",
    "    return thresholds\n",
    "\n",
    "\n",
    "def predict_with_thresholds(y_prob, class_names, thresholds):\n",
    "    calibrated = []\n",
    "    for row in y_prob:\n",
    "        chosen_idx = None\n",
    "        chosen_score = -1.0\n",
    "        for idx, name in enumerate(class_names):\n",
    "            threshold = thresholds.get(name, 0.5)\n",
    "            if row[idx] >= threshold and row[idx] > chosen_score:\n",
    "                chosen_idx = idx\n",
    "                chosen_score = row[idx]\n",
    "        if chosen_idx is None:\n",
    "            chosen_idx = int(np.argmax(row))\n",
    "        calibrated.append(chosen_idx)\n",
    "    return np.array(calibrated)\n",
    "\n",
    "\n",
    "def summarize_metrics(y_true, y_pred, label):\n",
    "    return {\n",
    "        \"Mode\": label,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Macro Precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"Macro Recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"Macro F1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    }\n",
    "\n",
    "val_prob, val_true = run_inference(model_for_eval, val_gen)\n",
    "class_names = list(test_gen.class_indices.keys())\n",
    "thresholds = derive_thresholds(val_true, val_prob, class_names)\n",
    "print(\"Calibrated probability thresholds:\")\n",
    "for name in class_names:\n",
    "    print(f\"  {name}: {thresholds[name]:.3f}\")\n",
    "\n",
    "metrics = []\n",
    "test_prob, test_true = run_inference(model_for_eval, test_gen)\n",
    "default_pred = np.argmax(test_prob, axis=1)\n",
    "calibrated_pred = predict_with_thresholds(test_prob, class_names, thresholds)\n",
    "\n",
    "metrics_table = pd.DataFrame([\n",
    "    summarize_metrics(test_true, default_pred, \"Argmax\"),\n",
    "    summarize_metrics(test_true, calibrated_pred, \"Calibrated\")\n",
    "])\n",
    "display(metrics_table)\n",
    "metrics_table_path = FIGURE_DIR / \"acoustic_metrics_table.csv\"\n",
    "metrics_table.to_csv(metrics_table_path, index=False)\n",
    "print(\"Saved acoustic metrics table ->\", metrics_table_path)\n",
    "\n",
    "cm = confusion_matrix(test_true, calibrated_pred)\n",
    "cm_fig, ax = plt.subplots(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "ax.set_title(\"Confusion Matrix (Calibrated)\")\n",
    "cm_path = FIGURE_DIR / \"acoustic_confusion_matrix.png\"\n",
    "cm_fig.savefig(cm_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved acoustic confusion matrix ->\", cm_path)\n",
    "\n",
    "report_text = classification_report(test_true, calibrated_pred, target_names=class_names, zero_division=0)\n",
    "print(\"Calibrated classification report:\", report_text)\n",
    "report_path = FIGURE_DIR / \"acoustic_classification_report.txt\"\n",
    "report_path.write_text(report_text)\n",
    "\n",
    "roc_auc = roc_auc_score(\n",
    "    pd.get_dummies(test_true, drop_first=False).values,\n",
    "    test_prob,\n",
    "    average=\"macro\",\n",
    "    multi_class=\"ovr\"\n",
    ")\n",
    "pr_auc = average_precision_score(\n",
    "    pd.get_dummies(test_true, drop_first=False).values,\n",
    "    test_prob,\n",
    "    average=\"macro\"\n",
    ")\n",
    "auc_path = FIGURE_DIR / \"acoustic_auc_summary.json\"\n",
    "auc_path.write_text(json.dumps({\"roc_auc\": float(roc_auc), \"pr_auc\": float(pr_auc)}, indent=2))\n",
    "print(f\"ROC-AUC: {roc_auc:.4f} | PR-AUC: {pr_auc:.4f}\")\n",
    "print(\"Saved acoustic AUC summary ->\", auc_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5940ec58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:46:52.113769Z",
     "iopub.status.busy": "2025-12-28T19:46:52.113037Z",
     "iopub.status.idle": "2025-12-28T19:46:53.493147Z",
     "shell.execute_reply": "2025-12-28T19:46:53.492210Z"
    },
    "papermill": {
     "duration": 1.847231,
     "end_time": "2025-12-28T19:46:53.494995",
     "exception": false,
     "start_time": "2025-12-28T19:46:51.647764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': 'absent', 'confidence': 0.9702820181846619}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SR = 22050\n",
    "\n",
    "def audio_to_spectrogram_image(audio_path: Path):\n",
    "    y, sr = librosa.load(audio_path, sr=SR)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=512)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    fig = plt.figure(figsize=(2, 2), dpi=64)\n",
    "    librosa.display.specshow(S_dB, sr=sr, cmap=\"magma\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "\n",
    "    img = Image.open(buf).convert(\"RGB\").resize(IMG_SIZE)\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "def visualize_audio_prediction(audio_path: Path, model):\n",
    "    mel_input = audio_to_spectrogram_image(audio_path)\n",
    "    prediction = model.predict(mel_input)\n",
    "    class_names = list(test_gen.class_indices.keys())\n",
    "    pred_idx = int(np.argmax(prediction))\n",
    "    confidence = float(np.max(prediction))\n",
    "\n",
    "    y, sr = librosa.load(audio_path, sr=SR)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    times = np.linspace(0, len(y)/sr, len(y))\n",
    "    axes[0,0].plot(times, y)\n",
    "    axes[0,0].set_title(\"Waveform\")\n",
    "\n",
    "    img = axes[0,1].imshow(mel_db, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n",
    "    axes[0,1].set_title(\"Mel Spectrogram\")\n",
    "    plt.colorbar(img, ax=axes[0,1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    axes[1,0].bar(class_names, prediction[0], color=\"teal\")\n",
    "    axes[1,0].set_ylim(0, 1)\n",
    "    axes[1,0].set_title(\"Prediction Probabilities\")\n",
    "\n",
    "    axes[1,1].axis(\"off\")\n",
    "    axes[1,1].text(0.1, 0.5, f\"Predicted: {class_names[pred_idx]}\\nConfidence: {confidence:.2%}\", fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\"prediction\": class_names[pred_idx], \"confidence\": confidence}\n",
    "\n",
    "sample_audio = next(QUEEN_PRESENT_DIR.glob('*.wav'))\n",
    "visualize_audio_prediction(sample_audio, model_for_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce06818",
   "metadata": {
    "papermill": {
     "duration": 0.378053,
     "end_time": "2025-12-28T19:46:54.287008",
     "exception": false,
     "start_time": "2025-12-28T19:46:53.908955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Makueni Climate-Informed Forecasting\n",
    "\n",
    "We now project yield and occupancy directly from climate/NDVI sequences using Würzburg-pretrained models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855627ea",
   "metadata": {
    "papermill": {
     "duration": 0.462507,
     "end_time": "2025-12-28T19:46:55.127377",
     "exception": false,
     "start_time": "2025-12-28T19:46:54.664870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Makueni Apiary Intelligence Pipeline\n",
    "\n",
    "The second half of BeeUnity focuses on environmental + hive telemetry analytics for Makueni County. Users can optionally pick a geometry via ipyleaflet; however, Kaggle’s environment rarely ships the `jupyter-leaflet` extension, so we default to fixed coordinates while preserving the widget wiring for local notebooks. This section obeys Kaggle’s outbound-network policy via the `ENABLE_REMOTE_CALLS` flag and falls back to cached CSV exports inside `content/main-data/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54ab8f26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:46:55.901489Z",
     "iopub.status.busy": "2025-12-28T19:46:55.901147Z",
     "iopub.status.idle": "2025-12-28T19:46:56.076566Z",
     "shell.execute_reply": "2025-12-28T19:46:56.075883Z"
    },
    "papermill": {
     "duration": 0.57441,
     "end_time": "2025-12-28T19:46:56.084004",
     "exception": false,
     "start_time": "2025-12-28T19:46:55.509594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aaa880845b84247933e95002fdb819d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatText(value=-1.8048, description='Latitude', step=0.0001), FloatText(value=37.62, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5133ddedc0164eddb71f7e7388eaa30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Geometry', disabled=True, layout=Layout(height='140px', width='100%'), placeho…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f8d5aaa08d4a24801e30851569a6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-1.8048, 37.62], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DEFAULT_CENTER = (-1.8048, 37.62)\n",
    "ENABLE_LEAFLET_WIDGETS = False  # Set True only if jupyter-leaflet widgets are installed.\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from ipyleaflet import Map, Marker, DrawControl, basemaps\n",
    "except Exception:\n",
    "    print(\"ipyleaflet not available; using default coordinates.\")\n",
    "    lat_widget = lon_widget = geometry_widget = None\n",
    "else:\n",
    "    lat_widget = widgets.FloatText(value=DEFAULT_CENTER[0], description=\"Latitude\", step=0.0001)\n",
    "    lon_widget = widgets.FloatText(value=DEFAULT_CENTER[1], description=\"Longitude\", step=0.0001)\n",
    "    geometry_widget = widgets.Textarea(\n",
    "        value=\"\",\n",
    "        description=\"Geometry\",\n",
    "        placeholder=\"Draw a polygon/rectangle on the map.\",\n",
    "        layout=widgets.Layout(width=\"100%\", height=\"140px\"),\n",
    "        disabled=True,\n",
    "    )\n",
    "\n",
    "    leaflet_map = Map(center=DEFAULT_CENTER, zoom=8, basemap=basemaps.OpenStreetMap.Mapnik, scroll_wheel_zoom=True)\n",
    "    marker = Marker(location=DEFAULT_CENTER, draggable=True)\n",
    "    leaflet_map.add_layer(marker)\n",
    "\n",
    "    draw_control = DrawControl(\n",
    "        polygon={\"shapeOptions\": {\"color\": \"#2563eb\", \"weight\": 2, \"fillOpacity\": 0.2}},\n",
    "        rectangle={\"shapeOptions\": {\"color\": \"#f97316\", \"weight\": 2, \"fillOpacity\": 0.15}},\n",
    "        circle={},\n",
    "        circlemarker={},\n",
    "        polyline={},\n",
    "    )\n",
    "    leaflet_map.add_control(draw_control)\n",
    "\n",
    "    def _update_marker(change):\n",
    "        marker.location = (lat_widget.value, lon_widget.value)\n",
    "\n",
    "    lat_widget.observe(_update_marker, names=\"value\")\n",
    "    lon_widget.observe(_update_marker, names=\"value\")\n",
    "\n",
    "    display(widgets.HBox([lat_widget, lon_widget]))\n",
    "    display(geometry_widget)\n",
    "    display(leaflet_map)\n",
    "\n",
    "lat_widget_available = 'lat_widget' in globals() and lat_widget is not None\n",
    "lon_widget_available = 'lon_widget' in globals() and lon_widget is not None\n",
    "\n",
    "if lat_widget_available and lon_widget_available:\n",
    "    latitude = float(lat_widget.value)\n",
    "    longitude = float(lon_widget.value)\n",
    "else:\n",
    "    latitude, longitude = DEFAULT_CENTER\n",
    "    print(\"Using default coordinates:\", DEFAULT_CENTER)\n",
    "\n",
    "selected_geometry_geojson = globals().get('selected_geometry_geojson')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617b1474",
   "metadata": {
    "papermill": {
     "duration": 0.46379,
     "end_time": "2025-12-28T19:46:56.933205",
     "exception": false,
     "start_time": "2025-12-28T19:46:56.469415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Weather/NDVI Acquisition Strategy\n",
    "\n",
    "We scope the modeling window via `normalize_date_string`, clamp requests to the latest Open-Meteo archive availability, and split long ranges into 365-day chunks. When `ENABLE_REMOTE_CALLS` is false (the Kaggle default), we load pre-exported weather and NDVI CSVs staged under `content/main-data/`. When high-trust compute is available, the notebook can re-fetch ERA5/Open-Meteo and MODIS NDVI slices, persisting them with consistent schemas so report figures remain reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c7d71bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:46:57.691712Z",
     "iopub.status.busy": "2025-12-28T19:46:57.690844Z",
     "iopub.status.idle": "2025-12-28T19:46:57.855155Z",
     "shell.execute_reply": "2025-12-28T19:46:57.854392Z"
    },
    "papermill": {
     "duration": 0.545226,
     "end_time": "2025-12-28T19:46:57.856707",
     "exception": false,
     "start_time": "2025-12-28T19:46:57.311481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using date range: 2008-01-01 → 2025-12-05\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "\n",
    "raw_start_date = \"2008-01-01\"\n",
    "raw_end_date = \"2025-12-05\"\n",
    "timezone = \"Africa/Nairobi\"\n",
    "\n",
    "def normalize_date_string(d: str) -> dt.date:\n",
    "    parts = d.split(\"-\")\n",
    "    if len(parts) != 3:\n",
    "        raise ValueError(\"Date must be YYYY-MM-DD\")\n",
    "    y, m, day = [int(p) for p in parts]\n",
    "    m = max(1, min(12, m))\n",
    "    last_day = calendar.monthrange(y, m)[1]\n",
    "    day = max(1, min(last_day, day))\n",
    "    return dt.date(y, m, day)\n",
    "\n",
    "start_date = normalize_date_string(raw_start_date)\n",
    "end_date = normalize_date_string(raw_end_date)\n",
    "\n",
    "today = dt.date.today()\n",
    "api_latest = dt.date(2025, 12, 20)\n",
    "max_allowed = min(today, api_latest)\n",
    "\n",
    "if end_date > max_allowed:\n",
    "    print(f\"Clamping end_date {end_date} -> {max_allowed}\")\n",
    "    end_date = max_allowed\n",
    "if start_date > end_date:\n",
    "    raise ValueError(\"start_date must be before end_date\")\n",
    "\n",
    "print(\"Using date range:\", start_date, \"→\", end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78749cc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:46:58.612254Z",
     "iopub.status.busy": "2025-12-28T19:46:58.611927Z",
     "iopub.status.idle": "2025-12-28T19:46:58.619202Z",
     "shell.execute_reply": "2025-12-28T19:46:58.618632Z"
    },
    "papermill": {
     "duration": 0.386671,
     "end_time": "2025-12-28T19:46:58.620551",
     "exception": false,
     "start_time": "2025-12-28T19:46:58.233880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENABLE_REMOTE_CALLS = True  # Kaggle notebooks typically block outbound internet.\n",
    "\n",
    "def split_date_range(start: dt.date, end: dt.date, max_days: int = 365):\n",
    "    chunks = []\n",
    "    current = start\n",
    "    while current <= end:\n",
    "        chunk_end = min(end, current + dt.timedelta(days=max_days - 1))\n",
    "        chunks.append((current, chunk_end))\n",
    "        current = chunk_end + dt.timedelta(days=1)\n",
    "    return chunks\n",
    "\n",
    "def fetch_chunk(lat, lon, sdate: dt.date, edate: dt.date, timezone=\"Africa/Nairobi\", max_retries=3, backoff=2):\n",
    "    base = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    daily_vars = \",\".join([\n",
    "        \"temperature_2m_max\",\n",
    "        \"temperature_2m_min\",\n",
    "        \"temperature_2m_mean\",\n",
    "        \"precipitation_sum\",\n",
    "        \"relative_humidity_2m_mean\",\n",
    "        \"wind_speed_10m_max\",\n",
    "        \"cloudcover_mean\"\n",
    "    ])\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": sdate.strftime(\"%Y-%m-%d\"),\n",
    "        \"end_date\": edate.strftime(\"%Y-%m-%d\"),\n",
    "        \"daily\": daily_vars,\n",
    "        \"timezone\": timezone\n",
    "    }\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            resp = requests.get(base, params=params, timeout=30)\n",
    "            resp.raise_for_status()\n",
    "            payload = resp.json()\n",
    "            if \"daily\" not in payload or \"time\" not in payload[\"daily\"]:\n",
    "                raise ValueError(\"API response missing expected fields.\")\n",
    "            return payload\n",
    "        except Exception as exc:\n",
    "            print(f\"Attempt {attempt} failed: {exc}\")\n",
    "            if attempt == max_retries:\n",
    "                raise\n",
    "            time.sleep(backoff ** attempt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e416e970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:46:59.453076Z",
     "iopub.status.busy": "2025-12-28T19:46:59.452789Z",
     "iopub.status.idle": "2025-12-28T19:47:29.996953Z",
     "shell.execute_reply": "2025-12-28T19:47:29.996297Z"
    },
    "papermill": {
     "duration": 31.315452,
     "end_time": "2025-12-28T19:47:30.391531",
     "exception": false,
     "start_time": "2025-12-28T19:46:59.076079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched and saved weather CSV to /kaggle/working/content/main-data/makueni_weather_2008_2025.csv\n"
     ]
    }
   ],
   "source": [
    "weather_csv = MAIN_DATA_DIR / \"makueni_weather_2008_2025.csv\"\n",
    "chunks = split_date_range(start_date, end_date, max_days=365)\n",
    "\n",
    "if ENABLE_REMOTE_CALLS:\n",
    "    dfs = []\n",
    "    for s, e in chunks:\n",
    "        payload = fetch_chunk(latitude, longitude, s, e, timezone=timezone)\n",
    "        daily = payload[\"daily\"]\n",
    "        df_chunk = pd.DataFrame({\n",
    "            \"date\": daily[\"time\"],\n",
    "            \"temp_max\": daily.get(\"temperature_2m_max\"),\n",
    "            \"temp_min\": daily.get(\"temperature_2m_min\"),\n",
    "            \"temp_mean\": daily.get(\"temperature_2m_mean\"),\n",
    "            \"humidity_mean\": daily.get(\"relative_humidity_2m_mean\"),\n",
    "            \"rainfall_mm\": daily.get(\"precipitation_sum\"),\n",
    "            \"wind_speed_max\": daily.get(\"wind_speed_10m_max\"),\n",
    "            \"cloud_cover_percent\": daily.get(\"cloudcover_mean\"),\n",
    "        })\n",
    "        dfs.append(df_chunk)\n",
    "        time.sleep(1)\n",
    "    weather_df = pd.concat(dfs, ignore_index=True)\n",
    "    weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "    weather_df.sort_values(\"date\", inplace=True)\n",
    "    weather_df.to_csv(weather_csv, index=False)\n",
    "    print(\"Fetched and saved weather CSV to\", weather_csv)\n",
    "else:\n",
    "    if weather_csv.exists():\n",
    "        weather_df = pd.read_csv(weather_csv, parse_dates=[\"date\"])\n",
    "        print(f\"Loaded cached weather data from {weather_csv}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{weather_csv} not found; enable ENABLE_REMOTE_CALLS to regenerate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8b171e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:31.229795Z",
     "iopub.status.busy": "2025-12-28T19:47:31.228901Z",
     "iopub.status.idle": "2025-12-28T19:47:31.243825Z",
     "shell.execute_reply": "2025-12-28T19:47:31.243121Z"
    },
    "papermill": {
     "duration": 0.395169,
     "end_time": "2025-12-28T19:47:31.245229",
     "exception": false,
     "start_time": "2025-12-28T19:47:30.850060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached NDVI data from /kaggle/input/makueni-ndvi-2008-2025-csv/makueni_ndvi_2008_2025.csv\n"
     ]
    }
   ],
   "source": [
    "ENABLE_REMOTE_CALLS = False  # Kaggle notebooks typically block outbound internet.\n",
    "ndvi_csv = \"/kaggle/input/makueni-ndvi-2008-2025-csv/makueni_ndvi_2008_2025.csv\"\n",
    "\n",
    "if ENABLE_REMOTE_CALLS:\n",
    "    try:\n",
    "        ee.Initialize()\n",
    "    except Exception:\n",
    "        print(\"Authenticating with Earth Engine...\")\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "\n",
    "    point = ee.Geometry.Point([longitude, latitude])\n",
    "    modis = ee.ImageCollection(\"MODIS/061/MOD13Q1\").select(\"NDVI\").filterDate(start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")).filterBounds(point)\n",
    "\n",
    "    def extract_ndvi(image):\n",
    "        mean = image.reduceRegion(reducer=ee.Reducer.mean(), geometry=point, scale=250).get(\"NDVI\")\n",
    "        date = image.date().format(\"YYYY-MM-dd\")\n",
    "        return ee.Feature(None, {\"date\": date, \"ndvi_mean\": mean})\n",
    "\n",
    "    ndvi_fc = modis.map(extract_ndvi).getInfo()\n",
    "    records = [f[\"properties\"] for f in ndvi_fc[\"features\"]]\n",
    "    ndvi_df = pd.DataFrame(records)\n",
    "    ndvi_df[\"date\"] = pd.to_datetime(ndvi_df[\"date\"])\n",
    "    ndvi_df[\"ndvi_mean\"] = ndvi_df[\"ndvi_mean\"].astype(float) / 10000\n",
    "    ndvi_df.to_csv(ndvi_csv, index=False)\n",
    "    print(\"Fetched NDVI and saved to\", ndvi_csv)\n",
    "else:\n",
    "    if ndvi_csv:\n",
    "        ndvi_df = pd.read_csv(ndvi_csv, parse_dates=[\"date\"])\n",
    "        print(f\"Loaded cached NDVI data from {ndvi_csv}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{ndvi_csv} not found; enable ENABLE_REMOTE_CALLS to regenerate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28e392b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:32.007653Z",
     "iopub.status.busy": "2025-12-28T19:47:32.007336Z",
     "iopub.status.idle": "2025-12-28T19:47:32.025222Z",
     "shell.execute_reply": "2025-12-28T19:47:32.024389Z"
    },
    "papermill": {
     "duration": 0.402065,
     "end_time": "2025-12-28T19:47:32.026732",
     "exception": false,
     "start_time": "2025-12-28T19:47:31.624667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather+NDVI rows: (6549, 9)\n"
     ]
    }
   ],
   "source": [
    "df_weather = weather_df.copy()\n",
    "df_ndvi = ndvi_df.copy()\n",
    "df_weather['date'] = pd.to_datetime(df_weather['date'])\n",
    "df_ndvi['date'] = pd.to_datetime(df_ndvi['date'])\n",
    "df_merged = pd.merge(df_weather, df_ndvi, on='date', how='left').sort_values('date')\n",
    "weather_full = df_merged.copy()\n",
    "print('Weather+NDVI rows:', weather_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4695df81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:32.866121Z",
     "iopub.status.busy": "2025-12-28T19:47:32.865807Z",
     "iopub.status.idle": "2025-12-28T19:47:32.914500Z",
     "shell.execute_reply": "2025-12-28T19:47:32.913656Z"
    },
    "papermill": {
     "duration": 0.50936,
     "end_time": "2025-12-28T19:47:32.916003",
     "exception": false,
     "start_time": "2025-12-28T19:47:32.406643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved climate feature table -> /kaggle/working/content/main-data/makueni_climate_features.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>humidity_mean</th>\n",
       "      <th>rainfall_mm</th>\n",
       "      <th>wind_speed_max</th>\n",
       "      <th>cloud_cover_percent</th>\n",
       "      <th>ndvi_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>24.9</td>\n",
       "      <td>16.4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>74</td>\n",
       "      <td>1.2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>25.8</td>\n",
       "      <td>14.1</td>\n",
       "      <td>20.2</td>\n",
       "      <td>71</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>27.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-04</td>\n",
       "      <td>27.6</td>\n",
       "      <td>15.4</td>\n",
       "      <td>22.2</td>\n",
       "      <td>63</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-05</td>\n",
       "      <td>27.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>75</td>\n",
       "      <td>2.9</td>\n",
       "      <td>13.1</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  temp_max  temp_min  temp_mean  humidity_mean  rainfall_mm  \\\n",
       "0 2008-01-01      24.9      16.4       20.3             74          1.2   \n",
       "1 2008-01-02      25.8      14.1       20.2             71          0.8   \n",
       "2 2008-01-03      27.2      15.2       21.3             65          0.0   \n",
       "3 2008-01-04      27.6      15.4       22.2             63          0.1   \n",
       "4 2008-01-05      27.3      15.2       21.0             75          2.9   \n",
       "\n",
       "   wind_speed_max  cloud_cover_percent  ndvi_mean  \n",
       "0            15.1                   53     0.6805  \n",
       "1            14.3                   19        NaN  \n",
       "2            12.8                   11        NaN  \n",
       "3            12.2                   26        NaN  \n",
       "4            13.1                   58        NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = weather_full.copy()\n",
    "merged_path = MAIN_DATA_DIR / \"makueni_climate_features.csv\"\n",
    "merged.to_csv(merged_path, index=False)\n",
    "print(\"Saved climate feature table ->\", merged_path)\n",
    "merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01273ca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:33.707092Z",
     "iopub.status.busy": "2025-12-28T19:47:33.706812Z",
     "iopub.status.idle": "2025-12-28T19:47:33.712080Z",
     "shell.execute_reply": "2025-12-28T19:47:33.710708Z"
    },
    "papermill": {
     "duration": 0.403293,
     "end_time": "2025-12-28T19:47:33.714903",
     "exception": false,
     "start_time": "2025-12-28T19:47:33.311610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather+NDVI rows: (6549, 9)\n"
     ]
    }
   ],
   "source": [
    "weather_full = df_merged.copy()\n",
    "print('Weather+NDVI rows:', weather_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "038d1fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:34.576709Z",
     "iopub.status.busy": "2025-12-28T19:47:34.576427Z",
     "iopub.status.idle": "2025-12-28T19:47:34.837683Z",
     "shell.execute_reply": "2025-12-28T19:47:34.837136Z"
    },
    "papermill": {
     "duration": 0.645188,
     "end_time": "2025-12-28T19:47:34.839174",
     "exception": false,
     "start_time": "2025-12-28T19:47:34.193986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_month = df_merged.set_index(\"date\").resample(\"ME\").agg({\n",
    "    \"rainfall_mm\": \"sum\",\n",
    "    \"temp_mean\": \"mean\",\n",
    "    \"humidity_mean\": \"mean\",\n",
    "    \"ndvi_mean\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "axes[0].plot(df_month[\"date\"], df_month[\"rainfall_mm\"], marker=\"o\")\n",
    "axes[0].set_title(\"Monthly Rainfall (mm)\")\n",
    "\n",
    "axes[1].plot(df_month[\"date\"], df_month[\"temp_mean\"], marker=\"o\", color=\"tomato\")\n",
    "axes[1].set_title(\"Monthly Mean Temperature (°C)\")\n",
    "\n",
    "axes[2].plot(df_month[\"date\"], df_month[\"ndvi_mean\"], marker=\"o\", color=\"green\")\n",
    "axes[2].set_title(\"Monthly NDVI Mean\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylabel(\"Value\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d65cd",
   "metadata": {
    "papermill": {
     "duration": 0.382324,
     "end_time": "2025-12-28T19:47:35.604856",
     "exception": false,
     "start_time": "2025-12-28T19:47:35.222532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Climate Feature Extraction\n",
    "\n",
    "Derive clean hourly climate+NDVI features ready for inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a2a6489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:36.462636Z",
     "iopub.status.busy": "2025-12-28T19:47:36.462327Z",
     "iopub.status.idle": "2025-12-28T19:47:36.476430Z",
     "shell.execute_reply": "2025-12-28T19:47:36.475685Z"
    },
    "papermill": {
     "duration": 0.476098,
     "end_time": "2025-12-28T19:47:36.477764",
     "exception": false,
     "start_time": "2025-12-28T19:47:36.001666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate feature frame: (6549, 4)\n",
      "Proxy feature frame: (6549, 5)\n"
     ]
    }
   ],
   "source": [
    "climate_features = df_merged[['date','rainfall_mm','temp_mean','humidity_mean','ndvi_mean']].copy()\n",
    "climate_features = climate_features.sort_values('date').set_index('date')\n",
    "climate_features = climate_features.interpolate(limit_direction='both')\n",
    "proxy_features = pd.DataFrame(index=climate_features.index)\n",
    "proxy_features['weight'] = climate_features['rainfall_mm']\n",
    "proxy_features['temperature'] = climate_features['temp_mean']\n",
    "proxy_features['humidity'] = climate_features['humidity_mean']\n",
    "proxy_features['flow'] = climate_features['ndvi_mean']\n",
    "proxy_features['weight_delta_24h'] = proxy_features['weight'].diff(24).fillna(0)\n",
    "print('Climate feature frame:', climate_features.shape)\n",
    "print('Proxy feature frame:', proxy_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e95d13c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:37.241390Z",
     "iopub.status.busy": "2025-12-28T19:47:37.241069Z",
     "iopub.status.idle": "2025-12-28T19:47:37.245274Z",
     "shell.execute_reply": "2025-12-28T19:47:37.244554Z"
    },
    "papermill": {
     "duration": 0.388292,
     "end_time": "2025-12-28T19:47:37.246981",
     "exception": false,
     "start_time": "2025-12-28T19:47:36.858689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890b431",
   "metadata": {
    "papermill": {
     "duration": 0.436814,
     "end_time": "2025-12-28T19:47:38.164264",
     "exception": false,
     "start_time": "2025-12-28T19:47:37.727450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Würzburg Dataset Staging\n",
    "\n",
    "On Kaggle, stage the Würzburg datasets just like the acoustic source: attach a dataset named `wurzb-hive-telemetry` (or similar) under `/kaggle/input`, then copy it into `content/wurzburg/` so the pretraining block can load from both local runs and Kaggle sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe793840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:38.948783Z",
     "iopub.status.busy": "2025-12-28T19:47:38.948497Z",
     "iopub.status.idle": "2025-12-28T19:47:41.041227Z",
     "shell.execute_reply": "2025-12-28T19:47:41.040421Z"
    },
    "papermill": {
     "duration": 2.474814,
     "end_time": "2025-12-28T19:47:41.042821",
     "exception": false,
     "start_time": "2025-12-28T19:47:38.568007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staged Würzburg telemetry from /kaggle/input/bee-hive-metrics -> /kaggle/working/content/bee-hive-metrics\n"
     ]
    }
   ],
   "source": [
    "WURZBURG_INPUT_ROOT = Path('/kaggle/input')\n",
    "WURZBURG_TARGET = CONTENT_ROOT / 'bee-hive-metrics'\n",
    "if WURZBURG_INPUT_ROOT.exists():\n",
    "    candidates = [p for p in WURZBURG_INPUT_ROOT.iterdir() if 'bee-hive-metrics' in p.name.lower() or 'bee-hive-metrics' in p.name.lower()]\n",
    "    if candidates:\n",
    "        source = candidates[0]\n",
    "        WURZBURG_TARGET.mkdir(parents=True, exist_ok=True)\n",
    "        for csv_path in source.glob('*.csv'):\n",
    "            target_path = WURZBURG_TARGET / csv_path.name\n",
    "            if not target_path.exists():\n",
    "                shutil.copy(csv_path, target_path)\n",
    "        print(f\"Staged Würzburg telemetry from {source} -> {WURZBURG_TARGET}\")\n",
    "    else:\n",
    "        print('No Würzburg dataset attached under /kaggle/input; using existing content/wurzburg if present.')\n",
    "else:\n",
    "    WURZBURG_TARGET.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1807bf7b",
   "metadata": {
    "papermill": {
     "duration": 0.458985,
     "end_time": "2025-12-28T19:47:41.880456",
     "exception": false,
     "start_time": "2025-12-28T19:47:41.421471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Würzburg/Schwartau Hive Telemetry Pretraining\n",
    "\n",
    "To ground our synthetic Makueni logs in real telemetry, we ingest the Würzburg/Schwartau sensor datasets (`content/wurzburg/*`). These CSVs provide minute-level hive weight, entrance flow, and local temperature/humidity measurements from 2017–2019. We aggregate them into hourly/daily features, derive proxy yield/ stress labels via rolling weight deltas, and use them to pretrain the tabular and sequence models before adapting to Makueni's climate distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b78bc05a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:42.654345Z",
     "iopub.status.busy": "2025-12-28T19:47:42.654037Z",
     "iopub.status.idle": "2025-12-28T19:47:46.365434Z",
     "shell.execute_reply": "2025-12-28T19:47:46.364609Z"
    },
    "papermill": {
     "duration": 4.09559,
     "end_time": "2025-12-28T19:47:46.367193",
     "exception": false,
     "start_time": "2025-12-28T19:47:42.271603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensors: {'weight': (1035861, 1), 'temperature': (958831, 1), 'humidity': (20845, 1), 'flow': (2071720, 1)}\n",
      "Hourly feature set: (20865, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>weight</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>flow</th>\n",
       "      <th>weight_delta_24h</th>\n",
       "      <th>yield_positive</th>\n",
       "      <th>stress_event</th>\n",
       "      <th>yield_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 05:00:00</td>\n",
       "      <td>52.695098</td>\n",
       "      <td>-0.327590</td>\n",
       "      <td>92.406667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 06:00:00</td>\n",
       "      <td>52.685200</td>\n",
       "      <td>-0.409250</td>\n",
       "      <td>92.270000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 07:00:00</td>\n",
       "      <td>52.688667</td>\n",
       "      <td>-0.668364</td>\n",
       "      <td>92.575000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 08:00:00</td>\n",
       "      <td>52.674267</td>\n",
       "      <td>-0.966858</td>\n",
       "      <td>92.840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 09:00:00</td>\n",
       "      <td>52.595320</td>\n",
       "      <td>-1.623189</td>\n",
       "      <td>93.640000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp     weight  temperature   humidity  flow  \\\n",
       "0 2017-01-01 05:00:00  52.695098    -0.327590  92.406667   0.0   \n",
       "1 2017-01-01 06:00:00  52.685200    -0.409250  92.270000   0.0   \n",
       "2 2017-01-01 07:00:00  52.688667    -0.668364  92.575000   0.0   \n",
       "3 2017-01-01 08:00:00  52.674267    -0.966858  92.840000   0.0   \n",
       "4 2017-01-01 09:00:00  52.595320    -1.623189  93.640000   0.0   \n",
       "\n",
       "   weight_delta_24h  yield_positive  stress_event  yield_kg  \n",
       "0               NaN               0             0  0.000000  \n",
       "1               NaN               0             0  0.000000  \n",
       "2               NaN               0             0  0.003467  \n",
       "3               NaN               0             0  0.003467  \n",
       "4               NaN               0             0  0.003467  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "WURZBURG_DIR = CONTENT_ROOT / 'bee-hive-metrics'\n",
    "if not WURZBURG_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Missing Würzburg data at {WURZBURG_DIR}\")\n",
    "# Helper loader keeps timestamps sorted for consistent resampling\n",
    "def load_sensor(name):\n",
    "    path = WURZBURG_DIR / name\n",
    "    df = pd.read_csv(path, parse_dates=['timestamp'])\n",
    "    df = df.sort_values('timestamp').set_index('timestamp')\n",
    "    return df\n",
    "weight_df = load_sensor('weight_wurzburg.csv')\n",
    "temp_df = load_sensor('temperature_wurzburg.csv')\n",
    "humidity_df = load_sensor('humidity_wurzburg.csv')\n",
    "flow_df = load_sensor('flow_wurzburg.csv')\n",
    "print('Loaded sensors:', {\n",
    "    'weight': weight_df.shape,\n",
    "    'temperature': temp_df.shape,\n",
    "    'humidity': humidity_df.shape,\n",
    "    'flow': flow_df.shape\n",
    "})\n",
    "# Resample to hourly means and align\n",
    "hourly = pd.DataFrame({\n",
    "    'weight': weight_df['weight'].resample('1H').mean(),\n",
    "    'temperature': temp_df['temperature'].resample('1H').mean(),\n",
    "    'humidity': humidity_df['humidity'].resample('1H').mean(),\n",
    "    'flow': flow_df['flow'].resample('1H').mean(),\n",
    "})\n",
    "hourly = hourly.interpolate(limit_direction='both')\n",
    "# Derive proxy labels: positive weight change over 24h indicates nectar intake (yield), negative sustained drop indicates stress/harvest\n",
    "hourly['weight_delta_24h'] = hourly['weight'].diff(24)\n",
    "hourly['yield_positive'] = (hourly['weight_delta_24h'] > 0.5).astype(int)\n",
    "hourly['stress_event'] = (hourly['weight_delta_24h'] < -1.0).astype(int)\n",
    "hourly['yield_kg'] = hourly['weight'].diff().clip(lower=0).rolling(24, min_periods=1).sum().fillna(0)\n",
    "hourly.reset_index(inplace=True)\n",
    "print('Hourly feature set:', hourly.shape)\n",
    "hourly.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e80f02",
   "metadata": {
    "papermill": {
     "duration": 0.384176,
     "end_time": "2025-12-28T19:47:47.216907",
     "exception": false,
     "start_time": "2025-12-28T19:47:46.832731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Würzburg Yield Regression Pretraining\n",
    "\n",
    "We regress 24-hour rolling weight gains (`yield_kg`) against the sensor features to approximate honey output. The resulting HistGradientBoostingRegressor initializes the climate-only yield forecast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c554ee08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:47.973160Z",
     "iopub.status.busy": "2025-12-28T19:47:47.972517Z",
     "iopub.status.idle": "2025-12-28T19:47:48.558604Z",
     "shell.execute_reply": "2025-12-28T19:47:48.557854Z"
    },
    "papermill": {
     "duration": 0.967749,
     "end_time": "2025-12-28T19:47:48.560076",
     "exception": false,
     "start_time": "2025-12-28T19:47:47.592327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yield R^2: 0.7969711452314046\n",
      "Yield MAE: 0.5023884250479205\n",
      "Saved Würzburg yield regressor -> /kaggle/working/content/main-data/wurzb_hgb_yield_reg.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "feature_cols_w = ['weight', 'temperature', 'humidity', 'flow', 'weight_delta_24h']\n",
    "X_w = hourly[feature_cols_w].fillna(method='ffill').fillna(method='bfill')\n",
    "y_w = hourly['yield_kg']\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(\n",
    "    X_w, y_w, test_size=0.2, random_state=42\n",
    ")\n",
    "yield_regressor = HistGradientBoostingRegressor(max_depth=6, learning_rate=0.08, max_iter=300)\n",
    "yield_regressor.fit(X_train_w, y_train_w)\n",
    "y_pred_w = yield_regressor.predict(X_test_w)\n",
    "print('Yield R^2:', r2_score(y_test_w, y_pred_w))\n",
    "print('Yield MAE:', mean_absolute_error(y_test_w, y_pred_w))\n",
    "WURZBURG_MODEL_PATH = MAIN_DATA_DIR / 'wurzb_hgb_yield_reg.pkl'\n",
    "pd.to_pickle(yield_regressor, WURZBURG_MODEL_PATH)\n",
    "print('Saved Würzburg yield regressor ->', WURZBURG_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec425c",
   "metadata": {
    "papermill": {
     "duration": 0.472066,
     "end_time": "2025-12-28T19:47:49.418031",
     "exception": false,
     "start_time": "2025-12-28T19:47:48.945965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Würzburg Yield Inference\n",
    "\n",
    "Apply the pretrained HGB regressor to climate features to estimate kg/day trajectories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e163759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:50.189771Z",
     "iopub.status.busy": "2025-12-28T19:47:50.189255Z",
     "iopub.status.idle": "2025-12-28T19:47:50.295045Z",
     "shell.execute_reply": "2025-12-28T19:47:50.294333Z"
    },
    "papermill": {
     "duration": 0.49474,
     "end_time": "2025-12-28T19:47:50.296532",
     "exception": false,
     "start_time": "2025-12-28T19:47:49.801792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved climate yield forecast -> /kaggle/working/content/main-data/makueni_climate_yield_forecast.csv\n"
     ]
    }
   ],
   "source": [
    "WURZBURG_MODEL_PATH = MAIN_DATA_DIR / 'wurzb_hgb_yield_reg.pkl'\n",
    "if not WURZBURG_MODEL_PATH.exists():\n",
    "    raise FileNotFoundError('Pretrained Würzburg HGB missing')\n",
    "yield_regressor = pd.read_pickle(WURZBURG_MODEL_PATH)\n",
    "climate_X = proxy_features[['weight','temperature','humidity','flow','weight_delta_24h']]\n",
    "yield_kg_pred = yield_regressor.predict(climate_X)\n",
    "proxy_features['predicted_yield_kg'] = yield_kg_pred\n",
    "yield_forecast_path = MAIN_DATA_DIR / 'makueni_climate_yield_forecast.csv'\n",
    "proxy_features[['predicted_yield_kg']].to_csv(yield_forecast_path, index_label='date')\n",
    "print('Saved climate yield forecast ->', yield_forecast_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "903613dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:51.151742Z",
     "iopub.status.busy": "2025-12-28T19:47:51.151005Z",
     "iopub.status.idle": "2025-12-28T19:47:51.584555Z",
     "shell.execute_reply": "2025-12-28T19:47:51.583673Z"
    },
    "papermill": {
     "duration": 0.821832,
     "end_time": "2025-12-28T19:47:51.586123",
     "exception": false,
     "start_time": "2025-12-28T19:47:50.764291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved climate yield artifacts -> /kaggle/working/figures/climate_yield_forecast.png /kaggle/working/figures/climate_yield_metrics.json\n"
     ]
    }
   ],
   "source": [
    "yield_forecast = pd.read_csv(yield_forecast_path, index_col=0, parse_dates=True)\n",
    "yield_fig, ax = plt.subplots(figsize=(10, 3))\n",
    "ax.plot(yield_forecast.index, yield_forecast['predicted_yield_kg'], label='Predicted yield (kg/day)')\n",
    "ax.set_title('Climate-informed Yield Forecast')\n",
    "ax.set_ylabel('kg per day')\n",
    "ax.legend()\n",
    "yield_plot_path = FIGURE_DIR / 'climate_yield_forecast.png'\n",
    "yield_fig.savefig(yield_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "yield_metrics_path = FIGURE_DIR / 'climate_yield_metrics.json'\n",
    "yield_metrics_path.write_text(json.dumps({'mean_kg_per_day': float(yield_forecast['predicted_yield_kg'].mean()), 'total_kg': float(yield_forecast['predicted_yield_kg'].sum())}, indent=2))\n",
    "print('Saved climate yield artifacts ->', yield_plot_path, yield_metrics_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6387927",
   "metadata": {
    "papermill": {
     "duration": 0.385708,
     "end_time": "2025-12-28T19:47:52.352603",
     "exception": false,
     "start_time": "2025-12-28T19:47:51.966895",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Transfer to Makueni Tabular Model\n",
    "\n",
    "We reuse the Würzburg-trained gradient boosting model as initialization for the Makueni stress prediction: load `wurzb_hgb_yield.pkl`, continue training on the Makueni feature matrix, and compare against training-from-scratch baselines. This simple warm-start helps incorporate learned environmental response patterns despite limited local telemetry.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf1781",
   "metadata": {
    "papermill": {
     "duration": 0.467776,
     "end_time": "2025-12-28T19:47:53.200377",
     "exception": false,
     "start_time": "2025-12-28T19:47:52.732601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Würzburg Sequence Pretraining\n",
    "\n",
    "We also slice the Würzburg hourly features into temporal windows to pretrain the PyTorch sequence backbone. This yields a model familiar with real hive dynamics before fine-tuning on Makueni's synthetic/log-based sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dac7ab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:54.001166Z",
     "iopub.status.busy": "2025-12-28T19:47:54.000545Z",
     "iopub.status.idle": "2025-12-28T19:47:54.009954Z",
     "shell.execute_reply": "2025-12-28T19:47:54.009358Z"
    },
    "papermill": {
     "duration": 0.421946,
     "end_time": "2025-12-28T19:47:54.011283",
     "exception": false,
     "start_time": "2025-12-28T19:47:53.589337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HiveCNNBaseline(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x.squeeze(-1)\n",
    "class HiveCNNRecurrent(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(128)\n",
    "        self.gru = nn.GRU(128, 64, batch_first=True, bidirectional=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.layer_norm(x)\n",
    "        _, h_n = self.gru(x)\n",
    "        h_n = h_n.transpose(0, 1).reshape(x.size(0), -1)\n",
    "        x = self.classifier(h_n)\n",
    "        return x.squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e11e2ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:47:54.854924Z",
     "iopub.status.busy": "2025-12-28T19:47:54.854350Z",
     "iopub.status.idle": "2025-12-28T19:48:06.204161Z",
     "shell.execute_reply": "2025-12-28T19:48:06.203317Z"
    },
    "papermill": {
     "duration": 11.73274,
     "end_time": "2025-12-28T19:48:06.205644",
     "exception": false,
     "start_time": "2025-12-28T19:47:54.472904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Würzburg sequences: (20817, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Slice Würzburg hourly features into fixed windows for sequence pretraining\n",
    "WURZ_WINDOW = 24\n",
    "sequence_cols_w = ['weight', 'temperature', 'humidity', 'flow', 'weight_delta_24h']\n",
    "wurz_sequences = []\n",
    "wurz_labels = []\n",
    "for i in range(WURZ_WINDOW, len(hourly)):\n",
    "    window = hourly.iloc[i-WURZ_WINDOW:i][sequence_cols_w].values\n",
    "    label = hourly.iloc[i]['yield_positive']\n",
    "    if not np.any(np.isnan(window)):\n",
    "        wurz_sequences.append(window)\n",
    "        wurz_labels.append(label)\n",
    "\n",
    "wurz_sequences = np.array(wurz_sequences, dtype=np.float32)\n",
    "wurz_labels = np.array(wurz_labels, dtype=np.float32)\n",
    "print('Würzburg sequences:', wurz_sequences.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c8fb6a",
   "metadata": {
    "papermill": {
     "duration": 0.380709,
     "end_time": "2025-12-28T19:48:06.967777",
     "exception": false,
     "start_time": "2025-12-28T19:48:06.587068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Pretraining the Temporal CNN\n",
    "\n",
    "We reuse the `SEQUENCE_MODEL_VARIANT='cnn'` architecture to pretrain on the Würzburg sequences, save the weights, and later load them as initialization for the Makueni sequence training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b976aba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:48:07.808540Z",
     "iopub.status.busy": "2025-12-28T19:48:07.808268Z",
     "iopub.status.idle": "2025-12-28T19:48:24.697349Z",
     "shell.execute_reply": "2025-12-28T19:48:24.696466Z"
    },
    "papermill": {
     "duration": 17.352522,
     "end_time": "2025-12-28T19:48:24.698915",
     "exception": false,
     "start_time": "2025-12-28T19:48:07.346393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining sequence model on Würzburg data...\n",
      "Epoch 01: train_loss=0.7125 AUC=0.914 | val_loss=0.4946 AUC=0.956\n",
      "Epoch 02: train_loss=0.5157 AUC=0.951 | val_loss=0.4517 AUC=0.958\n",
      "Epoch 03: train_loss=0.4216 AUC=0.965 | val_loss=0.4512 AUC=0.965\n",
      "Epoch 04: train_loss=0.4140 AUC=0.966 | val_loss=0.4460 AUC=0.968\n",
      "Epoch 05: train_loss=0.3819 AUC=0.971 | val_loss=0.4729 AUC=0.967\n",
      "Epoch 06: train_loss=0.3549 AUC=0.976 | val_loss=0.5201 AUC=0.967\n",
      "Epoch 07: train_loss=0.3250 AUC=0.981 | val_loss=0.5403 AUC=0.969\n",
      "Epoch 08: train_loss=0.3854 AUC=0.974 | val_loss=0.3139 AUC=0.980\n",
      "Epoch 09: train_loss=0.3154 AUC=0.982 | val_loss=0.3450 AUC=0.978\n",
      "Epoch 10: train_loss=0.3404 AUC=0.979 | val_loss=0.3460 AUC=0.980\n",
      "Epoch 11: train_loss=0.2839 AUC=0.985 | val_loss=0.5007 AUC=0.969\n",
      "Epoch 12: train_loss=0.2683 AUC=0.987 | val_loss=0.4152 AUC=0.975\n",
      "Epoch 13: train_loss=0.2875 AUC=0.984 | val_loss=0.4097 AUC=0.981\n",
      "Epoch 14: train_loss=0.2697 AUC=0.986 | val_loss=0.7385 AUC=0.971\n",
      "Epoch 15: train_loss=0.2225 AUC=0.990 | val_loss=0.2932 AUC=0.984\n",
      "Epoch 16: train_loss=0.2356 AUC=0.989 | val_loss=0.7454 AUC=0.964\n",
      "Epoch 17: train_loss=0.2513 AUC=0.988 | val_loss=0.2465 AUC=0.988\n",
      "Epoch 18: train_loss=0.2177 AUC=0.990 | val_loss=0.2893 AUC=0.988\n",
      "Epoch 19: train_loss=0.2220 AUC=0.990 | val_loss=0.3476 AUC=0.980\n",
      "Epoch 20: train_loss=0.2003 AUC=0.992 | val_loss=0.2808 AUC=0.988\n",
      "Saved Würzburg sequence weights -> /kaggle/working/content/main-data/wurzburg_sequence_pretrain.pt\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Lightweight dataset wrapper so PyTorch loaders can stream Würzburg sequences\n",
    "class WurzburgDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.X = torch.tensor(sequences, dtype=torch.float32)\n",
    "        self.y = torch.tensor(labels, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "X_train_wseq, X_val_wseq, y_train_wseq, y_val_wseq = train_test_split(\n",
    "    wurz_sequences, wurz_labels, test_size=0.2, random_state=42, stratify=wurz_labels)\n",
    "\n",
    "w_train_ds = WurzburgDataset(X_train_wseq, y_train_wseq)\n",
    "w_val_ds = WurzburgDataset(X_val_wseq, y_val_wseq)\n",
    "w_train_loader = DataLoader(w_train_ds, batch_size=128, shuffle=True)\n",
    "w_val_loader = DataLoader(w_val_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "pretrain_model = HiveCNNBaseline(input_channels=len(sequence_cols_w)).to(device)\n",
    "pretrain_optimizer = torch.optim.Adam(pretrain_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "pretrain_criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor((len(y_train_wseq)-y_train_wseq.sum())/max(y_train_wseq.sum(),1), device=device))\n",
    "\n",
    "def run_pretrain_epoch(loader, train=True):\n",
    "    pretrain_model.train(train)\n",
    "    total_loss=0\n",
    "    preds=[]\n",
    "    targets=[]\n",
    "    for batch_X, batch_y in loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        pretrain_optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = pretrain_model(batch_X)\n",
    "            loss = pretrain_criterion(logits, batch_y)\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                pretrain_optimizer.step()\n",
    "        total_loss += loss.item()*batch_X.size(0)\n",
    "        preds.append(torch.sigmoid(logits).detach().cpu().numpy())\n",
    "        targets.append(batch_y.detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "    return total_loss/len(loader.dataset), roc_auc_score(targets, preds)\n",
    "\n",
    "# Train for a few epochs and persist the best validation AUC weights\n",
    "print('Pretraining sequence model on Würzburg data...')\n",
    "best_auc = 0\n",
    "for epoch in range(20):\n",
    "    train_loss, train_auc = run_pretrain_epoch(w_train_loader, True)\n",
    "    val_loss, val_auc = run_pretrain_epoch(w_val_loader, False)\n",
    "    print(f'Epoch {epoch+1:02d}: train_loss={train_loss:.4f} AUC={train_auc:.3f} | val_loss={val_loss:.4f} AUC={val_auc:.3f}')\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        torch.save(pretrain_model.state_dict(), MAIN_DATA_DIR / 'wurzburg_sequence_pretrain.pt')\n",
    "print('Saved Würzburg sequence weights ->', MAIN_DATA_DIR / 'wurzburg_sequence_pretrain.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41645332",
   "metadata": {
    "papermill": {
     "duration": 0.409698,
     "end_time": "2025-12-28T19:48:25.491977",
     "exception": false,
     "start_time": "2025-12-28T19:48:25.082279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Würzburg CNN Inference\n",
    "\n",
    "Convert climate sequences to windows and run the pretrained CNN to estimate occupancy risk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16d86e81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:48:26.346702Z",
     "iopub.status.busy": "2025-12-28T19:48:26.346131Z",
     "iopub.status.idle": "2025-12-28T19:48:29.782687Z",
     "shell.execute_reply": "2025-12-28T19:48:29.781857Z"
    },
    "papermill": {
     "duration": 3.821526,
     "end_time": "2025-12-28T19:48:29.784421",
     "exception": false,
     "start_time": "2025-12-28T19:48:25.962895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate sequences: (6525, 24, 5)\n",
      "Saved occupancy forecast -> /kaggle/working/content/main-data/makueni_climate_occupancy_forecast.csv\n"
     ]
    }
   ],
   "source": [
    "WINDOW = 24  # match Würzburg pretraining window\n",
    "climate_sequences = []\n",
    "for i in range(WINDOW, len(proxy_features)):\n",
    "    window = proxy_features.iloc[i-WINDOW:i][['weight','temperature','humidity','flow','weight_delta_24h']].values\n",
    "    if not np.any(np.isnan(window)):\n",
    "        climate_sequences.append(window)\n",
    "climate_sequences = np.array(climate_sequences, dtype=np.float32)\n",
    "print('Climate sequences:', climate_sequences.shape)\n",
    "cnn_model = HiveCNNBaseline(climate_sequences.shape[-1]).to(device)\n",
    "pretrain_path = MAIN_DATA_DIR / 'wurzburg_sequence_pretrain.pt'\n",
    "cnn_model.load_state_dict(torch.load(pretrain_path, map_location=device), strict=False)\n",
    "cnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    occupancy = torch.sigmoid(cnn_model(torch.tensor(climate_sequences).to(device))).cpu().numpy()\n",
    "forecast = proxy_features.iloc[WINDOW:].copy()\n",
    "forecast['occupancy_risk'] = occupancy\n",
    "climate_forecast_path = MAIN_DATA_DIR / 'makueni_climate_occupancy_forecast.csv'\n",
    "forecast[['occupancy_risk']].to_csv(climate_forecast_path, index_label='date')\n",
    "print('Saved occupancy forecast ->', climate_forecast_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e307afb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:48:30.593695Z",
     "iopub.status.busy": "2025-12-28T19:48:30.593397Z",
     "iopub.status.idle": "2025-12-28T19:48:31.004877Z",
     "shell.execute_reply": "2025-12-28T19:48:31.004048Z"
    },
    "papermill": {
     "duration": 0.817617,
     "end_time": "2025-12-28T19:48:31.006527",
     "exception": false,
     "start_time": "2025-12-28T19:48:30.188910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved climate occupancy artifacts -> /kaggle/working/figures/climate_occupancy_forecast.png /kaggle/working/figures/climate_occupancy_metrics.json\n"
     ]
    }
   ],
   "source": [
    "occupancy_forecast = pd.read_csv(climate_forecast_path, index_col=0, parse_dates=True)\n",
    "occ_fig, ax = plt.subplots(figsize=(10, 3))\n",
    "ax.plot(occupancy_forecast.index, occupancy_forecast['occupancy_risk'], label='Occupancy risk')\n",
    "ax.set_title('Climate-informed Occupancy Risk')\n",
    "ax.set_ylabel('Risk')\n",
    "ax.legend()\n",
    "occ_plot_path = FIGURE_DIR / 'climate_occupancy_forecast.png'\n",
    "occ_fig.savefig(occ_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "occ_metrics_path = FIGURE_DIR / 'climate_occupancy_metrics.json'\n",
    "occ_metrics_path.write_text(json.dumps({'mean_risk': float(occupancy_forecast['occupancy_risk'].mean())}, indent=2))\n",
    "print('Saved climate occupancy artifacts ->', occ_plot_path, occ_metrics_path)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 166904,
     "sourceId": 461059,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7505074,
     "sourceId": 12134294,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9120225,
     "sourceId": 14288414,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5825.87788,
   "end_time": "2025-12-28T19:48:34.934844",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-28T18:11:29.056964",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "342295a7420147b9bfd0234464bd61d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": "140px",
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "3cba829b64794ff393378f20f0a0ad3f": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.20",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module": "jupyter-leaflet",
       "_model_module_version": "^0.20",
       "_model_name": "LeafletAttributionControlModel",
       "_view_count": null,
       "_view_module": "jupyter-leaflet",
       "_view_module_version": "^0.20",
       "_view_name": "LeafletAttributionControlView",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "ipyleaflet"
      }
     },
     "4286b31434744652b7023ef3a54993e3": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.20",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module": "jupyter-leaflet",
       "_model_module_version": "^0.20",
       "_model_name": "LeafletZoomControlModel",
       "_view_count": null,
       "_view_module": "jupyter-leaflet",
       "_view_module_version": "^0.20",
       "_view_name": "LeafletZoomControlView",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ],
       "position": "topleft",
       "zoom_in_text": "+",
       "zoom_in_title": "Zoom in",
       "zoom_out_text": "-",
       "zoom_out_title": "Zoom out"
      }
     },
     "47a46475bdd540cca6d92e51bcefeca5": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.20",
      "model_name": "LeafletDrawControlModel",
      "state": {
       "_model_module": "jupyter-leaflet",
       "_model_module_version": "^0.20",
       "_model_name": "LeafletDrawControlModel",
       "_view_count": null,
       "_view_module": "jupyter-leaflet",
       "_view_module_version": "^0.20",
       "_view_name": "LeafletDrawControlView",
       "circle": {},
       "circlemarker": {},
       "data": [],
       "edit": true,
       "marker": {},
       "options": [
        "position"
       ],
       "polygon": {
        "shapeOptions": {
         "color": "#2563eb",
         "fillOpacity": 0.2,
         "weight": 2
        }
       },
       "polyline": {},
       "position": "topleft",
       "rectangle": {
        "shapeOptions": {
         "color": "#f97316",
         "fillOpacity": 0.15,
         "weight": 2
        }
       },
       "remove": true
      }
     },
     "47e479eb32564d52985aef099ecd4aab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5133ddedc0164eddb71f7e7388eaa30d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "TextareaModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "TextareaModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "TextareaView",
       "continuous_update": true,
       "description": "Geometry",
       "description_allow_html": false,
       "disabled": true,
       "layout": "IPY_MODEL_342295a7420147b9bfd0234464bd61d8",
       "placeholder": "Draw a polygon/rectangle on the map.",
       "rows": null,
       "style": "IPY_MODEL_aef0414725dd479ead9ab16b9f09ba2b",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "59c377c409804e788979c59a2f7b6092": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f51661568064f9da1b909898f500cc6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6fc929f844c8457f881a4f517c1e3d11": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.20",
      "model_name": "LeafletMapStyleModel",
      "state": {
       "_model_module": "jupyter-leaflet",
       "_model_module_version": "^0.20",
       "_model_name": "LeafletMapStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "cursor": "grab"
      }
     },
     "75f8d5aaa08d4a24801e30851569a6d4": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.20",
      "model_name": "LeafletMapModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "jupyter-leaflet",
       "_model_module_version": "^0.20",
       "_model_name": "LeafletMapModel",
       "_view_count": null,
       "_view_module": "jupyter-leaflet",
       "_view_module_version": "^0.20",
       "_view_name": "LeafletMapView",
       "bottom": 0.0,
       "bounce_at_zoom_limits": true,
       "box_zoom": true,
       "center": [
        -1.8048,
        37.62
       ],
       "close_popup_on_click": true,
       "controls": [
        "IPY_MODEL_4286b31434744652b7023ef3a54993e3",
        "IPY_MODEL_3cba829b64794ff393378f20f0a0ad3f",
        "IPY_MODEL_47a46475bdd540cca6d92e51bcefeca5"
       ],
       "crs": {
        "custom": false,
        "name": "EPSG3857"
       },
       "default_style": "IPY_MODEL_dd84e5c420e04cc8a40834861e0f7d98",
       "double_click_zoom": true,
       "dragging": true,
       "dragging_style": "IPY_MODEL_993a97899edc4034a91a6bdbdf9d1231",
       "east": 0.0,
       "fullscreen": false,
       "inertia": true,
       "inertia_deceleration": 3000,
       "inertia_max_speed": 1500,
       "interpolation": "bilinear",
       "keyboard": true,
       "keyboard_pan_offset": 80,
       "keyboard_zoom_offset": 1,
       "layers": [
        "IPY_MODEL_d35c112cc31c44e3864f5daf55c7c6bf",
        "IPY_MODEL_dcd1582670cc45b1943f175b1819ee08"
       ],
       "layout": "IPY_MODEL_8935bb75ebea47a5a2c1f076b5fe3977",
       "left": 9007199254740991.0,
       "max_zoom": null,
       "min_zoom": null,
       "modisdate": "2025-12-27",
       "north": 0.0,
       "options": [
        "bounce_at_zoom_limits",
        "box_zoom",
        "center",
        "close_popup_on_click",
        "double_click_zoom",
        "dragging",
        "fullscreen",
        "inertia",
        "inertia_deceleration",
        "inertia_max_speed",
        "interpolation",
        "keyboard",
        "keyboard_pan_offset",
        "keyboard_zoom_offset",
        "max_zoom",
        "min_zoom",
        "prefer_canvas",
        "scroll_wheel_zoom",
        "tap",
        "tap_tolerance",
        "touch_zoom",
        "world_copy_jump",
        "zoom",
        "zoom_animation_threshold",
        "zoom_delta",
        "zoom_snap"
       ],
       "panes": {},
       "prefer_canvas": false,
       "right": 0.0,
       "scroll_wheel_zoom": true,
       "south": 0.0,
       "style": "IPY_MODEL_6fc929f844c8457f881a4f517c1e3d11",
       "tabbable": null,
       "tap": true,
       "tap_tolerance": 15,
       "tooltip": null,
       "top": 9007199254740991.0,
       "touch_zoom": true,
       "west": 0.0,
       "window_url": "",
       "world_copy_jump": false,
       "zoom": 8.0,
       "zoom_animation_threshold": 4,
       "zoom_delta": 1.0,
       "zoom_snap": 1.0
      }
     },
     "87038a39eece4e45a3a5940c72980815": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatTextModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatTextModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "FloatTextView",
       "continuous_update": false,
       "description": "Longitude",
       "description_allow_html": false,
       "disabled": false,
       "layout": "IPY_MODEL_59c377c409804e788979c59a2f7b6092",
       "step": 0.0001,
       "style": "IPY_MODEL_47e479eb32564d52985aef099ecd4aab",
       "tabbable": null,
       "tooltip": null,
       "value": 37.62
      }
     },
     "8935bb75ebea47a5a2c1f076b5fe3977": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9902d30492fb4fe59ae06b57e7e41d7e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "993a97899edc4034a91a6bdbdf9d1231": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.20",
      "model_name": "LeafletMapStyleModel",
      "state": {
       "_model_module": "jupyter-leaflet",
       "_model_module_version": "^0.20",
       "_model_name": "LeafletMapStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "cursor": "move"
      }
     },
     "9aaa880845b84247933e95002fdb819d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d4e25910779f4a3296466624514ec14a",
        "IPY_MODEL_87038a39eece4e45a3a5940c72980815"
       ],
       "layout": "IPY_MODEL_5f51661568064f9da1b909898f500cc6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "aef0414725dd479ead9ab16b9f09ba2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "TextStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "TextStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d35c112cc31c44e3864f5daf55c7c6bf": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.20",
      "model_name": "LeafletTileLayerModel",
      "state": {
       "_model_module": "jupyter-leaflet",
       "_model_module_version": "^0.20",
       "_model_name": "LeafletTileLayerModel",
       "_view_count": null,
       "_view_module": "jupyter-leaflet",
       "_view_module_version": "^0.20",
       "_view_name": "LeafletTileLayerView",
       "attribution": "&copy; <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors",
       "base": true,
       "bottom": true,
       "bounds": null,
       "detect_retina": false,
       "loading": false,
       "max_native_zoom": null,
       "max_zoom": 19,
       "min_native_zoom": null,
       "min_zoom": 1,
       "name": "OpenStreetMap.Mapnik",
       "no_wrap": false,
       "opacity": 1.0,
       "options": [
        "attribution",
        "bounds",
        "detect_retina",
        "max_native_zoom",
        "max_zoom",
        "min_native_zoom",
        "min_zoom",
        "no_wrap",
        "pm_ignore",
        "tile_size",
        "tms",
        "zoom_offset"
       ],
       "pane": "",
       "pm_ignore": true,
       "popup": null,
       "popup_max_height": null,
       "popup_max_width": 300,
       "popup_min_width": 50,
       "show_loading": false,
       "snap_ignore": true,
       "subitems": [],
       "tile_size": 256,
       "tms": false,
       "url": "https://tile.openstreetmap.org/{z}/{x}/{y}.png",
       "visible": true,
       "zoom_offset": 0
      }
     },
     "d4e25910779f4a3296466624514ec14a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatTextModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatTextModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "FloatTextView",
       "continuous_update": false,
       "description": "Latitude",
       "description_allow_html": false,
       "disabled": false,
       "layout": "IPY_MODEL_9902d30492fb4fe59ae06b57e7e41d7e",
       "step": 0.0001,
       "style": "IPY_MODEL_d98e6b4aa67847f78ef74b16c729c08d",
       "tabbable": null,
       "tooltip": null,
       "value": -1.8048
      }
     },
     "d98e6b4aa67847f78ef74b16c729c08d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dcd1582670cc45b1943f175b1819ee08": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.20",
      "model_name": "LeafletMarkerModel",
      "state": {
       "_model_module": "jupyter-leaflet",
       "_model_module_version": "^0.20",
       "_model_name": "LeafletMarkerModel",
       "_view_count": null,
       "_view_module": "jupyter-leaflet",
       "_view_module_version": "^0.20",
       "_view_name": "LeafletMarkerView",
       "alt": "",
       "base": false,
       "bottom": false,
       "draggable": true,
       "icon": null,
       "keyboard": true,
       "location": [
        -1.8048,
        37.62
       ],
       "name": "",
       "opacity": 1.0,
       "options": [
        "alt",
        "draggable",
        "keyboard",
        "pm_ignore",
        "rise_offset",
        "rise_on_hover",
        "rotation_angle",
        "rotation_origin",
        "title",
        "z_index_offset"
       ],
       "pane": "",
       "pm_ignore": true,
       "popup": null,
       "popup_max_height": null,
       "popup_max_width": 300,
       "popup_min_width": 50,
       "rise_offset": 250,
       "rise_on_hover": false,
       "rotation_angle": 0.0,
       "rotation_origin": "",
       "snap_ignore": true,
       "subitems": [],
       "title": "",
       "visible": true,
       "z_index_offset": 0
      }
     },
     "dd84e5c420e04cc8a40834861e0f7d98": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.20",
      "model_name": "LeafletMapStyleModel",
      "state": {
       "_model_module": "jupyter-leaflet",
       "_model_module_version": "^0.20",
       "_model_name": "LeafletMapStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "cursor": "grab"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
