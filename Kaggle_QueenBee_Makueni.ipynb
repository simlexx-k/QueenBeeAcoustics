{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 12134294,
     "sourceType": "datasetVersion",
     "datasetId": 7505074
    },
    {
     "sourceId": 14288414,
     "sourceType": "datasetVersion",
     "datasetId": 9120225
    },
    {
     "sourceId": 461059,
     "sourceType": "datasetVersion",
     "datasetId": 166904
    }
   ],
   "dockerImageVersionId": 31234,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "fdc48dcf",
   "cell_type": "markdown",
   "source": "# Kaggle Cloud Ops: Queen Bee Acoustics + Makueni Apiary Intelligence",
   "metadata": {}
  },
  {
   "id": "9325b117",
   "cell_type": "markdown",
   "source": "This unified notebook stitches together:\n\n1. **Queen Bee acoustic detection (CNN + hyperparameter tuning)**\n2. **Makueni Apiary intelligence workflows (weather, NDVI, telemetry, hive stress ML)**\n\n> **Kaggle usage:** Attach the `harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen` dataset plus any `content/main-data` exports as Kaggle data sources. All intermediate files are written under `content/` so the same notebook also works locally.",
   "metadata": {}
  },
  {
   "id": "2f36f683-6666-4169-9339-6b24eb66bc8e",
   "cell_type": "markdown",
   "source": "## BeeUnity System Blueprint\n\nBeeUnity couples two complementary sensing/analytics tracks inside a single reproducible notebook.\n\n- **Acoustic intelligence (Sections \u00a73-15)** ingests the Kaggle beehive audio corpus, generates mel spectrograms, and trains/ tunes a convolutional network for multi-class queen state detection. The outputs are calibrated probabilities + decision thresholds that can be streamed into downstream alerting or fusion models.\n- **Makueni apiary intelligence (Sections \u00a717 onwards)** orchestrates weather/NDVI staging, hive log synthesis, and two tiers of ML models (sklearn HistGradientBoosting + PyTorch temporal CNN/GRU) to estimate hive stress / occupancy risk.\n\nEvery block includes deterministic filesystem staging and writes intermediate products to `/kaggle/working` or `content/` so the research report can quote exact metrics while Kaggle submissions remain GPU safe.\n",
   "metadata": {}
  },
  {
   "id": "ffc483a3",
   "cell_type": "code",
   "source": "!pip install -q earthengine-api ipyleaflet ipywidgets keras-tuner librosa tqdm",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:00:56.514162Z",
     "iopub.execute_input": "2025-12-25T08:00:56.514847Z",
     "iopub.status.idle": "2025-12-25T08:00:59.989726Z",
     "shell.execute_reply.started": "2025-12-25T08:00:56.514817Z",
     "shell.execute_reply": "2025-12-25T08:00:59.988666Z"
    }
   },
   "outputs": [],
   "execution_count": 77
  },
  {
   "id": "422e9772",
   "cell_type": "code",
   "source": "import os\nimport shutil\nfrom pathlib import Path\n\nPROJECT_ROOT = Path.cwd()\nDEFAULT_CONTENT = PROJECT_ROOT / \"content\"\nKAGGLE_WORKING = Path(\"/kaggle/working\")\n\nif DEFAULT_CONTENT.exists():\n    CONTENT_ROOT = DEFAULT_CONTENT.resolve()\nelse:\n    CONTENT_ROOT = (KAGGLE_WORKING / \"content\").resolve()\n    CONTENT_ROOT.mkdir(parents=True, exist_ok=True)\n\nos.environ[\"MERGED_CONTENT_ROOT\"] = str(CONTENT_ROOT)\nMAIN_DATA_DIR = (CONTENT_ROOT / \"main-data\")\nMAIN_DATA_DIR.mkdir(parents=True, exist_ok=True)\n\nKAGGLE_INPUT_ROOT = Path(\"/kaggle/input\")\n\ndef _stage_dataset(keyword, target_subdir):\n    if not KAGGLE_INPUT_ROOT.exists():\n        return None\n    matches = [p for p in KAGGLE_INPUT_ROOT.iterdir() if keyword in p.name.lower()]\n    if not matches:\n        print(f\"[setup] Kaggle input dataset containing '{keyword}' not found.\")\n        return None\n    source = matches[0]\n    target = CONTENT_ROOT / target_subdir\n    shutil.rmtree(target, ignore_errors=True)\n    shutil.copytree(source, target, dirs_exist_ok=True)\n    print(f\"[setup] Staged {source.name} -> {target}\")\n    return target\n\ndef _maybe_stage(keyword, subdir):\n    try:\n        _stage_dataset(keyword, subdir)\n    except Exception as exc:\n        print(f\"[setup] Skipping auto-stage for {keyword}: {exc}\")\n\n_maybe_stage(\"beehive\", \"beehive_audio\")\n_maybe_stage(\"makueni\", \"main-data\")\n\nprint(f\"CONTENT_ROOT -> {CONTENT_ROOT}\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:00:59.991485Z",
     "iopub.execute_input": "2025-12-25T08:00:59.991741Z",
     "iopub.status.idle": "2025-12-25T08:02:03.487547Z",
     "shell.execute_reply.started": "2025-12-25T08:00:59.991717Z",
     "shell.execute_reply": "2025-12-25T08:02:03.486718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "[setup] Staged beehive-audio-dataset-with-queen-and-without-queen -> /kaggle/working/content/beehive_audio\n[setup] Staged makueni-ndvi-2008-2025-csv -> /kaggle/working/content/main-data\nCONTENT_ROOT -> /kaggle/working/content\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 78
  },
  {
   "id": "e8446e4b",
   "cell_type": "code",
   "source": "import calendar\nimport datetime as dt\nimport gc\nimport io\nimport json\nimport math\nimport os\nimport time\nimport warnings\nfrom pathlib import Path\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport keras_tuner as kt\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom sklearn.metrics import (\n    accuracy_score,\n    average_precision_score,\n    classification_report,\n    confusion_matrix,\n    f1_score,\n    precision_recall_curve,\n    precision_score,\n    recall_score,\n    roc_auc_score,\n    RocCurveDisplay\n)\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nimport requests\nwarnings.filterwarnings(\"ignore\")\nsns.set(style=\"whitegrid\")\nplt.rcParams[\"figure.figsize\"] = (8, 4)\nCONTENT_ROOT = Path(os.environ[\"MERGED_CONTENT_ROOT\"])\nMAIN_DATA_DIR = CONTENT_ROOT / \"main-data\"\nfrom pathlib import Path\nFIGURE_DIR = Path('artifacts/figures')\nFIGURE_DIR.mkdir(parents=True, exist_ok=True)\nprint('Saving figures and tables to', FIGURE_DIR.resolve())\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:03.488539Z",
     "iopub.execute_input": "2025-12-25T08:02:03.489137Z",
     "iopub.status.idle": "2025-12-25T08:02:03.497923Z",
     "shell.execute_reply.started": "2025-12-25T08:02:03.489114Z",
     "shell.execute_reply": "2025-12-25T08:02:03.497211Z"
    }
   },
   "outputs": [],
   "execution_count": 79
  },
  {
   "id": "c0841127-3c28-43d2-9771-c8fa7896202a",
   "cell_type": "code",
   "source": "from pathlib import Path\nFIGURE_DIR = Path('artifacts/figures')\nFIGURE_DIR.mkdir(parents=True, exist_ok=True)\nprint('Saving figures and tables to', FIGURE_DIR.resolve())\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "65370be7-7ace-4303-9e7c-da72d1989ebe",
   "cell_type": "code",
   "source": "FIGURE_DIR = Path('/kaggle/working/figures')\nFIGURE_DIR.mkdir(parents=True, exist_ok=True)\nprint('Saving figures and tables to', FIGURE_DIR)\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "00311da8",
   "cell_type": "markdown",
   "source": "## Queen Bee Acoustic Detection Pipeline",
   "metadata": {}
  },
  {
   "id": "673125f9-a703-4f88-bdd9-5f5491598d9d",
   "cell_type": "markdown",
   "source": "### Acoustic Dataset Staging & Lineage\n\nThe queen-bee classifier is trained from the Kaggle dataset `harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen`. We avoid copying raw WAVs into writable storage unless needed; instead, `_discover_audio_dataset` crawls the mounted `/kaggle/input` tree, validates the folder structure, and exposes canonical paths for the `QueenBee Present`, `QueenBee Absent`, and `External Noise` subsets. This guarantees that every spectrogram (and therefore every model checkpoint) can be traced back to a known dataset version, satisfying the reproducibility requirement in the BeeUnity methodology.\n",
   "metadata": {}
  },
  {
   "id": "1c46188a",
   "cell_type": "code",
   "source": "from pathlib import Path\n\ndef _discover_audio_dataset(content_root: Path) -> Path:\n    search_root = Path(\"/kaggle/input/beehive-audio-dataset-with-queen-and-without-queen\")\n    if not search_root.exists():\n        raise FileNotFoundError(\n            \"Dataset not staged. Attach Kaggle dataset \"\n            \"'harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen'.\"\n        )\n\n    for candidate in sorted(search_root.rglob(\"Dataset\")):\n        if (candidate / \"Bee Hive Audios\").exists():\n            return candidate\n\n    raise FileNotFoundError(\"Could not locate 'Dataset/Bee Hive Audios'.\")\n\n# Discover dataset (READ-ONLY)\nAUDIO_DATASET_ROOT = _discover_audio_dataset(None)\n\nBEEHIVE_AUDIO_DIR = next(AUDIO_DATASET_ROOT.glob(\"**/Bee Hive Audios\"))\nQUEEN_PRESENT_DIR = BEEHIVE_AUDIO_DIR / \"QueenBee Present\"\nQUEEN_ABSENT_DIR = BEEHIVE_AUDIO_DIR / \"QueenBee Absent\"\nEXTERNAL_DIR = AUDIO_DATASET_ROOT / \"External Noise\"\n\n# WRITEABLE spectrogram directory\nSPECTROGRAM_DIR = Path(\"/kaggle/working/spectrograms\")\nSPECTROGRAM_PRESENT = SPECTROGRAM_DIR / \"present\"\nSPECTROGRAM_ABSENT = SPECTROGRAM_DIR / \"absent\"\nSPECTROGRAM_EXTERNAL = SPECTROGRAM_DIR / \"external\"\n\nfor path in [SPECTROGRAM_PRESENT, SPECTROGRAM_ABSENT, SPECTROGRAM_EXTERNAL]:\n    path.mkdir(parents=True, exist_ok=True)\n\nprint(\"Audio dataset root (read-only):\", AUDIO_DATASET_ROOT)\nprint(\"Spectrogram cache (writable):\", SPECTROGRAM_DIR)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:03.499515Z",
     "iopub.execute_input": "2025-12-25T08:02:03.499822Z",
     "iopub.status.idle": "2025-12-25T08:02:06.668384Z",
     "shell.execute_reply.started": "2025-12-25T08:02:03.499768Z",
     "shell.execute_reply": "2025-12-25T08:02:06.667757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Audio dataset root (read-only): /kaggle/input/beehive-audio-dataset-with-queen-and-without-queen/Dataset\nSpectrogram cache (writable): /kaggle/working/spectrograms\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 80
  },
  {
   "id": "5601ca8a",
   "cell_type": "code",
   "source": "try:\n    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu_resolver)\n    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n    strategy = tf.distribute.TPUStrategy(tpu_resolver)\n    ACCELERATOR = \"TPU\"\nexcept (ValueError, tf.errors.NotFoundError):\n    gpus = tf.config.list_physical_devices(\"GPU\")\n    if gpus:\n        for gpu in gpus:\n            try:\n                tf.config.experimental.set_memory_growth(gpu, True)\n            except Exception:\n                pass\n        # Default to single-replica strategy for Kaggle GPU stability\n        strategy = tf.distribute.get_strategy()\n        ACCELERATOR = \"GPU\"\n    else:\n        strategy = tf.distribute.get_strategy()\n        ACCELERATOR = \"CPU\"\n\nprint(f\"Using {ACCELERATOR} via {strategy.__class__.__name__}\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:06.669148Z",
     "iopub.execute_input": "2025-12-25T08:02:06.669351Z",
     "iopub.status.idle": "2025-12-25T08:02:06.675392Z",
     "shell.execute_reply.started": "2025-12-25T08:02:06.669333Z",
     "shell.execute_reply": "2025-12-25T08:02:06.674695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Using GPU via _DefaultDistributionStrategy\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 81
  },
  {
   "id": "774287bd-fb49-4d52-a455-1f09f6ff707b",
   "cell_type": "markdown",
   "source": "### Audio Conditioning & Spectrogram Cache\n\nTo stabilize CNN training we transform each WAV into a fixed 3-second mono clip sampled at 22.05 kHz. The `preprocess_and_save_spectrogram` routine trims silence, enforces constant-length padding, normalizes amplitude, and renders a 128\u00d7128 mel-spectrogram using librosa. Spectrograms land under `/kaggle/working/spectrograms/<class>/` and the generators only touch PNGs, eliminating expensive audio decoding during model fit. Progress-aware helpers (e.g., `_compute_progress`) let reruns skip already materialized windows so Kaggle GPU runtime stays within budget.\n",
   "metadata": {}
  },
  {
   "id": "20b2348e",
   "cell_type": "code",
   "source": "SAMPLE_RATE = 22050\nDURATION = 3\nSAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n\nlibrosa.cache.clear()\nplt.switch_backend(\"Agg\")\n\ndef preprocess_and_save_spectrogram(audio_path: Path, output_image_path: Path, sr=SAMPLE_RATE, duration=DURATION):\n    try:\n        y, _ = librosa.load(audio_path, sr=sr)\n        y, _ = librosa.effects.trim(y)\n        y = librosa.to_mono(y) if y.ndim > 1 else y\n        y = librosa.util.normalize(y)\n\n        expected_samples = sr * duration\n        if len(y) < expected_samples:\n            y = np.pad(y, (0, expected_samples - len(y)), mode=\"constant\")\n        else:\n            y = y[:expected_samples]\n\n        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n        mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n\n        plt.figure(figsize=(2, 2), dpi=64)\n        librosa.display.specshow(mel_db, sr=sr, cmap=\"magma\")\n        plt.axis(\"off\")\n        output_image_path.parent.mkdir(parents=True, exist_ok=True)\n        plt.savefig(output_image_path, bbox_inches=\"tight\", pad_inches=0)\n        plt.close()\n    except Exception as exc:\n        print(f\"[spectrogram] Failed on {audio_path}: {exc}\")\n\ndef _compute_progress(files, output_dir: Path):\n    total = len(files)\n    processed = sum((output_dir / f\"{Path(f).stem}.png\").exists() for f in files)\n    return total, processed\n\ndef process_audio_folder(input_dir: Path, output_dir: Path, desc: str):\n    if not input_dir.exists():\n        print(f\"[spectrogram] {input_dir} missing, skipping {desc}.\")\n        return\n    wav_files = sorted([f for f in input_dir.iterdir() if f.suffix.lower() == \".wav\"])\n    total, processed = _compute_progress([f.name for f in wav_files], output_dir)\n    with tqdm(total=total, initial=processed, desc=desc, unit=\"file\") as pbar:\n        for wav_path in wav_files:\n            out_path = output_dir / f\"{wav_path.stem}.png\"\n            if out_path.exists():\n                pbar.update(1)\n                continue\n            preprocess_and_save_spectrogram(wav_path, out_path)\n            gc.collect()\n            pbar.update(1)\n\ndef process_external_folder(input_dir: Path, output_dir: Path):\n    if not input_dir.exists():\n        print(\"[spectrogram] External noise folder missing, skipping.\")\n        return\n    audio_paths = []\n    for root, _, files in os.walk(input_dir):\n        audio_paths += [Path(root) / f for f in files if f.lower().endswith(\".wav\")]\n    with tqdm(total=len(audio_paths), desc=\"External noise\", unit=\"file\") as pbar:\n        for wav_path in audio_paths:\n            out_path = output_dir / f\"{wav_path.stem}.png\"\n            if out_path.exists():\n                pbar.update(1)\n                continue\n            preprocess_and_save_spectrogram(wav_path, out_path)\n            pbar.update(1)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:06.676310Z",
     "iopub.execute_input": "2025-12-25T08:02:06.676864Z",
     "iopub.status.idle": "2025-12-25T08:02:06.703360Z",
     "shell.execute_reply.started": "2025-12-25T08:02:06.676841Z",
     "shell.execute_reply": "2025-12-25T08:02:06.702822Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "[Memory(location=None)]: Flushing completely the cache\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 82
  },
  {
   "id": "5194f6d3",
   "cell_type": "code",
   "source": "process_audio_folder(QUEEN_PRESENT_DIR, SPECTROGRAM_PRESENT, \"QueenBee Present\")\nprocess_audio_folder(QUEEN_ABSENT_DIR, SPECTROGRAM_ABSENT, \"QueenBee Absent\")\nprocess_external_folder(EXTERNAL_DIR, SPECTROGRAM_EXTERNAL)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:06.704036Z",
     "iopub.execute_input": "2025-12-25T08:02:06.704211Z",
     "iopub.status.idle": "2025-12-25T08:02:06.999704Z",
     "shell.execute_reply.started": "2025-12-25T08:02:06.704195Z",
     "shell.execute_reply": "2025-12-25T08:02:06.999041Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "QueenBee Present: 8000file [00:00, 77319.70file/s]             \nQueenBee Absent: 4000file [00:00, 80590.73file/s]             \nExternal noise: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:00<00:00, 59606.97file/s]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 83
  },
  {
   "id": "fb90b30b",
   "cell_type": "code",
   "source": "def count_pngs(folder: Path):\n    return len([f for f in folder.glob(\"*.png\")])\n\nclass_labels = [\"present\", \"absent\", \"external\"]\ncounts = [\n    count_pngs(SPECTROGRAM_PRESENT),\n    count_pngs(SPECTROGRAM_ABSENT),\n    count_pngs(SPECTROGRAM_EXTERNAL),\n]\n\nplt.figure(figsize=(6, 4))\nbars = plt.bar(class_labels, counts, color=[\"sienna\", \"peru\", \"gray\"], edgecolor=\"black\")\nplt.ylim(0, max(counts) * 1.1 if counts else 10)\nplt.title(\"Spectrogram Count per Class\")\nplt.ylabel(\"Images\")\nfor bar in bars:\n    y = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width() / 2, y + max(1, y ** 0.5), int(y), ha=\"center\", va=\"bottom\")\nplt.show()\n\nprint(dict(zip(class_labels, counts)))\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:07.000624Z",
     "iopub.execute_input": "2025-12-25T08:02:07.000853Z",
     "iopub.status.idle": "2025-12-25T08:02:07.083161Z",
     "shell.execute_reply.started": "2025-12-25T08:02:07.000832Z",
     "shell.execute_reply": "2025-12-25T08:02:07.082594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "{'present': 4000, 'absent': 2000, 'external': 2000}\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 84
  },
  {
   "id": "070b018d-7e72-48c5-adc2-467d285d21e3",
   "cell_type": "markdown",
   "source": "### Stratified DataFrames, Augmentation, and Class Weights\n\nThe original ImageDataGenerator split approach caused leakage between validation/test folds. We now build a pandas catalog of every spectrogram file, stratify it into train/val/test via `train_test_split`, and feed `flow_from_dataframe` generators. Light-weight augmentations (flip + shifts) only touch the training subset. Class imbalance (present:absent:external = 4000:2000:2000) is mitigated through `compute_class_weight` and a custom `SparseClassRecall` metric that explicitly tracks recall on the underrepresented `absent` class; both feed into every Keras fit/tuning call so the notebook\u2019s metrics align with the research objective of catching queen loss events.\n",
   "metadata": {}
  },
  {
   "id": "b1438348",
   "cell_type": "code",
   "source": "IMG_SIZE = (128, 128)\nBASE_BATCH_SIZE = 32\nBATCH_SIZE = BASE_BATCH_SIZE  # Keep per-device batch size stable on Kaggle\nSEED = 42\n\nspectro_records = []\nfor class_dir in sorted(SPECTROGRAM_DIR.iterdir()):\n    if class_dir.is_dir():\n        label = class_dir.name\n        for img_path in class_dir.glob(\"*.png\"):\n            spectro_records.append({\"filepath\": str(img_path), \"label\": label})\n\nif not spectro_records:\n    raise RuntimeError(\"No spectrograms were generated; run preprocessing above first.\")\n\nspectro_df = pd.DataFrame(spectro_records)\nCLASS_NAMES = sorted(spectro_df[\"label\"].unique())\n\ntrain_df, temp_df = train_test_split(\n    spectro_df,\n    test_size=0.4,\n    stratify=spectro_df[\"label\"],\n    random_state=SEED\n)\nval_df, test_df = train_test_split(\n    temp_df,\n    test_size=0.5,\n    stratify=temp_df[\"label\"],\n    random_state=SEED\n)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    horizontal_flip=True,\n    width_shift_range=0.05,\n    height_shift_range=0.05\n)\neval_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_gen = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"sparse\",\n    classes=CLASS_NAMES,\n    shuffle=True,\n    seed=SEED\n)\n\nval_gen = eval_datagen.flow_from_dataframe(\n    val_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"sparse\",\n    classes=CLASS_NAMES,\n    shuffle=False,\n    seed=SEED\n)\n\ntest_gen = eval_datagen.flow_from_dataframe(\n    test_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"sparse\",\n    classes=CLASS_NAMES,\n    shuffle=False,\n    seed=SEED\n)\n\nraw_class_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.array(CLASS_NAMES),\n    y=train_df[\"label\"]\n)\nCLASS_WEIGHTS = {\n    train_gen.class_indices[label]: weight for label, weight in zip(CLASS_NAMES, raw_class_weights)\n}\nprint(\"Class indices:\", train_gen.class_indices)\nprint(\"Class weights:\", CLASS_WEIGHTS)\n\nABSENT_CLASS_INDEX = train_gen.class_indices[\"absent\"]\n\nclass SparseClassRecall(tf.keras.metrics.Metric):\n    def __init__(self, class_id, name=\"sparse_class_recall\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.class_id = class_id\n        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.false_negatives = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.cast(tf.reshape(y_true, [-1]), tf.int32)\n        y_pred = tf.cast(tf.argmax(y_pred, axis=-1), tf.int32)\n        class_mask = tf.cast(tf.equal(y_true, self.class_id), self.dtype)\n        pred_mask = tf.cast(tf.equal(y_pred, self.class_id), self.dtype)\n        if sample_weight is None:\n            weights = tf.ones_like(class_mask)\n        else:\n            weights = tf.cast(tf.reshape(sample_weight, [-1]), self.dtype)\n            weights = tf.broadcast_to(weights, tf.shape(class_mask))\n        weighted_mask = class_mask * weights\n        tp = tf.reduce_sum(pred_mask * weighted_mask)\n        fn = tf.reduce_sum((1.0 - pred_mask) * weighted_mask)\n        self.true_positives.assign_add(tp)\n        self.false_negatives.assign_add(fn)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\"class_id\": int(self.class_id)})\n        return config\n\n    def result(self):\n        return tf.math.divide_no_nan(self.true_positives, self.true_positives + self.false_negatives)\n\n    def reset_states(self):\n        self.true_positives.assign(0.0)\n        self.false_negatives.assign(0.0)\n\ndef make_absent_recall(name=\"recall_absent\"):\n    return SparseClassRecall(class_id=ABSENT_CLASS_INDEX, name=name)\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:07.084084Z",
     "iopub.execute_input": "2025-12-25T08:02:07.084412Z",
     "iopub.status.idle": "2025-12-25T08:02:07.211572Z",
     "shell.execute_reply.started": "2025-12-25T08:02:07.084380Z",
     "shell.execute_reply": "2025-12-25T08:02:07.211012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Found 4800 validated image filenames belonging to 3 classes.\nFound 1600 validated image filenames belonging to 3 classes.\nFound 1600 validated image filenames belonging to 3 classes.\nClass indices: {'absent': 0, 'external': 1, 'present': 2}\nClass weights: {0: np.float64(1.3333333333333333), 1: np.float64(1.3333333333333333), 2: np.float64(0.6666666666666666)}\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 85
  },
  {
   "id": "58a40d5d-8bf8-4979-9c60-01cf60be727b",
   "cell_type": "markdown",
   "source": "### Baseline CNN Training Plan\n\nThe baseline network is intentionally compact so it trains quickly on Kaggle GPUs yet captures salient spectral patterns: three Conv-BN-Pool stages followed by GAP and a 64-unit dense head. Training runs under the selected `strategy` with class weights + early stopping keyed to `val_recall_absent` to bias the model toward correctly flagging queen-absent clips. This baseline establishes the minimum viable performance before hyperparameter search.\n",
   "metadata": {}
  },
  {
   "id": "a233e93a",
   "cell_type": "code",
   "source": "from tensorflow.keras.callbacks import EarlyStopping\n\ndef build_baseline_model():\n    model = models.Sequential([\n        layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\", input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(64, activation=\"relu\"),\n        layers.Dropout(0.5),\n        layers.Dense(3, activation=\"softmax\"),\n    ])\n    model.compile(\n        optimizer=\"adam\",\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\", make_absent_recall()]\n    )\n    return model\n\nwith strategy.scope():\n    baseline_model = build_baseline_model()\n\nbaseline_callbacks = [\n    EarlyStopping(monitor=\"val_recall_absent\", mode=\"max\", patience=3, restore_best_weights=True)\n]\n\nbaseline_history = baseline_model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=20,\n    class_weight=CLASS_WEIGHTS,\n    callbacks=baseline_callbacks\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:07.213854Z",
     "iopub.execute_input": "2025-12-25T08:02:07.214130Z",
     "iopub.status.idle": "2025-12-25T08:03:37.052571Z",
     "shell.execute_reply.started": "2025-12-25T08:02:07.214109Z",
     "shell.execute_reply": "2025-12-25T08:03:37.051920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 144ms/step - accuracy: 0.7123 - loss: 0.6749 - recall_absent: 0.7678 - val_accuracy: 0.5294 - val_loss: 1.1168 - val_recall_absent: 0.0000e+00\nEpoch 2/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 140ms/step - accuracy: 0.8961 - loss: 0.2786 - recall_absent: 0.9125 - val_accuracy: 0.3481 - val_loss: 1.7710 - val_recall_absent: 0.0000e+00\nEpoch 3/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 140ms/step - accuracy: 0.9316 - loss: 0.1825 - recall_absent: 0.9241 - val_accuracy: 0.2500 - val_loss: 5.2762 - val_recall_absent: 0.0000e+00\nEpoch 4/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 140ms/step - accuracy: 0.9405 - loss: 0.1604 - recall_absent: 0.9390 - val_accuracy: 0.7387 - val_loss: 2.5434 - val_recall_absent: 0.0000e+00\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 86
  },
  {
   "id": "04506242-d867-47f5-8efb-c7452a7fa19b",
   "cell_type": "markdown",
   "source": "### KerasTuner Hyperband Search & Fine-Tune\n\nHyperparameter tuning explores filter widths, dense units, dropout, and optimizer choice via `kt.Hyperband`, again optimizing `val_recall_absent`. The tuner runs outside the distribution `strategy` scope (per TensorFlow guidance) while the search/ fine-tune phases inherit the same class weights + early stopping regime as the baseline. The best trial is persisted as a `.keras` artifact under `/kaggle/working` for downstream deployment / report inclusion.\n",
   "metadata": {}
  },
  {
   "id": "75194ab4",
   "cell_type": "code",
   "source": "from tensorflow.keras.callbacks import EarlyStopping\nfrom pathlib import Path\n\ndef build_tunable_model(hp):\n    model = models.Sequential([\n        layers.Conv2D(\n            hp.Choice(\"conv1\", [32, 64]), 3,\n            activation=\"relu\", padding=\"same\",\n            input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n        ),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.Conv2D(hp.Choice(\"conv2\", [64, 128]), 3, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.Conv2D(hp.Choice(\"conv3\", [128, 256]), 3, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(hp.Int(\"dense_units\", 64, 128, step=32), activation=\"relu\"),\n        layers.Dropout(hp.Float(\"dropout\", 0.3, 0.6, step=0.1)),\n        layers.Dense(3, activation=\"softmax\"),\n    ])\n\n    model.compile(\n        optimizer=hp.Choice(\"optimizer\", [\"adam\", \"nadam\"]),\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\", make_absent_recall()]\n    )\n    return model\n\n\n# Strategy ONLY for tuner creation\nwith strategy.scope():\n    tuner = kt.Hyperband(\n        build_tunable_model,\n        objective=kt.Objective(\"val_recall_absent\", direction=\"max\"),\n        max_epochs=15,\n        factor=3,\n        directory=\"/kaggle/working/queenbee_tuning\",\n        project_name=\"queenbee_cnn\"\n    )\n\nstopper = EarlyStopping(\n    monitor=\"val_recall_absent\",\n    mode=\"max\",\n    patience=3,\n    restore_best_weights=True\n)\n\n# Search OUTSIDE strategy scope\ntuner.search(\n    train_gen,\n    validation_data=val_gen,\n    epochs=15,\n    class_weight=CLASS_WEIGHTS,\n    callbacks=[stopper]\n)\n\n# NO strategy scope here\nbest_model = tuner.get_best_models(num_models=1)[0]\n\nfine_tune_history = best_model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=15,\n    class_weight=CLASS_WEIGHTS,\n    callbacks=[stopper]\n)\n\n# Writable save path\nbest_model_path = Path(\"/kaggle/working/queenbee_final_tuned_model.keras\")\nbest_model.save(best_model_path)\n\nprint(\"Saved tuned model to\", best_model_path)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:03:37.053620Z",
     "iopub.execute_input": "2025-12-25T08:03:37.053885Z",
     "iopub.status.idle": "2025-12-25T08:05:09.828322Z",
     "shell.execute_reply.started": "2025-12-25T08:03:37.053864Z",
     "shell.execute_reply": "2025-12-25T08:05:09.827404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Reloading Tuner from /kaggle/working/queenbee_tuning/queenbee_cnn/tuner0.json\nEpoch 1/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 146ms/step - accuracy: 0.8976 - loss: 0.3386 - recall_absent: 0.8787 - val_accuracy: 0.5306 - val_loss: 0.9954 - val_recall_absent: 0.9900\nEpoch 2/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 142ms/step - accuracy: 0.9532 - loss: 0.1079 - recall_absent: 0.9564 - val_accuracy: 0.9081 - val_loss: 0.2799 - val_recall_absent: 0.9575\nEpoch 3/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 142ms/step - accuracy: 0.9639 - loss: 0.0746 - recall_absent: 0.9640 - val_accuracy: 0.9381 - val_loss: 0.1628 - val_recall_absent: 0.8500\nEpoch 4/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 143ms/step - accuracy: 0.9630 - loss: 0.0877 - recall_absent: 0.9620 - val_accuracy: 0.5750 - val_loss: 1.4998 - val_recall_absent: 0.2425\nSaved tuned model to /kaggle/working/queenbee_final_tuned_model.keras\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 87
  },
  {
   "id": "2e8f7167",
   "cell_type": "code",
   "source": "from tensorflow.keras.models import load_model\n\nmodel_for_eval = load_model(\n    best_model_path,\n    custom_objects={\"SparseClassRecall\": SparseClassRecall}\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:05:09.829294Z",
     "iopub.execute_input": "2025-12-25T08:05:09.829931Z",
     "iopub.status.idle": "2025-12-25T08:05:10.050890Z",
     "shell.execute_reply.started": "2025-12-25T08:05:09.829909Z",
     "shell.execute_reply": "2025-12-25T08:05:10.050208Z"
    }
   },
   "outputs": [],
   "execution_count": 88
  },
  {
   "id": "890403d2-2bac-4feb-925a-09b27723c576",
   "cell_type": "markdown",
   "source": "### Probability Calibration & Threshold Selection\n\nRaw softmax scores tend to collapse onto the majority `present` class. After loading the tuned CNN we perform two evaluation modes: standard argmax and calibrated predictions. Validation probabilities drive per-class precision-recall curves, from which we select F1-optimal thresholds. Those calibrated thresholds are then applied to the held-out test generator, yielding confusion matrices, detailed classification reports, and macro ROC/PR AUC metrics that the manuscript can cite when describing queen-state detection performance.\n",
   "metadata": {}
  },
  {
   "id": "921011f7",
   "cell_type": "code",
   "source": "def run_inference(model, generator):\n    generator.reset()\n    y_prob = model.predict(generator, verbose=1)\n    y_true = generator.classes\n    return y_prob, y_true\n\n\ndef derive_thresholds(y_true, y_prob, class_names):\n    y_true_oh = tf.keras.utils.to_categorical(y_true, num_classes=len(class_names))\n    thresholds = {}\n    for idx, name in enumerate(class_names):\n        precision, recall, thresh = precision_recall_curve(y_true_oh[:, idx], y_prob[:, idx])\n        if thresh.size == 0:\n            thresholds[name] = 0.5\n            continue\n        f1 = 2 * precision * recall / np.clip(precision + recall, 1e-8, None)\n        best_idx = np.nanargmax(f1)\n        thresholds[name] = float(thresh[min(best_idx, len(thresh) - 1)])\n    return thresholds\n\n\ndef predict_with_thresholds(y_prob, class_names, thresholds):\n    calibrated = []\n    for row in y_prob:\n        chosen_idx = None\n        chosen_score = -1.0\n        for idx, name in enumerate(class_names):\n            threshold = thresholds.get(name, 0.5)\n            if row[idx] >= threshold and row[idx] > chosen_score:\n                chosen_idx = idx\n                chosen_score = row[idx]\n        if chosen_idx is None:\n            chosen_idx = int(np.argmax(row))\n        calibrated.append(chosen_idx)\n    return np.array(calibrated)\n\n\ndef summarize_metrics(y_true, y_pred, label):\n    return {\n        \"Mode\": label,\n        \"Accuracy\": accuracy_score(y_true, y_pred),\n        \"Macro Precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n        \"Macro Recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n        \"Macro F1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n    }\n\nval_prob, val_true = run_inference(model_for_eval, val_gen)\nclass_names = list(test_gen.class_indices.keys())\nthresholds = derive_thresholds(val_true, val_prob, class_names)\nprint(\"Calibrated probability thresholds:\")\nfor name in class_names:\n    print(f\"  {name}: {thresholds[name]:.3f}\")\n\nmetrics = []\ntest_prob, test_true = run_inference(model_for_eval, test_gen)\ndefault_pred = np.argmax(test_prob, axis=1)\ncalibrated_pred = predict_with_thresholds(test_prob, class_names, thresholds)\n\nmetrics_table = pd.DataFrame([\n    summarize_metrics(test_true, default_pred, \"Argmax\"),\n    summarize_metrics(test_true, calibrated_pred, \"Calibrated\")\n])\ndisplay(metrics_table)\nmetrics_table_path = FIGURE_DIR / \"acoustic_metrics_table.csv\"\nmetrics_table.to_csv(metrics_table_path, index=False)\nprint(\"Saved acoustic metrics table ->\", metrics_table_path)\n\ncm = confusion_matrix(test_true, calibrated_pred)\ncm_fig, ax = plt.subplots(figsize=(5, 4))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, ax=ax)\nax.set_xlabel(\"Predicted\")\nax.set_ylabel(\"True\")\nax.set_title(\"Confusion Matrix (Calibrated)\")\ncm_path = FIGURE_DIR / \"acoustic_confusion_matrix.png\"\ncm_fig.savefig(cm_path, dpi=300, bbox_inches=\"tight\")\nplt.show()\nprint(\"Saved acoustic confusion matrix ->\", cm_path)\n\nreport_text = classification_report(test_true, calibrated_pred, target_names=class_names, zero_division=0)\nprint(\"Calibrated classification report:\n\", report_text)\nreport_path = FIGURE_DIR / \"acoustic_classification_report.txt\"\nreport_path.write_text(report_text)\n\nroc_auc = roc_auc_score(\n    pd.get_dummies(test_true, drop_first=False).values,\n    test_prob,\n    average=\"macro\",\n    multi_class=\"ovr\"\n)\npr_auc = average_precision_score(\n    pd.get_dummies(test_true, drop_first=False).values,\n    test_prob,\n    average=\"macro\"\n)\nauc_path = FIGURE_DIR / \"acoustic_auc_summary.json\"\nauc_path.write_text(json.dumps({\"roc_auc\": float(roc_auc), \"pr_auc\": float(pr_auc)}, indent=2))\nprint(f\"ROC-AUC: {roc_auc:.4f} | PR-AUC: {pr_auc:.4f}\")\nprint(\"Saved acoustic AUC summary ->\", auc_path)\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:05:10.051850Z",
     "iopub.execute_input": "2025-12-25T08:05:10.052111Z",
     "iopub.status.idle": "2025-12-25T08:05:13.998148Z",
     "shell.execute_reply.started": "2025-12-25T08:05:10.052072Z",
     "shell.execute_reply": "2025-12-25T08:05:13.997501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001b[1m50/50\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\nCalibrated probability thresholds:\n  absent: 0.898\n  external: 0.779\n  present: 0.032\n\u001b[1m50/50\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "         Mode  Accuracy  Macro Precision  Macro Recall  Macro F1\n0      Argmax  0.526875         0.695540      0.681667  0.501093\n1  Calibrated  0.946875         0.937807      0.957083  0.946250",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mode</th>\n      <th>Accuracy</th>\n      <th>Macro Precision</th>\n      <th>Macro Recall</th>\n      <th>Macro F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Argmax</td>\n      <td>0.526875</td>\n      <td>0.695540</td>\n      <td>0.681667</td>\n      <td>0.501093</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Calibrated</td>\n      <td>0.946875</td>\n      <td>0.937807</td>\n      <td>0.957083</td>\n      <td>0.946250</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Calibrated classification report:               precision    recall  f1-score   support\n\n      absent       0.89      0.97      0.93       400\n    external       0.94      0.98      0.96       400\n     present       0.99      0.92      0.95       800\n\n    accuracy                           0.95      1600\n   macro avg       0.94      0.96      0.95      1600\nweighted avg       0.95      0.95      0.95      1600\n\nROC-AUC: 0.9813 | PR-AUC: 0.9667\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 89
  },
  {
   "id": "8a188280",
   "cell_type": "code",
   "source": "SR = 22050\n\ndef audio_to_spectrogram_image(audio_path: Path):\n    y, sr = librosa.load(audio_path, sr=SR)\n    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=512)\n    S_dB = librosa.power_to_db(S, ref=np.max)\n\n    fig = plt.figure(figsize=(2, 2), dpi=64)\n    librosa.display.specshow(S_dB, sr=sr, cmap=\"magma\")\n    plt.axis(\"off\")\n\n    buf = io.BytesIO()\n    plt.savefig(buf, format=\"png\", bbox_inches=\"tight\", pad_inches=0)\n    plt.close(fig)\n    buf.seek(0)\n\n    img = Image.open(buf).convert(\"RGB\").resize(IMG_SIZE)\n    img_array = np.array(img, dtype=np.float32) / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\ndef visualize_audio_prediction(audio_path: Path, model):\n    mel_input = audio_to_spectrogram_image(audio_path)\n    prediction = model.predict(mel_input)\n    class_names = list(test_gen.class_indices.keys())\n    pred_idx = int(np.argmax(prediction))\n    confidence = float(np.max(prediction))\n\n    y, sr = librosa.load(audio_path, sr=SR)\n    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n    mel_db = librosa.power_to_db(mel, ref=np.max)\n\n    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n    times = np.linspace(0, len(y)/sr, len(y))\n    axes[0,0].plot(times, y)\n    axes[0,0].set_title(\"Waveform\")\n\n    img = axes[0,1].imshow(mel_db, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n    axes[0,1].set_title(\"Mel Spectrogram\")\n    plt.colorbar(img, ax=axes[0,1], fraction=0.046, pad=0.04)\n\n    axes[1,0].bar(class_names, prediction[0], color=\"teal\")\n    axes[1,0].set_ylim(0, 1)\n    axes[1,0].set_title(\"Prediction Probabilities\")\n\n    axes[1,1].axis(\"off\")\n    axes[1,1].text(0.1, 0.5, f\"Predicted: {class_names[pred_idx]}\\nConfidence: {confidence:.2%}\", fontsize=14)\n\n    plt.tight_layout()\n    plt.show()\n\n    return {\"prediction\": class_names[pred_idx], \"confidence\": confidence}\n\nsample_audio = next(QUEEN_PRESENT_DIR.glob('*.wav'))\nvisualize_audio_prediction(sample_audio, model_for_eval)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:05:13.999019Z",
     "iopub.execute_input": "2025-12-25T08:05:13.999273Z",
     "iopub.status.idle": "2025-12-25T08:05:15.087313Z",
     "shell.execute_reply.started": "2025-12-25T08:05:13.999241Z",
     "shell.execute_reply": "2025-12-25T08:05:15.086704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n",
     "output_type": "stream"
    },
    {
     "execution_count": 90,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'prediction': 'external', 'confidence': 0.6416568160057068}"
     },
     "metadata": {}
    }
   ],
   "execution_count": 90
  },
  {
   "id": "86e1ed93",
   "cell_type": "markdown",
   "source": "## Makueni Climate-Informed Forecasting\n\nWe now project yield and occupancy directly from climate/NDVI sequences using W\u00fcrzburg-pretrained models.\n",
   "metadata": {}
  },
  {
   "id": "07adc57a-7308-41ca-bd31-e6b6396ddade",
   "cell_type": "markdown",
   "source": "## Makueni Apiary Intelligence Pipeline\n\nThe second half of BeeUnity focuses on environmental + hive telemetry analytics for Makueni County. Users can optionally pick a geometry via ipyleaflet; however, Kaggle\u2019s environment rarely ships the `jupyter-leaflet` extension, so we default to fixed coordinates while preserving the widget wiring for local notebooks. This section obeys Kaggle\u2019s outbound-network policy via the `ENABLE_REMOTE_CALLS` flag and falls back to cached CSV exports inside `content/main-data/`.\n",
   "metadata": {}
  },
  {
   "id": "6c6b0129",
   "cell_type": "code",
   "source": "DEFAULT_CENTER = (-1.8048, 37.62)\nENABLE_LEAFLET_WIDGETS = False  # Set True only if jupyter-leaflet widgets are installed.\n\ntry:\n    import ipywidgets as widgets\n    from ipyleaflet import Map, Marker, DrawControl, basemaps\nexcept Exception:\n    print(\"ipyleaflet not available; using default coordinates.\")\n    lat_widget = lon_widget = geometry_widget = None\nelse:\n    lat_widget = widgets.FloatText(value=DEFAULT_CENTER[0], description=\"Latitude\", step=0.0001)\n    lon_widget = widgets.FloatText(value=DEFAULT_CENTER[1], description=\"Longitude\", step=0.0001)\n    geometry_widget = widgets.Textarea(\n        value=\"\",\n        description=\"Geometry\",\n        placeholder=\"Draw a polygon/rectangle on the map.\",\n        layout=widgets.Layout(width=\"100%\", height=\"140px\"),\n        disabled=True,\n    )\n\n    leaflet_map = Map(center=DEFAULT_CENTER, zoom=8, basemap=basemaps.OpenStreetMap.Mapnik, scroll_wheel_zoom=True)\n    marker = Marker(location=DEFAULT_CENTER, draggable=True)\n    leaflet_map.add_layer(marker)\n\n    draw_control = DrawControl(\n        polygon={\"shapeOptions\": {\"color\": \"#2563eb\", \"weight\": 2, \"fillOpacity\": 0.2}},\n        rectangle={\"shapeOptions\": {\"color\": \"#f97316\", \"weight\": 2, \"fillOpacity\": 0.15}},\n        circle={},\n        circlemarker={},\n        polyline={},\n    )\n    leaflet_map.add_control(draw_control)\n\n    def _update_marker(change):\n        marker.location = (lat_widget.value, lon_widget.value)\n\n    lat_widget.observe(_update_marker, names=\"value\")\n    lon_widget.observe(_update_marker, names=\"value\")\n\n    display(widgets.HBox([lat_widget, lon_widget]))\n    display(geometry_widget)\n    display(leaflet_map)\n\nlat_widget_available = 'lat_widget' in globals() and lat_widget is not None\nlon_widget_available = 'lon_widget' in globals() and lon_widget is not None\n\nif lat_widget_available and lon_widget_available:\n    latitude = float(lat_widget.value)\n    longitude = float(lon_widget.value)\nelse:\n    latitude, longitude = DEFAULT_CENTER\n    print(\"Using default coordinates:\", DEFAULT_CENTER)\n\nselected_geometry_geojson = globals().get('selected_geometry_geojson')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:47:26.432241Z",
     "iopub.execute_input": "2025-12-28T12:47:26.432927Z",
     "iopub.status.idle": "2025-12-28T12:47:26.460398Z",
     "shell.execute_reply.started": "2025-12-28T12:47:26.432897Z",
     "shell.execute_reply": "2025-12-28T12:47:26.459674Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatText(value=-1.8048, description='Latitude', step=0.0001), FloatText(value=37.62, descripti\u2026",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a287739d278d4b76ada68bf21af7de71"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Textarea(value='', description='Geometry', disabled=True, layout=Layout(height='140px', width='100%'), placeho\u2026",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c52e4b5b34a444f807c9eda9cfe12fd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Map(center=[-1.8048, 37.62], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom\u2026",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38a5599b319d4a4aa2375b09a9ded330"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": 103
  },
  {
   "id": "86325237-f19b-4d81-9413-14c99b9be32a",
   "cell_type": "markdown",
   "source": "### Weather/NDVI Acquisition Strategy\n\nWe scope the modeling window via `normalize_date_string`, clamp requests to the latest Open-Meteo archive availability, and split long ranges into 365-day chunks. When `ENABLE_REMOTE_CALLS` is false (the Kaggle default), we load pre-exported weather and NDVI CSVs staged under `content/main-data/`. When high-trust compute is available, the notebook can re-fetch ERA5/Open-Meteo and MODIS NDVI slices, persisting them with consistent schemas so report figures remain reproducible.\n",
   "metadata": {}
  },
  {
   "id": "13f4ff43",
   "cell_type": "code",
   "source": "import ee\n\nraw_start_date = \"2008-01-01\"\nraw_end_date = \"2025-12-05\"\ntimezone = \"Africa/Nairobi\"\n\ndef normalize_date_string(d: str) -> dt.date:\n    parts = d.split(\"-\")\n    if len(parts) != 3:\n        raise ValueError(\"Date must be YYYY-MM-DD\")\n    y, m, day = [int(p) for p in parts]\n    m = max(1, min(12, m))\n    last_day = calendar.monthrange(y, m)[1]\n    day = max(1, min(last_day, day))\n    return dt.date(y, m, day)\n\nstart_date = normalize_date_string(raw_start_date)\nend_date = normalize_date_string(raw_end_date)\n\ntoday = dt.date.today()\napi_latest = dt.date(2025, 12, 20)\nmax_allowed = min(today, api_latest)\n\nif end_date > max_allowed:\n    print(f\"Clamping end_date {end_date} -> {max_allowed}\")\n    end_date = max_allowed\nif start_date > end_date:\n    raise ValueError(\"start_date must be before end_date\")\n\nprint(\"Using date range:\", start_date, \"\u2192\", end_date)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:47:31.611899Z",
     "iopub.execute_input": "2025-12-28T12:47:31.612747Z",
     "iopub.status.idle": "2025-12-28T12:47:31.619278Z",
     "shell.execute_reply.started": "2025-12-28T12:47:31.612716Z",
     "shell.execute_reply": "2025-12-28T12:47:31.618589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Using date range: 2008-01-01 \u2192 2025-12-05\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 104
  },
  {
   "id": "f651dd70",
   "cell_type": "code",
   "source": "ENABLE_REMOTE_CALLS = True  # Kaggle notebooks typically block outbound internet.\n\ndef split_date_range(start: dt.date, end: dt.date, max_days: int = 365):\n    chunks = []\n    current = start\n    while current <= end:\n        chunk_end = min(end, current + dt.timedelta(days=max_days - 1))\n        chunks.append((current, chunk_end))\n        current = chunk_end + dt.timedelta(days=1)\n    return chunks\n\ndef fetch_chunk(lat, lon, sdate: dt.date, edate: dt.date, timezone=\"Africa/Nairobi\", max_retries=3, backoff=2):\n    base = \"https://archive-api.open-meteo.com/v1/archive\"\n    daily_vars = \",\".join([\n        \"temperature_2m_max\",\n        \"temperature_2m_min\",\n        \"temperature_2m_mean\",\n        \"precipitation_sum\",\n        \"relative_humidity_2m_mean\",\n        \"wind_speed_10m_max\",\n        \"cloudcover_mean\"\n    ])\n    params = {\n        \"latitude\": lat,\n        \"longitude\": lon,\n        \"start_date\": sdate.strftime(\"%Y-%m-%d\"),\n        \"end_date\": edate.strftime(\"%Y-%m-%d\"),\n        \"daily\": daily_vars,\n        \"timezone\": timezone\n    }\n    for attempt in range(1, max_retries + 1):\n        try:\n            resp = requests.get(base, params=params, timeout=30)\n            resp.raise_for_status()\n            payload = resp.json()\n            if \"daily\" not in payload or \"time\" not in payload[\"daily\"]:\n                raise ValueError(\"API response missing expected fields.\")\n            return payload\n        except Exception as exc:\n            print(f\"Attempt {attempt} failed: {exc}\")\n            if attempt == max_retries:\n                raise\n            time.sleep(backoff ** attempt)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:50:34.012925Z",
     "iopub.execute_input": "2025-12-28T12:50:34.013661Z",
     "iopub.status.idle": "2025-12-28T12:50:34.021110Z",
     "shell.execute_reply.started": "2025-12-28T12:50:34.013605Z",
     "shell.execute_reply": "2025-12-28T12:50:34.020255Z"
    }
   },
   "outputs": [],
   "execution_count": 107
  },
  {
   "id": "b8b45a4d",
   "cell_type": "code",
   "source": "weather_csv = MAIN_DATA_DIR / \"makueni_weather_2008_2025.csv\"\nchunks = split_date_range(start_date, end_date, max_days=365)\n\nif ENABLE_REMOTE_CALLS:\n    dfs = []\n    for s, e in chunks:\n        payload = fetch_chunk(latitude, longitude, s, e, timezone=timezone)\n        daily = payload[\"daily\"]\n        df_chunk = pd.DataFrame({\n            \"date\": daily[\"time\"],\n            \"temp_max\": daily.get(\"temperature_2m_max\"),\n            \"temp_min\": daily.get(\"temperature_2m_min\"),\n            \"temp_mean\": daily.get(\"temperature_2m_mean\"),\n            \"humidity_mean\": daily.get(\"relative_humidity_2m_mean\"),\n            \"rainfall_mm\": daily.get(\"precipitation_sum\"),\n            \"wind_speed_max\": daily.get(\"wind_speed_10m_max\"),\n            \"cloud_cover_percent\": daily.get(\"cloudcover_mean\"),\n        })\n        dfs.append(df_chunk)\n        time.sleep(1)\n    weather_df = pd.concat(dfs, ignore_index=True)\n    weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n    weather_df.sort_values(\"date\", inplace=True)\n    weather_df.to_csv(weather_csv, index=False)\n    print(\"Fetched and saved weather CSV to\", weather_csv)\nelse:\n    if weather_csv.exists():\n        weather_df = pd.read_csv(weather_csv, parse_dates=[\"date\"])\n        print(f\"Loaded cached weather data from {weather_csv}\")\n    else:\n        raise FileNotFoundError(f\"{weather_csv} not found; enable ENABLE_REMOTE_CALLS to regenerate.\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:50:38.962719Z",
     "iopub.execute_input": "2025-12-28T12:50:38.963333Z",
     "iopub.status.idle": "2025-12-28T12:51:06.402303Z",
     "shell.execute_reply.started": "2025-12-28T12:50:38.963307Z",
     "shell.execute_reply": "2025-12-28T12:51:06.401685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Fetched and saved weather CSV to /kaggle/working/content/main-data/makueni_weather_2008_2025.csv\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 108
  },
  {
   "id": "0bd89f0c",
   "cell_type": "code",
   "source": "ENABLE_REMOTE_CALLS = False  # Kaggle notebooks typically block outbound internet.\nndvi_csv = \"/kaggle/input/makueni-ndvi-2008-2025-csv/makueni_ndvi_2008_2025.csv\"\n\nif ENABLE_REMOTE_CALLS:\n    try:\n        ee.Initialize()\n    except Exception:\n        print(\"Authenticating with Earth Engine...\")\n        ee.Authenticate()\n        ee.Initialize()\n\n    point = ee.Geometry.Point([longitude, latitude])\n    modis = ee.ImageCollection(\"MODIS/061/MOD13Q1\").select(\"NDVI\").filterDate(start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")).filterBounds(point)\n\n    def extract_ndvi(image):\n        mean = image.reduceRegion(reducer=ee.Reducer.mean(), geometry=point, scale=250).get(\"NDVI\")\n        date = image.date().format(\"YYYY-MM-dd\")\n        return ee.Feature(None, {\"date\": date, \"ndvi_mean\": mean})\n\n    ndvi_fc = modis.map(extract_ndvi).getInfo()\n    records = [f[\"properties\"] for f in ndvi_fc[\"features\"]]\n    ndvi_df = pd.DataFrame(records)\n    ndvi_df[\"date\"] = pd.to_datetime(ndvi_df[\"date\"])\n    ndvi_df[\"ndvi_mean\"] = ndvi_df[\"ndvi_mean\"].astype(float) / 10000\n    ndvi_df.to_csv(ndvi_csv, index=False)\n    print(\"Fetched NDVI and saved to\", ndvi_csv)\nelse:\n    if ndvi_csv:\n        ndvi_df = pd.read_csv(ndvi_csv, parse_dates=[\"date\"])\n        print(f\"Loaded cached NDVI data from {ndvi_csv}\")\n    else:\n        raise FileNotFoundError(f\"{ndvi_csv} not found; enable ENABLE_REMOTE_CALLS to regenerate.\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:51:10.772035Z",
     "iopub.execute_input": "2025-12-28T12:51:10.772650Z",
     "iopub.status.idle": "2025-12-28T12:51:10.793213Z",
     "shell.execute_reply.started": "2025-12-28T12:51:10.772607Z",
     "shell.execute_reply": "2025-12-28T12:51:10.792673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Loaded cached NDVI data from /kaggle/input/makueni-ndvi-2008-2025-csv/makueni_ndvi_2008_2025.csv\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 109
  },
  {
   "id": "f84d3908",
   "cell_type": "code",
   "source": [
    "merged = weather_full.copy()\n",
    "merged_path = MAIN_DATA_DIR / \"makueni_climate_features.csv\"\n",
    "merged.to_csv(merged_path, index=False)\n",
    "print(\"Saved climate feature table ->\", merged_path)\n",
    "merged.head()\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:51:16.273470Z",
     "iopub.execute_input": "2025-12-28T12:51:16.274026Z",
     "iopub.status.idle": "2025-12-28T12:51:16.330325Z",
     "shell.execute_reply.started": "2025-12-28T12:51:16.273999Z",
     "shell.execute_reply": "2025-12-28T12:51:16.329660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Merged weather+NDVI -> /kaggle/working/content/main-data/makueni_weather_ndvi_2008_2025.csv\n",
     "output_type": "stream"
    },
    {
     "execution_count": 110,
     "output_type": "execute_result",
     "data": {
      "text/plain": "        date  temp_max  temp_min  temp_mean  humidity_mean  rainfall_mm  \\\n0 2008-01-01      24.9      16.4       20.3             74          1.2   \n1 2008-01-02      25.8      14.1       20.2             71          0.8   \n2 2008-01-03      27.2      15.2       21.3             65          0.0   \n3 2008-01-04      27.6      15.4       22.2             63          0.1   \n4 2008-01-05      27.3      15.2       21.0             75          2.9   \n\n   wind_speed_max  cloud_cover_percent  ndvi_mean  \n0            15.1                   53     0.6805  \n1            14.3                   19        NaN  \n2            12.8                   11        NaN  \n3            12.2                   26        NaN  \n4            13.1                   58        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>temp_max</th>\n      <th>temp_min</th>\n      <th>temp_mean</th>\n      <th>humidity_mean</th>\n      <th>rainfall_mm</th>\n      <th>wind_speed_max</th>\n      <th>cloud_cover_percent</th>\n      <th>ndvi_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-01-01</td>\n      <td>24.9</td>\n      <td>16.4</td>\n      <td>20.3</td>\n      <td>74</td>\n      <td>1.2</td>\n      <td>15.1</td>\n      <td>53</td>\n      <td>0.6805</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-01-02</td>\n      <td>25.8</td>\n      <td>14.1</td>\n      <td>20.2</td>\n      <td>71</td>\n      <td>0.8</td>\n      <td>14.3</td>\n      <td>19</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-01-03</td>\n      <td>27.2</td>\n      <td>15.2</td>\n      <td>21.3</td>\n      <td>65</td>\n      <td>0.0</td>\n      <td>12.8</td>\n      <td>11</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-01-04</td>\n      <td>27.6</td>\n      <td>15.4</td>\n      <td>22.2</td>\n      <td>63</td>\n      <td>0.1</td>\n      <td>12.2</td>\n      <td>26</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-01-05</td>\n      <td>27.3</td>\n      <td>15.2</td>\n      <td>21.0</td>\n      <td>75</td>\n      <td>2.9</td>\n      <td>13.1</td>\n      <td>58</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 110
  },
  {
   "id": "a59ea8ad-f1eb-4f9f-8c1c-65a3ae8b9e2c",
   "cell_type": "code",
   "source": "weather_full = df_merged.copy()\nprint('Weather+NDVI rows:', weather_full.shape)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:51:22.764568Z",
     "iopub.execute_input": "2025-12-28T12:51:22.764880Z",
     "iopub.status.idle": "2025-12-28T12:51:22.769807Z",
     "shell.execute_reply.started": "2025-12-28T12:51:22.764857Z",
     "shell.execute_reply": "2025-12-28T12:51:22.769038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Weather+NDVI rows: (6549, 9)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 111
  },
  {
   "id": "27121437",
   "cell_type": "code",
   "source": "df_month = df_merged.set_index(\"date\").resample(\"ME\").agg({\n    \"rainfall_mm\": \"sum\",\n    \"temp_mean\": \"mean\",\n    \"humidity_mean\": \"mean\",\n    \"ndvi_mean\": \"mean\"\n}).reset_index()\n\nfig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\naxes[0].plot(df_month[\"date\"], df_month[\"rainfall_mm\"], marker=\"o\")\naxes[0].set_title(\"Monthly Rainfall (mm)\")\n\naxes[1].plot(df_month[\"date\"], df_month[\"temp_mean\"], marker=\"o\", color=\"tomato\")\naxes[1].set_title(\"Monthly Mean Temperature (\u00b0C)\")\n\naxes[2].plot(df_month[\"date\"], df_month[\"ndvi_mean\"], marker=\"o\", color=\"green\")\naxes[2].set_title(\"Monthly NDVI Mean\")\n\nfor ax in axes:\n    ax.grid(True, alpha=0.3)\n    ax.set_ylabel(\"Value\")\n\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:51:25.651542Z",
     "iopub.execute_input": "2025-12-28T12:51:25.652273Z",
     "iopub.status.idle": "2025-12-28T12:51:25.905122Z",
     "shell.execute_reply.started": "2025-12-28T12:51:25.652247Z",
     "shell.execute_reply": "2025-12-28T12:51:25.904550Z"
    }
   },
   "outputs": [],
   "execution_count": 112
  },
  {
   "id": "7469a1c5-7c39-4950-ab79-c5537aaa7c18",
   "cell_type": "markdown",
   "source": "### Hive Telemetry & Synthetic Augmentation\n\nDirect hive telemetry from community partners is still sparse, so the notebook synthesizes weekly hive logs per hive id (Honey yield, Varroa %, hive weight, brood area, stress events). The generator preserves realistic ranges/variances and encodes queen age metadata so the downstream models can learn temporal drift patterns. When actual CSV exports (`hive_logs_2008_2025.csv`) exist they take precedence, keeping the pipeline faithful to the project scope in Chapter 3.\n",
   "metadata": {}
  },
  {
   "id": "8dea5e59",
   "cell_type": "code",
   "source": "hive_logs_path = MAIN_DATA_DIR / \"hive_logs_2008_2025.csv\"\nif hive_logs_path.exists():\n    hive_df = pd.read_csv(hive_logs_path, parse_dates=[\"date\"])\n    print(\"Loaded hive logs from\", hive_logs_path)\nelse:\n    print(\"No local hive logs detected; relying on W\u00fcrzburg telemetry for pretraining and climate-driven features.\")\n    hive_df = pd.DataFrame()\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:51:30.133391Z",
     "iopub.execute_input": "2025-12-28T12:51:30.134011Z",
     "iopub.status.idle": "2025-12-28T12:51:30.138988Z",
     "shell.execute_reply.started": "2025-12-28T12:51:30.133981Z",
     "shell.execute_reply": "2025-12-28T12:51:30.138213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "No local hive logs detected; relying on W\u00fcrzburg telemetry for pretraining and climate-driven features.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 113
  },
  {
   "id": "3c6f516c",
   "cell_type": "code",
   "source": "merged = pd.merge(hive_df, weather_full, on=\"date\", how=\"left\") if not hive_df.empty else weather_full.copy()\nmerged[\"yield_proxy\"] = merged.get(\"honey_yield_kg\", pd.Series(0, index=merged.index)).fillna(0)\nmerged_path = MAIN_DATA_DIR / \"merged_hive_weather_floral_2025.csv\"\nmerged.to_csv(merged_path, index=False)\nprint(\"Merged hive/weather/floral ->\", merged_path)\nmerged.head()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:51:33.793849Z",
     "iopub.execute_input": "2025-12-28T12:51:33.794141Z",
     "iopub.status.idle": "2025-12-28T12:51:33.842867Z",
     "shell.execute_reply.started": "2025-12-28T12:51:33.794116Z",
     "shell.execute_reply": "2025-12-28T12:51:33.842308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Merged hive/weather/floral -> /kaggle/working/content/main-data/merged_hive_weather_floral_2025.csv\n",
     "output_type": "stream"
    },
    {
     "execution_count": 114,
     "output_type": "execute_result",
     "data": {
      "text/plain": "        date  temp_max  temp_min  temp_mean  humidity_mean  rainfall_mm  \\\n0 2008-01-01      24.9      16.4       20.3             74          1.2   \n1 2008-01-02      25.8      14.1       20.2             71          0.8   \n2 2008-01-03      27.2      15.2       21.3             65          0.0   \n3 2008-01-04      27.6      15.4       22.2             63          0.1   \n4 2008-01-05      27.3      15.2       21.0             75          2.9   \n\n   wind_speed_max  cloud_cover_percent  ndvi_mean  yield_proxy  \n0            15.1                   53     0.6805            0  \n1            14.3                   19        NaN            0  \n2            12.8                   11        NaN            0  \n3            12.2                   26        NaN            0  \n4            13.1                   58        NaN            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>temp_max</th>\n      <th>temp_min</th>\n      <th>temp_mean</th>\n      <th>humidity_mean</th>\n      <th>rainfall_mm</th>\n      <th>wind_speed_max</th>\n      <th>cloud_cover_percent</th>\n      <th>ndvi_mean</th>\n      <th>yield_proxy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-01-01</td>\n      <td>24.9</td>\n      <td>16.4</td>\n      <td>20.3</td>\n      <td>74</td>\n      <td>1.2</td>\n      <td>15.1</td>\n      <td>53</td>\n      <td>0.6805</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-01-02</td>\n      <td>25.8</td>\n      <td>14.1</td>\n      <td>20.2</td>\n      <td>71</td>\n      <td>0.8</td>\n      <td>14.3</td>\n      <td>19</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-01-03</td>\n      <td>27.2</td>\n      <td>15.2</td>\n      <td>21.3</td>\n      <td>65</td>\n      <td>0.0</td>\n      <td>12.8</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-01-04</td>\n      <td>27.6</td>\n      <td>15.4</td>\n      <td>22.2</td>\n      <td>63</td>\n      <td>0.1</td>\n      <td>12.2</td>\n      <td>26</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-01-05</td>\n      <td>27.3</td>\n      <td>15.2</td>\n      <td>21.0</td>\n      <td>75</td>\n      <td>2.9</td>\n      <td>13.1</td>\n      <td>58</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 114
  },
  {
   "id": "70539f43-e972-4695-82b4-a1e06a65162d",
   "cell_type": "markdown",
   "source": "### Climate Feature Extraction\n\nDerive clean hourly climate+NDVI features ready for inference.\n",
   "metadata": {}
  },
  {
   "id": "c853922d-75e9-471f-8d84-101dd83f9bb8",
   "cell_type": "code",
   "source": "climate_features = df_merged[['date','rainfall_mm','temp_mean','humidity_mean','ndvi_mean']].copy()\nclimate_features = climate_features.sort_values('date').set_index('date')\nclimate_features = climate_features.interpolate(limit_direction='both')\nprint('Climate feature frame:', climate_features.shape)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:51:39.396681Z",
     "iopub.execute_input": "2025-12-28T12:51:39.397011Z",
     "iopub.status.idle": "2025-12-28T12:51:39.407630Z",
     "shell.execute_reply.started": "2025-12-28T12:51:39.396986Z",
     "shell.execute_reply": "2025-12-28T12:51:39.406941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Climate feature frame: (6549, 4)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 115
  },
  {
   "id": "2796d708-4402-452d-a94d-6671e7c1b9c3",
   "cell_type": "markdown",
   "source": "### W\u00fcrzburg Tabular Inference\n\nApply pretrained HGB to climate features for yield probability curves.\n",
   "metadata": {}
  },
  {
   "id": "1373c8bd-1431-4f82-96d1-399161705ba2",
   "cell_type": "code",
   "source": "WURZBURG_MODEL_PATH = MAIN_DATA_DIR / 'wurzb_hgb_yield.pkl'\nif not WURZBURG_MODEL_PATH.exists():\n    raise FileNotFoundError('Pretrained W\u00fcrzburg HGB missing')\nhgb_w = pd.read_pickle(WURZBURG_MODEL_PATH)\nclimate_X = climate_features[['rainfall_mm','temp_mean','humidity_mean','ndvi_mean']].fillna(0)\nyield_probs = hgb_w.predict_proba(climate_X)[:,1]\nclimate_features['predicted_yield_prob'] = yield_probs\nyield_forecast_path = MAIN_DATA_DIR / 'makueni_climate_yield_forecast.csv'\nclimate_features[['predicted_yield_prob']].to_csv(yield_forecast_path)\nprint('Saved climate yield forecast ->', yield_forecast_path)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:59:21.503776Z",
     "iopub.execute_input": "2025-12-28T12:59:21.504560Z",
     "iopub.status.idle": "2025-12-28T12:59:21.519076Z",
     "shell.execute_reply.started": "2025-12-28T12:59:21.504530Z",
     "shell.execute_reply": "2025-12-28T12:59:21.518150Z"
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/4041989765.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhgb_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWURZBURG_MODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclimate_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclimate_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rainfall_mm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'temp_mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'humidity_mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ndvi_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0myield_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhgb_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclimate_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mclimate_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_yield_prob'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myield_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0myield_forecast_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAIN_DATA_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'makueni_climate_yield_forecast.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2190\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2191\u001b[0m         \"\"\"\n\u001b[0;32m-> 2192\u001b[0;31m         \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\u001b[0m in \u001b[0;36m_raw_predict\u001b[0;34m(self, X, n_threads)\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0mis_binned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_in_fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_binned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\u001b[0m in \u001b[0;36m_preprocess_X\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mvalidate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \u001b[0mvalidated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2918\u001b[0m     \"\"\"\n\u001b[0;32m-> 2919\u001b[0;31m     \u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2920\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2921\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2775\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Feature names must be in the same order as they were in fit.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- humidity_mean\n- ndvi_mean\n- rainfall_mm\n- temp_mean\nFeature names seen at fit time, yet now missing:\n- flow\n- humidity\n- temperature\n- weight\n- weight_delta_24h\n"
     ],
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- humidity_mean\n- ndvi_mean\n- rainfall_mm\n- temp_mean\nFeature names seen at fit time, yet now missing:\n- flow\n- humidity\n- temperature\n- weight\n- weight_delta_24h\n",
     "output_type": "error"
    }
   ],
   "execution_count": 129
  },
  {
   "id": "a8b9617b-fc71-4e18-bf8a-4e5e934316f2",
   "cell_type": "markdown",
   "source": "### W\u00fcrzburg CNN Inference\n\nConvert climate sequences to windows and run the pretrained CNN to estimate occupancy risk.\n",
   "metadata": {}
  },
  {
   "id": "bd039058-154c-4847-b612-0793d5837d7a",
   "cell_type": "code",
   "source": [
    "WINDOW = 24  # match W\u00fcrzburg pretraining window\n",
    "climate_sequences = []\n",
    "for i in range(WINDOW, len(climate_features)):\n",
    "    window = climate_features.iloc[i-WINDOW:i][['rainfall_mm','temp_mean','humidity_mean','ndvi_mean']].values\n",
    "    if not np.any(np.isnan(window)):\n",
    "        climate_sequences.append(window)\n",
    "climate_sequences = np.array(climate_sequences, dtype=np.float32)\n",
    "print('Climate sequences:', climate_sequences.shape)\n",
    "cnn_model = HiveCNNBaseline(climate_sequences.shape[-1]).to(device)\n",
    "pretrain_path = MAIN_DATA_DIR / 'wurzburg_sequence_pretrain.pt'\n",
    "cnn_model.load_state_dict(torch.load(pretrain_path, map_location=device), strict=False)\n",
    "cnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    occupancy = torch.sigmoid(cnn_model(torch.tensor(climate_sequences).to(device))).cpu().numpy()\n",
    "forecast = climate_features.iloc[WINDOW:].copy()\n",
    "forecast['occupancy_risk'] = occupancy\n",
    "climate_forecast_path = MAIN_DATA_DIR / 'makueni_climate_occupancy_forecast.csv'\n",
    "forecast[['occupancy_risk']].to_csv(climate_forecast_path)\n",
    "print('Saved occupancy forecast ->', climate_forecast_path)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:59:27.092548Z",
     "iopub.execute_input": "2025-12-28T12:59:27.092861Z",
     "iopub.status.idle": "2025-12-28T12:59:30.087530Z",
     "shell.execute_reply.started": "2025-12-28T12:59:27.092838Z",
     "shell.execute_reply": "2025-12-28T12:59:30.086540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Climate sequences: (6525, 24, 4)\n",
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/1366746150.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclimate_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclimate_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Climate sequences:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclimate_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHiveCNNBaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclimate_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpretrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAIN_DATA_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'wurzburg_sequence_pretrain.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HiveCNNBaseline' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'HiveCNNBaseline' is not defined",
     "output_type": "error"
    }
   ],
   "execution_count": 130
  },
  {
   "id": "fdf170ba-8cf9-44c0-9d1c-59a8a3fbdcff",
   "cell_type": "markdown",
   "source": "### W\u00fcrzburg Dataset Staging\n\nOn Kaggle, stage the W\u00fcrzburg datasets just like the acoustic source: attach a dataset named `wurzb-hive-telemetry` (or similar) under `/kaggle/input`, then copy it into `content/wurzburg/` so the pretraining block can load from both local runs and Kaggle sessions.\n",
   "metadata": {}
  },
  {
   "id": "89eddb70-2b84-4d27-bbed-ec0fdd56ca76",
   "cell_type": "code",
   "source": "WURZBURG_INPUT_ROOT = Path('/kaggle/input')\nWURZBURG_TARGET = CONTENT_ROOT / 'bee-hive-metrics'\nif WURZBURG_INPUT_ROOT.exists():\n    candidates = [p for p in WURZBURG_INPUT_ROOT.iterdir() if 'bee-hive-metrics' in p.name.lower() or 'bee-hive-metrics' in p.name.lower()]\n    if candidates:\n        source = candidates[0]\n        WURZBURG_TARGET.mkdir(parents=True, exist_ok=True)\n        for csv_path in source.glob('*.csv'):\n            target_path = WURZBURG_TARGET / csv_path.name\n            if not target_path.exists():\n                shutil.copy(csv_path, target_path)\n        print(f\"Staged W\u00fcrzburg telemetry from {source} -> {WURZBURG_TARGET}\")\n    else:\n        print('No W\u00fcrzburg dataset attached under /kaggle/input; using existing content/wurzburg if present.')\nelse:\n    WURZBURG_TARGET.mkdir(parents=True, exist_ok=True)\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:54:04.740583Z",
     "iopub.execute_input": "2025-12-28T12:54:04.741251Z",
     "iopub.status.idle": "2025-12-28T12:54:07.619996Z",
     "shell.execute_reply.started": "2025-12-28T12:54:04.741224Z",
     "shell.execute_reply": "2025-12-28T12:54:07.619340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Staged W\u00fcrzburg telemetry from /kaggle/input/bee-hive-metrics -> /kaggle/working/content/bee-hive-metrics\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 121
  },
  {
   "id": "fc6876c4-1d4c-4aae-92ba-5b749bf787e0",
   "cell_type": "markdown",
   "source": "### W\u00fcrzburg/Schwartau Hive Telemetry Pretraining\n\nTo ground our synthetic Makueni logs in real telemetry, we ingest the W\u00fcrzburg/Schwartau sensor datasets (`content/wurzburg/*`). These CSVs provide minute-level hive weight, entrance flow, and local temperature/humidity measurements from 2017\u20132019. We aggregate them into hourly/daily features, derive proxy yield/ stress labels via rolling weight deltas, and use them to pretrain the tabular and sequence models before adapting to Makueni's climate distribution.\n",
   "metadata": {}
  },
  {
   "id": "af2f8cae-9c2d-46db-9936-10453d6b3b4c",
   "cell_type": "code",
   "source": "from pathlib import Path\nimport pandas as pd\n\nWURZBURG_DIR = CONTENT_ROOT / 'bee-hive-metrics'\nif not WURZBURG_DIR.exists():\n    raise FileNotFoundError(f\"Missing W\u00fcrzburg data at {WURZBURG_DIR}\")\n\n# Helper loader keeps timestamps sorted for consistent resampling\ndef load_sensor(name):\n    path = WURZBURG_DIR / name\n    df = pd.read_csv(path, parse_dates=['timestamp'])\n    df = df.sort_values('timestamp').set_index('timestamp')\n    return df\n\nweight_df = load_sensor('weight_wurzburg.csv')\ntemp_df = load_sensor('temperature_wurzburg.csv')\nhumidity_df = load_sensor('humidity_wurzburg.csv')\nflow_df = load_sensor('flow_wurzburg.csv')\n\nprint('Loaded sensors:', {\n    'weight': weight_df.shape,\n    'temperature': temp_df.shape,\n    'humidity': humidity_df.shape,\n    'flow': flow_df.shape\n})\n\n# Resample to hourly means and align\nhourly = pd.DataFrame({\n    'weight': weight_df['weight'].resample('1H').mean(),\n    'temperature': temp_df['temperature'].resample('1H').mean(),\n    'humidity': humidity_df['humidity'].resample('1H').mean(),\n    'flow': flow_df['flow'].resample('1H').mean(),\n})\nhourly = hourly.interpolate(limit_direction='both')\n\n# Derive proxy labels: positive weight change over 24h indicates nectar intake (yield), negative sustained drop indicates stress/harvest\nhourly['weight_delta_24h'] = hourly['weight'].diff(24)\nhourly['yield_positive'] = (hourly['weight_delta_24h'] > 0.5).astype(int)\nhourly['stress_event'] = (hourly['weight_delta_24h'] < -1.0).astype(int)\n\nhourly.reset_index(inplace=True)\nprint('Hourly feature set:', hourly.shape)\nhourly.head()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:54:21.453501Z",
     "iopub.execute_input": "2025-12-28T12:54:21.454083Z",
     "iopub.status.idle": "2025-12-28T12:54:25.183039Z",
     "shell.execute_reply.started": "2025-12-28T12:54:21.454054Z",
     "shell.execute_reply": "2025-12-28T12:54:25.182239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Loaded sensors: {'weight': (1035861, 1), 'temperature': (958831, 1), 'humidity': (20845, 1), 'flow': (2071720, 1)}\nHourly feature set: (20865, 8)\n",
     "output_type": "stream"
    },
    {
     "execution_count": 122,
     "output_type": "execute_result",
     "data": {
      "text/plain": "            timestamp     weight  temperature   humidity  flow  \\\n0 2017-01-01 05:00:00  52.695098    -0.327590  92.406667   0.0   \n1 2017-01-01 06:00:00  52.685200    -0.409250  92.270000   0.0   \n2 2017-01-01 07:00:00  52.688667    -0.668364  92.575000   0.0   \n3 2017-01-01 08:00:00  52.674267    -0.966858  92.840000   0.0   \n4 2017-01-01 09:00:00  52.595320    -1.623189  93.640000   0.0   \n\n   weight_delta_24h  yield_positive  stress_event  \n0               NaN               0             0  \n1               NaN               0             0  \n2               NaN               0             0  \n3               NaN               0             0  \n4               NaN               0             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>weight</th>\n      <th>temperature</th>\n      <th>humidity</th>\n      <th>flow</th>\n      <th>weight_delta_24h</th>\n      <th>yield_positive</th>\n      <th>stress_event</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-01-01 05:00:00</td>\n      <td>52.695098</td>\n      <td>-0.327590</td>\n      <td>92.406667</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-01-01 06:00:00</td>\n      <td>52.685200</td>\n      <td>-0.409250</td>\n      <td>92.270000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-01-01 07:00:00</td>\n      <td>52.688667</td>\n      <td>-0.668364</td>\n      <td>92.575000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-01-01 08:00:00</td>\n      <td>52.674267</td>\n      <td>-0.966858</td>\n      <td>92.840000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-01-01 09:00:00</td>\n      <td>52.595320</td>\n      <td>-1.623189</td>\n      <td>93.640000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 122
  },
  {
   "id": "32fe6dbf-e98f-4f4e-b1c9-93b7e3a48835",
   "cell_type": "markdown",
   "source": "#### W\u00fcrzburg Tabular Pretraining\n\nWe treat the hourly temperature/humidity/flow/weight statistics plus rolling deltas as features and pretrain a HistGradientBoostingClassifier to predict the proxy `yield_positive` label. This serves as an initialization for the Makueni model (via warm-start) and quantifies how real telemetry behaves before domain adaptation.\n",
   "metadata": {}
  },
  {
   "id": "4f85e72a-759a-4abf-8bfa-caf9283db893",
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score\n\nfeature_cols_w = ['weight', 'temperature', 'humidity', 'flow', 'weight_delta_24h']\nX_w = hourly[feature_cols_w].fillna(method='ffill').fillna(method='bfill')\ny_w = hourly['yield_positive']\n\nX_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X_w, y_w, test_size=0.2, random_state=42, stratify=y_w)\n\nhgb_w = HistGradientBoostingClassifier(max_depth=6, learning_rate=0.08, max_iter=300, class_weight='balanced')\nhgb_w.fit(X_train_w, y_train_w)\n\ny_pred_w = hgb_w.predict(X_test_w)\ny_prob_w = hgb_w.predict_proba(X_test_w)[:, 1]\n\nprint(classification_report(y_test_w, y_pred_w))\nprint('ROC-AUC:', roc_auc_score(y_test_w, y_prob_w))\n\n# Persist for transfer learning\nWURZBURG_MODEL_PATH = MAIN_DATA_DIR / 'wurzb_hgb_yield.pkl'\npd.to_pickle(hgb_w, WURZBURG_MODEL_PATH)\nprint('Saved W\u00fcrzburg HGB model ->', WURZBURG_MODEL_PATH)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:54:44.840513Z",
     "iopub.execute_input": "2025-12-28T12:54:44.841103Z",
     "iopub.status.idle": "2025-12-28T12:54:45.178927Z",
     "shell.execute_reply.started": "2025-12-28T12:54:44.841076Z",
     "shell.execute_reply": "2025-12-28T12:54:45.178093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      3940\n           1       0.97      1.00      0.98       233\n\n    accuracy                           1.00      4173\n   macro avg       0.98      1.00      0.99      4173\nweighted avg       1.00      1.00      1.00      4173\n\nROC-AUC: 0.9999771246813794\nSaved W\u00fcrzburg HGB model -> /kaggle/working/content/main-data/wurzb_hgb_yield.pkl\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 123
  },
  {
   "id": "900f2fba-0dab-4136-b504-40cdfc80c4d5",
   "cell_type": "markdown",
   "source": "#### Transfer to Makueni Tabular Model\n\nWe reuse the W\u00fcrzburg-trained gradient boosting model as initialization for the Makueni stress prediction: load `wurzb_hgb_yield.pkl`, continue training on the Makueni feature matrix, and compare against training-from-scratch baselines. This simple warm-start helps incorporate learned environmental response patterns despite limited local telemetry.\n",
   "metadata": {}
  },
  {
   "id": "541d34ec-5036-4a7c-9915-777541c8a68f",
   "cell_type": "markdown",
   "source": "#### W\u00fcrzburg Sequence Pretraining\n\nWe also slice the W\u00fcrzburg hourly features into temporal windows to pretrain the PyTorch sequence backbone. This yields a model familiar with real hive dynamics before fine-tuning on Makueni's synthetic/log-based sequences.\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "class HiveCNNBaseline(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "class HiveCNNRecurrent(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(128)\n",
    "        self.gru = nn.GRU(128, 64, batch_first=True, bidirectional=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.layer_norm(x)\n",
    "        _, h_n = self.gru(x)\n",
    "        h_n = h_n.transpose(0, 1).reshape(x.size(0), -1)\n",
    "        x = self.classifier(h_n)\n",
    "        return x.squeeze(-1)\n",
    "\n"
   ]
  },
  {
   "id": "5a2a89e8-a62d-4a36-9234-93d5d8292741",
   "cell_type": "code",
   "source": "# Slice W\u00fcrzburg hourly features into fixed windows for sequence pretraining\nWURZ_WINDOW = 24\nsequence_cols_w = ['weight', 'temperature', 'humidity', 'flow', 'weight_delta_24h']\nwurz_sequences = []\nwurz_labels = []\nfor i in range(WURZ_WINDOW, len(hourly)):\n    window = hourly.iloc[i-WURZ_WINDOW:i][sequence_cols_w].values\n    label = hourly.iloc[i]['yield_positive']\n    if not np.any(np.isnan(window)):\n        wurz_sequences.append(window)\n        wurz_labels.append(label)\n\nwurz_sequences = np.array(wurz_sequences, dtype=np.float32)\nwurz_labels = np.array(wurz_labels, dtype=np.float32)\nprint('W\u00fcrzburg sequences:', wurz_sequences.shape)\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:57:38.123791Z",
     "iopub.execute_input": "2025-12-28T12:57:38.124086Z",
     "iopub.status.idle": "2025-12-28T12:57:49.798332Z",
     "shell.execute_reply.started": "2025-12-28T12:57:38.124063Z",
     "shell.execute_reply": "2025-12-28T12:57:49.797678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "W\u00fcrzburg sequences: (20817, 24, 5)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 127
  },
  {
   "id": "520dc390-14ea-4a32-a804-200158026e7b",
   "cell_type": "markdown",
   "source": "##### Pretraining the Temporal CNN\n\nWe reuse the `SEQUENCE_MODEL_VARIANT='cnn'` architecture to pretrain on the W\u00fcrzburg sequences, save the weights, and later load them as initialization for the Makueni sequence training.\n",
   "metadata": {}
  },
  {
   "id": "76106549-72c3-43c3-b54b-51405eb37996",
   "cell_type": "code",
   "source": "from torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\n# Lightweight dataset wrapper so PyTorch loaders can stream W\u00fcrzburg sequences\nclass WurzburgDataset(Dataset):\n    def __init__(self, sequences, labels):\n        self.X = torch.tensor(sequences, dtype=torch.float32)\n        self.y = torch.tensor(labels, dtype=torch.float32)\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\nX_train_wseq, X_val_wseq, y_train_wseq, y_val_wseq = train_test_split(\n    wurz_sequences, wurz_labels, test_size=0.2, random_state=42, stratify=wurz_labels)\n\nw_train_ds = WurzburgDataset(X_train_wseq, y_train_wseq)\nw_val_ds = WurzburgDataset(X_val_wseq, y_val_wseq)\nw_train_loader = DataLoader(w_train_ds, batch_size=128, shuffle=True)\nw_val_loader = DataLoader(w_val_ds, batch_size=128, shuffle=False)\n\npretrain_model = HiveCNNBaseline(input_channels=len(sequence_cols_w)).to(device)\npretrain_optimizer = torch.optim.Adam(pretrain_model.parameters(), lr=1e-3, weight_decay=1e-4)\npretrain_criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor((len(y_train_wseq)-y_train_wseq.sum())/max(y_train_wseq.sum(),1), device=device))\n\ndef run_pretrain_epoch(loader, train=True):\n    pretrain_model.train(train)\n    total_loss=0\n    preds=[]\n    targets=[]\n    for batch_X, batch_y in loader:\n        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n        pretrain_optimizer.zero_grad()\n        with torch.set_grad_enabled(train):\n            logits = pretrain_model(batch_X)\n            loss = pretrain_criterion(logits, batch_y)\n            if train:\n                loss.backward()\n                pretrain_optimizer.step()\n        total_loss += loss.item()*batch_X.size(0)\n        preds.append(torch.sigmoid(logits).detach().cpu().numpy())\n        targets.append(batch_y.detach().cpu().numpy())\n    preds = np.concatenate(preds)\n    targets = np.concatenate(targets)\n    return total_loss/len(loader.dataset), roc_auc_score(targets, preds)\n\n# Train for a few epochs and persist the best validation AUC weights\nprint('Pretraining sequence model on W\u00fcrzburg data...')\nbest_auc = 0\nfor epoch in range(10):\n    train_loss, train_auc = run_pretrain_epoch(w_train_loader, True)\n    val_loss, val_auc = run_pretrain_epoch(w_val_loader, False)\n    print(f'Epoch {epoch+1:02d}: train_loss={train_loss:.4f} AUC={train_auc:.3f} | val_loss={val_loss:.4f} AUC={val_auc:.3f}')\n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(pretrain_model.state_dict(), MAIN_DATA_DIR / 'wurzburg_sequence_pretrain.pt')\nprint('Saved W\u00fcrzburg sequence weights ->', MAIN_DATA_DIR / 'wurzburg_sequence_pretrain.pt')\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T12:58:17.531649Z",
     "iopub.execute_input": "2025-12-28T12:58:17.532394Z",
     "iopub.status.idle": "2025-12-28T12:58:17.586193Z",
     "shell.execute_reply.started": "2025-12-28T12:58:17.532366Z",
     "shell.execute_reply": "2025-12-28T12:58:17.585319Z"
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/1543283788.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mw_val_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_val_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mpretrain_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHiveCNNBaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_cols_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mpretrain_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mpretrain_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_wseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_train_wseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_wseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HiveCNNBaseline' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'HiveCNNBaseline' is not defined",
     "output_type": "error"
    }
   ],
   "execution_count": 128
  }
 ]
}