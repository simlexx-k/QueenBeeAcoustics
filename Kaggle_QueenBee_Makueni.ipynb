{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 12134294,
     "sourceType": "datasetVersion",
     "datasetId": 7505074
    },
    {
     "sourceId": 14288414,
     "sourceType": "datasetVersion",
     "datasetId": 9120225
    }
   ],
   "dockerImageVersionId": 31234,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "fdc48dcf",
   "cell_type": "markdown",
   "source": "# Kaggle Cloud Ops: Queen Bee Acoustics + Makueni Apiary Intelligence",
   "metadata": {}
  },
  {
   "id": "9325b117",
   "cell_type": "markdown",
   "source": "This unified notebook stitches together:\n\n1. **Queen Bee acoustic detection (CNN + hyperparameter tuning)**\n2. **Makueni Apiary intelligence workflows (weather, NDVI, telemetry, hive stress ML)**\n\n> **Kaggle usage:** Attach the `harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen` dataset plus any `content/main-data` exports as Kaggle data sources. All intermediate files are written under `content/` so the same notebook also works locally.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeeUnity System Blueprint\n",
    "\n",
    "BeeUnity couples two complementary sensing/analytics tracks inside a single reproducible notebook.\n",
    "\n",
    "- **Acoustic intelligence (Sections \u00a73-15)** ingests the Kaggle beehive audio corpus, generates mel spectrograms, and trains/ tunes a convolutional network for multi-class queen state detection. The outputs are calibrated probabilities + decision thresholds that can be streamed into downstream alerting or fusion models.\n",
    "- **Makueni apiary intelligence (Sections \u00a717 onwards)** orchestrates weather/NDVI staging, hive log synthesis, and two tiers of ML models (sklearn HistGradientBoosting + PyTorch temporal CNN/GRU) to estimate hive stress / occupancy risk.\n",
    "\n",
    "Every block includes deterministic filesystem staging and writes intermediate products to `/kaggle/working` or `content/` so the research report can quote exact metrics while Kaggle submissions remain GPU safe.\n"
   ]
  },
  {
   "id": "ffc483a3",
   "cell_type": "code",
   "source": "!pip install -q earthengine-api ipyleaflet ipywidgets keras-tuner librosa tqdm",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:00:56.514162Z",
     "iopub.execute_input": "2025-12-25T08:00:56.514847Z",
     "iopub.status.idle": "2025-12-25T08:00:59.989726Z",
     "shell.execute_reply.started": "2025-12-25T08:00:56.514817Z",
     "shell.execute_reply": "2025-12-25T08:00:59.988666Z"
    }
   },
   "outputs": [],
   "execution_count": 77
  },
  {
   "id": "422e9772",
   "cell_type": "code",
   "source": "import os\nimport shutil\nfrom pathlib import Path\n\nPROJECT_ROOT = Path.cwd()\nDEFAULT_CONTENT = PROJECT_ROOT / \"content\"\nKAGGLE_WORKING = Path(\"/kaggle/working\")\n\nif DEFAULT_CONTENT.exists():\n    CONTENT_ROOT = DEFAULT_CONTENT.resolve()\nelse:\n    CONTENT_ROOT = (KAGGLE_WORKING / \"content\").resolve()\n    CONTENT_ROOT.mkdir(parents=True, exist_ok=True)\n\nos.environ[\"MERGED_CONTENT_ROOT\"] = str(CONTENT_ROOT)\nMAIN_DATA_DIR = (CONTENT_ROOT / \"main-data\")\nMAIN_DATA_DIR.mkdir(parents=True, exist_ok=True)\n\nKAGGLE_INPUT_ROOT = Path(\"/kaggle/input\")\n\ndef _stage_dataset(keyword, target_subdir):\n    if not KAGGLE_INPUT_ROOT.exists():\n        return None\n    matches = [p for p in KAGGLE_INPUT_ROOT.iterdir() if keyword in p.name.lower()]\n    if not matches:\n        print(f\"[setup] Kaggle input dataset containing '{keyword}' not found.\")\n        return None\n    source = matches[0]\n    target = CONTENT_ROOT / target_subdir\n    shutil.rmtree(target, ignore_errors=True)\n    shutil.copytree(source, target, dirs_exist_ok=True)\n    print(f\"[setup] Staged {source.name} -> {target}\")\n    return target\n\ndef _maybe_stage(keyword, subdir):\n    try:\n        _stage_dataset(keyword, subdir)\n    except Exception as exc:\n        print(f\"[setup] Skipping auto-stage for {keyword}: {exc}\")\n\n_maybe_stage(\"beehive\", \"beehive_audio\")\n_maybe_stage(\"makueni\", \"main-data\")\n\nprint(f\"CONTENT_ROOT -> {CONTENT_ROOT}\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:00:59.991485Z",
     "iopub.execute_input": "2025-12-25T08:00:59.991741Z",
     "iopub.status.idle": "2025-12-25T08:02:03.487547Z",
     "shell.execute_reply.started": "2025-12-25T08:00:59.991717Z",
     "shell.execute_reply": "2025-12-25T08:02:03.486718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "[setup] Staged beehive-audio-dataset-with-queen-and-without-queen -> /kaggle/working/content/beehive_audio\n[setup] Staged makueni-ndvi-2008-2025-csv -> /kaggle/working/content/main-data\nCONTENT_ROOT -> /kaggle/working/content\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 78
  },
  {
   "id": "e8446e4b",
   "cell_type": "code",
   "source": [
    "import calendar\n",
    "import datetime as dt\n",
    "import gc\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras_tuner as kt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    RocCurveDisplay\n",
    ")\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import requests\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "CONTENT_ROOT = Path(os.environ[\"MERGED_CONTENT_ROOT\"])\n",
    "MAIN_DATA_DIR = CONTENT_ROOT / \"main-data\"\n",
    "from pathlib import Path\n",
    "FIGURE_DIR = Path('artifacts/figures')\n",
    "FIGURE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Saving figures and tables to', FIGURE_DIR.resolve())\n",
    "\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:03.488539Z",
     "iopub.execute_input": "2025-12-25T08:02:03.489137Z",
     "iopub.status.idle": "2025-12-25T08:02:03.497923Z",
     "shell.execute_reply.started": "2025-12-25T08:02:03.489114Z",
     "shell.execute_reply": "2025-12-25T08:02:03.497211Z"
    }
   },
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "FIGURE_DIR = Path('artifacts/figures')\n",
    "FIGURE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Saving figures and tables to', FIGURE_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "FIGURE_DIR = Path('/kaggle/working/figures')\n",
    "FIGURE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Saving figures and tables to', FIGURE_DIR)\n"
   ]
  },
  {
   "id": "00311da8",
   "cell_type": "markdown",
   "source": "## Queen Bee Acoustic Detection Pipeline",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acoustic Dataset Staging & Lineage\n",
    "\n",
    "The queen-bee classifier is trained from the Kaggle dataset `harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen`. We avoid copying raw WAVs into writable storage unless needed; instead, `_discover_audio_dataset` crawls the mounted `/kaggle/input` tree, validates the folder structure, and exposes canonical paths for the `QueenBee Present`, `QueenBee Absent`, and `External Noise` subsets. This guarantees that every spectrogram (and therefore every model checkpoint) can be traced back to a known dataset version, satisfying the reproducibility requirement in the BeeUnity methodology.\n"
   ]
  },
  {
   "id": "1c46188a",
   "cell_type": "code",
   "source": "from pathlib import Path\n\ndef _discover_audio_dataset(content_root: Path) -> Path:\n    search_root = Path(\"/kaggle/input/beehive-audio-dataset-with-queen-and-without-queen\")\n    if not search_root.exists():\n        raise FileNotFoundError(\n            \"Dataset not staged. Attach Kaggle dataset \"\n            \"'harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen'.\"\n        )\n\n    for candidate in sorted(search_root.rglob(\"Dataset\")):\n        if (candidate / \"Bee Hive Audios\").exists():\n            return candidate\n\n    raise FileNotFoundError(\"Could not locate 'Dataset/Bee Hive Audios'.\")\n\n# Discover dataset (READ-ONLY)\nAUDIO_DATASET_ROOT = _discover_audio_dataset(None)\n\nBEEHIVE_AUDIO_DIR = next(AUDIO_DATASET_ROOT.glob(\"**/Bee Hive Audios\"))\nQUEEN_PRESENT_DIR = BEEHIVE_AUDIO_DIR / \"QueenBee Present\"\nQUEEN_ABSENT_DIR = BEEHIVE_AUDIO_DIR / \"QueenBee Absent\"\nEXTERNAL_DIR = AUDIO_DATASET_ROOT / \"External Noise\"\n\n# WRITEABLE spectrogram directory\nSPECTROGRAM_DIR = Path(\"/kaggle/working/spectrograms\")\nSPECTROGRAM_PRESENT = SPECTROGRAM_DIR / \"present\"\nSPECTROGRAM_ABSENT = SPECTROGRAM_DIR / \"absent\"\nSPECTROGRAM_EXTERNAL = SPECTROGRAM_DIR / \"external\"\n\nfor path in [SPECTROGRAM_PRESENT, SPECTROGRAM_ABSENT, SPECTROGRAM_EXTERNAL]:\n    path.mkdir(parents=True, exist_ok=True)\n\nprint(\"Audio dataset root (read-only):\", AUDIO_DATASET_ROOT)\nprint(\"Spectrogram cache (writable):\", SPECTROGRAM_DIR)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:03.499515Z",
     "iopub.execute_input": "2025-12-25T08:02:03.499822Z",
     "iopub.status.idle": "2025-12-25T08:02:06.668384Z",
     "shell.execute_reply.started": "2025-12-25T08:02:03.499768Z",
     "shell.execute_reply": "2025-12-25T08:02:06.667757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Audio dataset root (read-only): /kaggle/input/beehive-audio-dataset-with-queen-and-without-queen/Dataset\nSpectrogram cache (writable): /kaggle/working/spectrograms\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 80
  },
  {
   "id": "5601ca8a",
   "cell_type": "code",
   "source": "try:\n    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu_resolver)\n    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n    strategy = tf.distribute.TPUStrategy(tpu_resolver)\n    ACCELERATOR = \"TPU\"\nexcept (ValueError, tf.errors.NotFoundError):\n    gpus = tf.config.list_physical_devices(\"GPU\")\n    if gpus:\n        for gpu in gpus:\n            try:\n                tf.config.experimental.set_memory_growth(gpu, True)\n            except Exception:\n                pass\n        # Default to single-replica strategy for Kaggle GPU stability\n        strategy = tf.distribute.get_strategy()\n        ACCELERATOR = \"GPU\"\n    else:\n        strategy = tf.distribute.get_strategy()\n        ACCELERATOR = \"CPU\"\n\nprint(f\"Using {ACCELERATOR} via {strategy.__class__.__name__}\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:06.669148Z",
     "iopub.execute_input": "2025-12-25T08:02:06.669351Z",
     "iopub.status.idle": "2025-12-25T08:02:06.675392Z",
     "shell.execute_reply.started": "2025-12-25T08:02:06.669333Z",
     "shell.execute_reply": "2025-12-25T08:02:06.674695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Using GPU via _DefaultDistributionStrategy\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Conditioning & Spectrogram Cache\n",
    "\n",
    "To stabilize CNN training we transform each WAV into a fixed 3-second mono clip sampled at 22.05 kHz. The `preprocess_and_save_spectrogram` routine trims silence, enforces constant-length padding, normalizes amplitude, and renders a 128\u00d7128 mel-spectrogram using librosa. Spectrograms land under `/kaggle/working/spectrograms/<class>/` and the generators only touch PNGs, eliminating expensive audio decoding during model fit. Progress-aware helpers (e.g., `_compute_progress`) let reruns skip already materialized windows so Kaggle GPU runtime stays within budget.\n"
   ]
  },
  {
   "id": "20b2348e",
   "cell_type": "code",
   "source": "SAMPLE_RATE = 22050\nDURATION = 3\nSAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n\nlibrosa.cache.clear()\nplt.switch_backend(\"Agg\")\n\ndef preprocess_and_save_spectrogram(audio_path: Path, output_image_path: Path, sr=SAMPLE_RATE, duration=DURATION):\n    try:\n        y, _ = librosa.load(audio_path, sr=sr)\n        y, _ = librosa.effects.trim(y)\n        y = librosa.to_mono(y) if y.ndim > 1 else y\n        y = librosa.util.normalize(y)\n\n        expected_samples = sr * duration\n        if len(y) < expected_samples:\n            y = np.pad(y, (0, expected_samples - len(y)), mode=\"constant\")\n        else:\n            y = y[:expected_samples]\n\n        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n        mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n\n        plt.figure(figsize=(2, 2), dpi=64)\n        librosa.display.specshow(mel_db, sr=sr, cmap=\"magma\")\n        plt.axis(\"off\")\n        output_image_path.parent.mkdir(parents=True, exist_ok=True)\n        plt.savefig(output_image_path, bbox_inches=\"tight\", pad_inches=0)\n        plt.close()\n    except Exception as exc:\n        print(f\"[spectrogram] Failed on {audio_path}: {exc}\")\n\ndef _compute_progress(files, output_dir: Path):\n    total = len(files)\n    processed = sum((output_dir / f\"{Path(f).stem}.png\").exists() for f in files)\n    return total, processed\n\ndef process_audio_folder(input_dir: Path, output_dir: Path, desc: str):\n    if not input_dir.exists():\n        print(f\"[spectrogram] {input_dir} missing, skipping {desc}.\")\n        return\n    wav_files = sorted([f for f in input_dir.iterdir() if f.suffix.lower() == \".wav\"])\n    total, processed = _compute_progress([f.name for f in wav_files], output_dir)\n    with tqdm(total=total, initial=processed, desc=desc, unit=\"file\") as pbar:\n        for wav_path in wav_files:\n            out_path = output_dir / f\"{wav_path.stem}.png\"\n            if out_path.exists():\n                pbar.update(1)\n                continue\n            preprocess_and_save_spectrogram(wav_path, out_path)\n            gc.collect()\n            pbar.update(1)\n\ndef process_external_folder(input_dir: Path, output_dir: Path):\n    if not input_dir.exists():\n        print(\"[spectrogram] External noise folder missing, skipping.\")\n        return\n    audio_paths = []\n    for root, _, files in os.walk(input_dir):\n        audio_paths += [Path(root) / f for f in files if f.lower().endswith(\".wav\")]\n    with tqdm(total=len(audio_paths), desc=\"External noise\", unit=\"file\") as pbar:\n        for wav_path in audio_paths:\n            out_path = output_dir / f\"{wav_path.stem}.png\"\n            if out_path.exists():\n                pbar.update(1)\n                continue\n            preprocess_and_save_spectrogram(wav_path, out_path)\n            pbar.update(1)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:06.676310Z",
     "iopub.execute_input": "2025-12-25T08:02:06.676864Z",
     "iopub.status.idle": "2025-12-25T08:02:06.703360Z",
     "shell.execute_reply.started": "2025-12-25T08:02:06.676841Z",
     "shell.execute_reply": "2025-12-25T08:02:06.702822Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "[Memory(location=None)]: Flushing completely the cache\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 82
  },
  {
   "id": "5194f6d3",
   "cell_type": "code",
   "source": "process_audio_folder(QUEEN_PRESENT_DIR, SPECTROGRAM_PRESENT, \"QueenBee Present\")\nprocess_audio_folder(QUEEN_ABSENT_DIR, SPECTROGRAM_ABSENT, \"QueenBee Absent\")\nprocess_external_folder(EXTERNAL_DIR, SPECTROGRAM_EXTERNAL)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:06.704036Z",
     "iopub.execute_input": "2025-12-25T08:02:06.704211Z",
     "iopub.status.idle": "2025-12-25T08:02:06.999704Z",
     "shell.execute_reply.started": "2025-12-25T08:02:06.704195Z",
     "shell.execute_reply": "2025-12-25T08:02:06.999041Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "QueenBee Present: 8000file [00:00, 77319.70file/s]             \nQueenBee Absent: 4000file [00:00, 80590.73file/s]             \nExternal noise: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:00<00:00, 59606.97file/s]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 83
  },
  {
   "id": "fb90b30b",
   "cell_type": "code",
   "source": "def count_pngs(folder: Path):\n    return len([f for f in folder.glob(\"*.png\")])\n\nclass_labels = [\"present\", \"absent\", \"external\"]\ncounts = [\n    count_pngs(SPECTROGRAM_PRESENT),\n    count_pngs(SPECTROGRAM_ABSENT),\n    count_pngs(SPECTROGRAM_EXTERNAL),\n]\n\nplt.figure(figsize=(6, 4))\nbars = plt.bar(class_labels, counts, color=[\"sienna\", \"peru\", \"gray\"], edgecolor=\"black\")\nplt.ylim(0, max(counts) * 1.1 if counts else 10)\nplt.title(\"Spectrogram Count per Class\")\nplt.ylabel(\"Images\")\nfor bar in bars:\n    y = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width() / 2, y + max(1, y ** 0.5), int(y), ha=\"center\", va=\"bottom\")\nplt.show()\n\nprint(dict(zip(class_labels, counts)))\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:07.000624Z",
     "iopub.execute_input": "2025-12-25T08:02:07.000853Z",
     "iopub.status.idle": "2025-12-25T08:02:07.083161Z",
     "shell.execute_reply.started": "2025-12-25T08:02:07.000832Z",
     "shell.execute_reply": "2025-12-25T08:02:07.082594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "{'present': 4000, 'absent': 2000, 'external': 2000}\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified DataFrames, Augmentation, and Class Weights\n",
    "\n",
    "The original ImageDataGenerator split approach caused leakage between validation/test folds. We now build a pandas catalog of every spectrogram file, stratify it into train/val/test via `train_test_split`, and feed `flow_from_dataframe` generators. Light-weight augmentations (flip + shifts) only touch the training subset. Class imbalance (present:absent:external = 4000:2000:2000) is mitigated through `compute_class_weight` and a custom `SparseClassRecall` metric that explicitly tracks recall on the underrepresented `absent` class; both feed into every Keras fit/tuning call so the notebook\u2019s metrics align with the research objective of catching queen loss events.\n"
   ]
  },
  {
   "id": "b1438348",
   "cell_type": "code",
   "source": "IMG_SIZE = (128, 128)\nBASE_BATCH_SIZE = 32\nBATCH_SIZE = BASE_BATCH_SIZE  # Keep per-device batch size stable on Kaggle\nSEED = 42\n\nspectro_records = []\nfor class_dir in sorted(SPECTROGRAM_DIR.iterdir()):\n    if class_dir.is_dir():\n        label = class_dir.name\n        for img_path in class_dir.glob(\"*.png\"):\n            spectro_records.append({\"filepath\": str(img_path), \"label\": label})\n\nif not spectro_records:\n    raise RuntimeError(\"No spectrograms were generated; run preprocessing above first.\")\n\nspectro_df = pd.DataFrame(spectro_records)\nCLASS_NAMES = sorted(spectro_df[\"label\"].unique())\n\ntrain_df, temp_df = train_test_split(\n    spectro_df,\n    test_size=0.4,\n    stratify=spectro_df[\"label\"],\n    random_state=SEED\n)\nval_df, test_df = train_test_split(\n    temp_df,\n    test_size=0.5,\n    stratify=temp_df[\"label\"],\n    random_state=SEED\n)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    horizontal_flip=True,\n    width_shift_range=0.05,\n    height_shift_range=0.05\n)\neval_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_gen = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"sparse\",\n    classes=CLASS_NAMES,\n    shuffle=True,\n    seed=SEED\n)\n\nval_gen = eval_datagen.flow_from_dataframe(\n    val_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"sparse\",\n    classes=CLASS_NAMES,\n    shuffle=False,\n    seed=SEED\n)\n\ntest_gen = eval_datagen.flow_from_dataframe(\n    test_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"sparse\",\n    classes=CLASS_NAMES,\n    shuffle=False,\n    seed=SEED\n)\n\nraw_class_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.array(CLASS_NAMES),\n    y=train_df[\"label\"]\n)\nCLASS_WEIGHTS = {\n    train_gen.class_indices[label]: weight for label, weight in zip(CLASS_NAMES, raw_class_weights)\n}\nprint(\"Class indices:\", train_gen.class_indices)\nprint(\"Class weights:\", CLASS_WEIGHTS)\n\nABSENT_CLASS_INDEX = train_gen.class_indices[\"absent\"]\n\nclass SparseClassRecall(tf.keras.metrics.Metric):\n    def __init__(self, class_id, name=\"sparse_class_recall\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.class_id = class_id\n        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.false_negatives = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.cast(tf.reshape(y_true, [-1]), tf.int32)\n        y_pred = tf.cast(tf.argmax(y_pred, axis=-1), tf.int32)\n        class_mask = tf.cast(tf.equal(y_true, self.class_id), self.dtype)\n        pred_mask = tf.cast(tf.equal(y_pred, self.class_id), self.dtype)\n        if sample_weight is None:\n            weights = tf.ones_like(class_mask)\n        else:\n            weights = tf.cast(tf.reshape(sample_weight, [-1]), self.dtype)\n            weights = tf.broadcast_to(weights, tf.shape(class_mask))\n        weighted_mask = class_mask * weights\n        tp = tf.reduce_sum(pred_mask * weighted_mask)\n        fn = tf.reduce_sum((1.0 - pred_mask) * weighted_mask)\n        self.true_positives.assign_add(tp)\n        self.false_negatives.assign_add(fn)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\"class_id\": int(self.class_id)})\n        return config\n\n    def result(self):\n        return tf.math.divide_no_nan(self.true_positives, self.true_positives + self.false_negatives)\n\n    def reset_states(self):\n        self.true_positives.assign(0.0)\n        self.false_negatives.assign(0.0)\n\ndef make_absent_recall(name=\"recall_absent\"):\n    return SparseClassRecall(class_id=ABSENT_CLASS_INDEX, name=name)\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:07.084084Z",
     "iopub.execute_input": "2025-12-25T08:02:07.084412Z",
     "iopub.status.idle": "2025-12-25T08:02:07.211572Z",
     "shell.execute_reply.started": "2025-12-25T08:02:07.084380Z",
     "shell.execute_reply": "2025-12-25T08:02:07.211012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Found 4800 validated image filenames belonging to 3 classes.\nFound 1600 validated image filenames belonging to 3 classes.\nFound 1600 validated image filenames belonging to 3 classes.\nClass indices: {'absent': 0, 'external': 1, 'present': 2}\nClass weights: {0: np.float64(1.3333333333333333), 1: np.float64(1.3333333333333333), 2: np.float64(0.6666666666666666)}\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline CNN Training Plan\n",
    "\n",
    "The baseline network is intentionally compact so it trains quickly on Kaggle GPUs yet captures salient spectral patterns: three Conv-BN-Pool stages followed by GAP and a 64-unit dense head. Training runs under the selected `strategy` with class weights + early stopping keyed to `val_recall_absent` to bias the model toward correctly flagging queen-absent clips. This baseline establishes the minimum viable performance before hyperparameter search.\n"
   ]
  },
  {
   "id": "a233e93a",
   "cell_type": "code",
   "source": "from tensorflow.keras.callbacks import EarlyStopping\n\ndef build_baseline_model():\n    model = models.Sequential([\n        layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\", input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(64, activation=\"relu\"),\n        layers.Dropout(0.5),\n        layers.Dense(3, activation=\"softmax\"),\n    ])\n    model.compile(\n        optimizer=\"adam\",\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\", make_absent_recall()]\n    )\n    return model\n\nwith strategy.scope():\n    baseline_model = build_baseline_model()\n\nbaseline_callbacks = [\n    EarlyStopping(monitor=\"val_recall_absent\", mode=\"max\", patience=3, restore_best_weights=True)\n]\n\nbaseline_history = baseline_model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=20,\n    class_weight=CLASS_WEIGHTS,\n    callbacks=baseline_callbacks\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:02:07.213854Z",
     "iopub.execute_input": "2025-12-25T08:02:07.214130Z",
     "iopub.status.idle": "2025-12-25T08:03:37.052571Z",
     "shell.execute_reply.started": "2025-12-25T08:02:07.214109Z",
     "shell.execute_reply": "2025-12-25T08:03:37.051920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 144ms/step - accuracy: 0.7123 - loss: 0.6749 - recall_absent: 0.7678 - val_accuracy: 0.5294 - val_loss: 1.1168 - val_recall_absent: 0.0000e+00\nEpoch 2/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 140ms/step - accuracy: 0.8961 - loss: 0.2786 - recall_absent: 0.9125 - val_accuracy: 0.3481 - val_loss: 1.7710 - val_recall_absent: 0.0000e+00\nEpoch 3/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 140ms/step - accuracy: 0.9316 - loss: 0.1825 - recall_absent: 0.9241 - val_accuracy: 0.2500 - val_loss: 5.2762 - val_recall_absent: 0.0000e+00\nEpoch 4/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 140ms/step - accuracy: 0.9405 - loss: 0.1604 - recall_absent: 0.9390 - val_accuracy: 0.7387 - val_loss: 2.5434 - val_recall_absent: 0.0000e+00\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KerasTuner Hyperband Search & Fine-Tune\n",
    "\n",
    "Hyperparameter tuning explores filter widths, dense units, dropout, and optimizer choice via `kt.Hyperband`, again optimizing `val_recall_absent`. The tuner runs outside the distribution `strategy` scope (per TensorFlow guidance) while the search/ fine-tune phases inherit the same class weights + early stopping regime as the baseline. The best trial is persisted as a `.keras` artifact under `/kaggle/working` for downstream deployment / report inclusion.\n"
   ]
  },
  {
   "id": "75194ab4",
   "cell_type": "code",
   "source": "from tensorflow.keras.callbacks import EarlyStopping\nfrom pathlib import Path\n\ndef build_tunable_model(hp):\n    model = models.Sequential([\n        layers.Conv2D(\n            hp.Choice(\"conv1\", [32, 64]), 3,\n            activation=\"relu\", padding=\"same\",\n            input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n        ),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.Conv2D(hp.Choice(\"conv2\", [64, 128]), 3, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.Conv2D(hp.Choice(\"conv3\", [128, 256]), 3, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(hp.Int(\"dense_units\", 64, 128, step=32), activation=\"relu\"),\n        layers.Dropout(hp.Float(\"dropout\", 0.3, 0.6, step=0.1)),\n        layers.Dense(3, activation=\"softmax\"),\n    ])\n\n    model.compile(\n        optimizer=hp.Choice(\"optimizer\", [\"adam\", \"nadam\"]),\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\", make_absent_recall()]\n    )\n    return model\n\n\n# Strategy ONLY for tuner creation\nwith strategy.scope():\n    tuner = kt.Hyperband(\n        build_tunable_model,\n        objective=kt.Objective(\"val_recall_absent\", direction=\"max\"),\n        max_epochs=15,\n        factor=3,\n        directory=\"/kaggle/working/queenbee_tuning\",\n        project_name=\"queenbee_cnn\"\n    )\n\nstopper = EarlyStopping(\n    monitor=\"val_recall_absent\",\n    mode=\"max\",\n    patience=3,\n    restore_best_weights=True\n)\n\n# Search OUTSIDE strategy scope\ntuner.search(\n    train_gen,\n    validation_data=val_gen,\n    epochs=15,\n    class_weight=CLASS_WEIGHTS,\n    callbacks=[stopper]\n)\n\n# NO strategy scope here\nbest_model = tuner.get_best_models(num_models=1)[0]\n\nfine_tune_history = best_model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=15,\n    class_weight=CLASS_WEIGHTS,\n    callbacks=[stopper]\n)\n\n# Writable save path\nbest_model_path = Path(\"/kaggle/working/queenbee_final_tuned_model.keras\")\nbest_model.save(best_model_path)\n\nprint(\"Saved tuned model to\", best_model_path)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:03:37.053620Z",
     "iopub.execute_input": "2025-12-25T08:03:37.053885Z",
     "iopub.status.idle": "2025-12-25T08:05:09.828322Z",
     "shell.execute_reply.started": "2025-12-25T08:03:37.053864Z",
     "shell.execute_reply": "2025-12-25T08:05:09.827404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Reloading Tuner from /kaggle/working/queenbee_tuning/queenbee_cnn/tuner0.json\nEpoch 1/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 146ms/step - accuracy: 0.8976 - loss: 0.3386 - recall_absent: 0.8787 - val_accuracy: 0.5306 - val_loss: 0.9954 - val_recall_absent: 0.9900\nEpoch 2/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 142ms/step - accuracy: 0.9532 - loss: 0.1079 - recall_absent: 0.9564 - val_accuracy: 0.9081 - val_loss: 0.2799 - val_recall_absent: 0.9575\nEpoch 3/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 142ms/step - accuracy: 0.9639 - loss: 0.0746 - recall_absent: 0.9640 - val_accuracy: 0.9381 - val_loss: 0.1628 - val_recall_absent: 0.8500\nEpoch 4/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 143ms/step - accuracy: 0.9630 - loss: 0.0877 - recall_absent: 0.9620 - val_accuracy: 0.5750 - val_loss: 1.4998 - val_recall_absent: 0.2425\nSaved tuned model to /kaggle/working/queenbee_final_tuned_model.keras\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 87
  },
  {
   "id": "2e8f7167",
   "cell_type": "code",
   "source": "from tensorflow.keras.models import load_model\n\nmodel_for_eval = load_model(\n    best_model_path,\n    custom_objects={\"SparseClassRecall\": SparseClassRecall}\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:05:09.829294Z",
     "iopub.execute_input": "2025-12-25T08:05:09.829931Z",
     "iopub.status.idle": "2025-12-25T08:05:10.050890Z",
     "shell.execute_reply.started": "2025-12-25T08:05:09.829909Z",
     "shell.execute_reply": "2025-12-25T08:05:10.050208Z"
    }
   },
   "outputs": [],
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Calibration & Threshold Selection\n",
    "\n",
    "Raw softmax scores tend to collapse onto the majority `present` class. After loading the tuned CNN we perform two evaluation modes: standard argmax and calibrated predictions. Validation probabilities drive per-class precision-recall curves, from which we select F1-optimal thresholds. Those calibrated thresholds are then applied to the held-out test generator, yielding confusion matrices, detailed classification reports, and macro ROC/PR AUC metrics that the manuscript can cite when describing queen-state detection performance.\n"
   ]
  },
  {
   "id": "921011f7",
   "cell_type": "code",
   "source": [
    "def run_inference(model, generator):\n",
    "    generator.reset()\n",
    "    y_prob = model.predict(generator, verbose=1)\n",
    "    y_true = generator.classes\n",
    "    return y_prob, y_true\n",
    "\n",
    "\n",
    "def derive_thresholds(y_true, y_prob, class_names):\n",
    "    y_true_oh = tf.keras.utils.to_categorical(y_true, num_classes=len(class_names))\n",
    "    thresholds = {}\n",
    "    for idx, name in enumerate(class_names):\n",
    "        precision, recall, thresh = precision_recall_curve(y_true_oh[:, idx], y_prob[:, idx])\n",
    "        if thresh.size == 0:\n",
    "            thresholds[name] = 0.5\n",
    "            continue\n",
    "        f1 = 2 * precision * recall / np.clip(precision + recall, 1e-8, None)\n",
    "        best_idx = np.nanargmax(f1)\n",
    "        thresholds[name] = float(thresh[min(best_idx, len(thresh) - 1)])\n",
    "    return thresholds\n",
    "\n",
    "\n",
    "def predict_with_thresholds(y_prob, class_names, thresholds):\n",
    "    calibrated = []\n",
    "    for row in y_prob:\n",
    "        chosen_idx = None\n",
    "        chosen_score = -1.0\n",
    "        for idx, name in enumerate(class_names):\n",
    "            threshold = thresholds.get(name, 0.5)\n",
    "            if row[idx] >= threshold and row[idx] > chosen_score:\n",
    "                chosen_idx = idx\n",
    "                chosen_score = row[idx]\n",
    "        if chosen_idx is None:\n",
    "            chosen_idx = int(np.argmax(row))\n",
    "        calibrated.append(chosen_idx)\n",
    "    return np.array(calibrated)\n",
    "\n",
    "\n",
    "def summarize_metrics(y_true, y_pred, label):\n",
    "    return {\n",
    "        \"Mode\": label,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Macro Precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"Macro Recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"Macro F1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    }\n",
    "\n",
    "val_prob, val_true = run_inference(model_for_eval, val_gen)\n",
    "class_names = list(test_gen.class_indices.keys())\n",
    "thresholds = derive_thresholds(val_true, val_prob, class_names)\n",
    "print(\"Calibrated probability thresholds:\")\n",
    "for name in class_names:\n",
    "    print(f\"  {name}: {thresholds[name]:.3f}\")\n",
    "\n",
    "metrics = []\n",
    "test_prob, test_true = run_inference(model_for_eval, test_gen)\n",
    "default_pred = np.argmax(test_prob, axis=1)\n",
    "calibrated_pred = predict_with_thresholds(test_prob, class_names, thresholds)\n",
    "\n",
    "metrics_table = pd.DataFrame([\n",
    "    summarize_metrics(test_true, default_pred, \"Argmax\"),\n",
    "    summarize_metrics(test_true, calibrated_pred, \"Calibrated\")\n",
    "])\n",
    "display(metrics_table)\n",
    "metrics_table_path = FIGURE_DIR / \"acoustic_metrics_table.csv\"\n",
    "metrics_table.to_csv(metrics_table_path, index=False)\n",
    "print(\"Saved acoustic metrics table ->\", metrics_table_path)\n",
    "\n",
    "cm = confusion_matrix(test_true, calibrated_pred)\n",
    "cm_fig, ax = plt.subplots(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "ax.set_title(\"Confusion Matrix (Calibrated)\")\n",
    "cm_path = FIGURE_DIR / \"acoustic_confusion_matrix.png\"\n",
    "cm_fig.savefig(cm_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved acoustic confusion matrix ->\", cm_path)\n",
    "\n",
    "report_text = classification_report(test_true, calibrated_pred, target_names=class_names, zero_division=0)\n",
    "print(\"Calibrated classification report:\n",
    "\", report_text)\n",
    "report_path = FIGURE_DIR / \"acoustic_classification_report.txt\"\n",
    "report_path.write_text(report_text)\n",
    "\n",
    "roc_auc = roc_auc_score(\n",
    "    pd.get_dummies(test_true, drop_first=False).values,\n",
    "    test_prob,\n",
    "    average=\"macro\",\n",
    "    multi_class=\"ovr\"\n",
    ")\n",
    "pr_auc = average_precision_score(\n",
    "    pd.get_dummies(test_true, drop_first=False).values,\n",
    "    test_prob,\n",
    "    average=\"macro\"\n",
    ")\n",
    "auc_path = FIGURE_DIR / \"acoustic_auc_summary.json\"\n",
    "auc_path.write_text(json.dumps({\"roc_auc\": float(roc_auc), \"pr_auc\": float(pr_auc)}, indent=2))\n",
    "print(f\"ROC-AUC: {roc_auc:.4f} | PR-AUC: {pr_auc:.4f}\")\n",
    "print(\"Saved acoustic AUC summary ->\", auc_path)\n",
    "\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:05:10.051850Z",
     "iopub.execute_input": "2025-12-25T08:05:10.052111Z",
     "iopub.status.idle": "2025-12-25T08:05:13.998148Z",
     "shell.execute_reply.started": "2025-12-25T08:05:10.052072Z",
     "shell.execute_reply": "2025-12-25T08:05:13.997501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001b[1m50/50\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\nCalibrated probability thresholds:\n  absent: 0.898\n  external: 0.779\n  present: 0.032\n\u001b[1m50/50\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "         Mode  Accuracy  Macro Precision  Macro Recall  Macro F1\n0      Argmax  0.526875         0.695540      0.681667  0.501093\n1  Calibrated  0.946875         0.937807      0.957083  0.946250",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mode</th>\n      <th>Accuracy</th>\n      <th>Macro Precision</th>\n      <th>Macro Recall</th>\n      <th>Macro F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Argmax</td>\n      <td>0.526875</td>\n      <td>0.695540</td>\n      <td>0.681667</td>\n      <td>0.501093</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Calibrated</td>\n      <td>0.946875</td>\n      <td>0.937807</td>\n      <td>0.957083</td>\n      <td>0.946250</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Calibrated classification report:               precision    recall  f1-score   support\n\n      absent       0.89      0.97      0.93       400\n    external       0.94      0.98      0.96       400\n     present       0.99      0.92      0.95       800\n\n    accuracy                           0.95      1600\n   macro avg       0.94      0.96      0.95      1600\nweighted avg       0.95      0.95      0.95      1600\n\nROC-AUC: 0.9813 | PR-AUC: 0.9667\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 89
  },
  {
   "id": "8a188280",
   "cell_type": "code",
   "source": "SR = 22050\n\ndef audio_to_spectrogram_image(audio_path: Path):\n    y, sr = librosa.load(audio_path, sr=SR)\n    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=512)\n    S_dB = librosa.power_to_db(S, ref=np.max)\n\n    fig = plt.figure(figsize=(2, 2), dpi=64)\n    librosa.display.specshow(S_dB, sr=sr, cmap=\"magma\")\n    plt.axis(\"off\")\n\n    buf = io.BytesIO()\n    plt.savefig(buf, format=\"png\", bbox_inches=\"tight\", pad_inches=0)\n    plt.close(fig)\n    buf.seek(0)\n\n    img = Image.open(buf).convert(\"RGB\").resize(IMG_SIZE)\n    img_array = np.array(img, dtype=np.float32) / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\ndef visualize_audio_prediction(audio_path: Path, model):\n    mel_input = audio_to_spectrogram_image(audio_path)\n    prediction = model.predict(mel_input)\n    class_names = list(test_gen.class_indices.keys())\n    pred_idx = int(np.argmax(prediction))\n    confidence = float(np.max(prediction))\n\n    y, sr = librosa.load(audio_path, sr=SR)\n    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n    mel_db = librosa.power_to_db(mel, ref=np.max)\n\n    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n    times = np.linspace(0, len(y)/sr, len(y))\n    axes[0,0].plot(times, y)\n    axes[0,0].set_title(\"Waveform\")\n\n    img = axes[0,1].imshow(mel_db, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n    axes[0,1].set_title(\"Mel Spectrogram\")\n    plt.colorbar(img, ax=axes[0,1], fraction=0.046, pad=0.04)\n\n    axes[1,0].bar(class_names, prediction[0], color=\"teal\")\n    axes[1,0].set_ylim(0, 1)\n    axes[1,0].set_title(\"Prediction Probabilities\")\n\n    axes[1,1].axis(\"off\")\n    axes[1,1].text(0.1, 0.5, f\"Predicted: {class_names[pred_idx]}\\nConfidence: {confidence:.2%}\", fontsize=14)\n\n    plt.tight_layout()\n    plt.show()\n\n    return {\"prediction\": class_names[pred_idx], \"confidence\": confidence}\n\nsample_audio = next(QUEEN_PRESENT_DIR.glob('*.wav'))\nvisualize_audio_prediction(sample_audio, model_for_eval)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:05:13.999019Z",
     "iopub.execute_input": "2025-12-25T08:05:13.999273Z",
     "iopub.status.idle": "2025-12-25T08:05:15.087313Z",
     "shell.execute_reply.started": "2025-12-25T08:05:13.999241Z",
     "shell.execute_reply": "2025-12-25T08:05:15.086704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n",
     "output_type": "stream"
    },
    {
     "execution_count": 90,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'prediction': 'external', 'confidence': 0.6416568160057068}"
     },
     "metadata": {}
    }
   ],
   "execution_count": 90
  },
  {
   "id": "86e1ed93",
   "cell_type": "markdown",
   "source": "## Makueni Apiary Intelligence Pipeline",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Makueni Apiary Intelligence Pipeline\n",
    "\n",
    "The second half of BeeUnity focuses on environmental + hive telemetry analytics for Makueni County. Users can optionally pick a geometry via ipyleaflet; however, Kaggle\u2019s environment rarely ships the `jupyter-leaflet` extension, so we default to fixed coordinates while preserving the widget wiring for local notebooks. This section obeys Kaggle\u2019s outbound-network policy via the `ENABLE_REMOTE_CALLS` flag and falls back to cached CSV exports inside `content/main-data/`.\n"
   ]
  },
  {
   "id": "6c6b0129",
   "cell_type": "code",
   "source": "DEFAULT_CENTER = (-1.8048, 37.62)\nENABLE_LEAFLET_WIDGETS = False  # Set True only if jupyter-leaflet widgets are installed.\n\ntry:\n    import ipywidgets as widgets\n    from ipyleaflet import Map, Marker, DrawControl, basemaps\nexcept Exception:\n    print(\"ipyleaflet not available; using default coordinates.\")\n    lat_widget = lon_widget = geometry_widget = None\nelse:\n    lat_widget = widgets.FloatText(value=DEFAULT_CENTER[0], description=\"Latitude\", step=0.0001)\n    lon_widget = widgets.FloatText(value=DEFAULT_CENTER[1], description=\"Longitude\", step=0.0001)\n    geometry_widget = widgets.Textarea(\n        value=\"\",\n        description=\"Geometry\",\n        placeholder=\"Draw a polygon/rectangle on the map.\",\n        layout=widgets.Layout(width=\"100%\", height=\"140px\"),\n        disabled=True,\n    )\n\n    leaflet_map = Map(center=DEFAULT_CENTER, zoom=8, basemap=basemaps.OpenStreetMap.Mapnik, scroll_wheel_zoom=True)\n    marker = Marker(location=DEFAULT_CENTER, draggable=True)\n    leaflet_map.add_layer(marker)\n\n    draw_control = DrawControl(\n        polygon={\"shapeOptions\": {\"color\": \"#2563eb\", \"weight\": 2, \"fillOpacity\": 0.2}},\n        rectangle={\"shapeOptions\": {\"color\": \"#f97316\", \"weight\": 2, \"fillOpacity\": 0.15}},\n        circle={},\n        circlemarker={},\n        polyline={},\n    )\n    leaflet_map.add_control(draw_control)\n\n    def _update_marker(change):\n        marker.location = (lat_widget.value, lon_widget.value)\n\n    lat_widget.observe(_update_marker, names=\"value\")\n    lon_widget.observe(_update_marker, names=\"value\")\n\n    display(widgets.HBox([lat_widget, lon_widget]))\n    display(geometry_widget)\n    display(leaflet_map)\n\nlat_widget_available = 'lat_widget' in globals() and lat_widget is not None\nlon_widget_available = 'lon_widget' in globals() and lon_widget is not None\n\nif lat_widget_available and lon_widget_available:\n    latitude = float(lat_widget.value)\n    longitude = float(lon_widget.value)\nelse:\n    latitude, longitude = DEFAULT_CENTER\n    print(\"Using default coordinates:\", DEFAULT_CENTER)\n\nselected_geometry_geojson = globals().get('selected_geometry_geojson')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:05:15.088131Z",
     "iopub.execute_input": "2025-12-25T08:05:15.088366Z",
     "iopub.status.idle": "2025-12-25T08:05:15.115546Z",
     "shell.execute_reply.started": "2025-12-25T08:05:15.088345Z",
     "shell.execute_reply": "2025-12-25T08:05:15.114741Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatText(value=-1.8048, description='Latitude', step=0.0001), FloatText(value=37.62, descripti\u2026",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "665ac5f595dc432fa99216000f225cfe"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Textarea(value='', description='Geometry', disabled=True, layout=Layout(height='140px', width='100%'), placeho\u2026",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a02be003590f4043b55034ce7f884437"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Map(center=[-1.8048, 37.62], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom\u2026",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b75993e0e5214acbb36379bf0bd03bc1"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather/NDVI Acquisition Strategy\n",
    "\n",
    "We scope the modeling window via `normalize_date_string`, clamp requests to the latest Open-Meteo archive availability, and split long ranges into 365-day chunks. When `ENABLE_REMOTE_CALLS` is false (the Kaggle default), we load pre-exported weather and NDVI CSVs staged under `content/main-data/`. When high-trust compute is available, the notebook can re-fetch ERA5/Open-Meteo and MODIS NDVI slices, persisting them with consistent schemas so report figures remain reproducible.\n"
   ]
  },
  {
   "id": "13f4ff43",
   "cell_type": "code",
   "source": "import ee\n\nraw_start_date = \"2008-01-01\"\nraw_end_date = \"2025-12-05\"\ntimezone = \"Africa/Nairobi\"\n\ndef normalize_date_string(d: str) -> dt.date:\n    parts = d.split(\"-\")\n    if len(parts) != 3:\n        raise ValueError(\"Date must be YYYY-MM-DD\")\n    y, m, day = [int(p) for p in parts]\n    m = max(1, min(12, m))\n    last_day = calendar.monthrange(y, m)[1]\n    day = max(1, min(last_day, day))\n    return dt.date(y, m, day)\n\nstart_date = normalize_date_string(raw_start_date)\nend_date = normalize_date_string(raw_end_date)\n\ntoday = dt.date.today()\napi_latest = dt.date(2025, 12, 20)\nmax_allowed = min(today, api_latest)\n\nif end_date > max_allowed:\n    print(f\"Clamping end_date {end_date} -> {max_allowed}\")\n    end_date = max_allowed\nif start_date > end_date:\n    raise ValueError(\"start_date must be before end_date\")\n\nprint(\"Using date range:\", start_date, \"\u2192\", end_date)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:05:15.116696Z",
     "iopub.execute_input": "2025-12-25T08:05:15.117116Z",
     "iopub.status.idle": "2025-12-25T08:05:15.130636Z",
     "shell.execute_reply.started": "2025-12-25T08:05:15.117085Z",
     "shell.execute_reply": "2025-12-25T08:05:15.129971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Using date range: 2008-01-01 \u2192 2025-12-05\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 92
  },
  {
   "id": "f651dd70",
   "cell_type": "code",
   "source": "ENABLE_REMOTE_CALLS = True  # Kaggle notebooks typically block outbound internet.\n\ndef split_date_range(start: dt.date, end: dt.date, max_days: int = 365):\n    chunks = []\n    current = start\n    while current <= end:\n        chunk_end = min(end, current + dt.timedelta(days=max_days - 1))\n        chunks.append((current, chunk_end))\n        current = chunk_end + dt.timedelta(days=1)\n    return chunks\n\ndef fetch_chunk(lat, lon, sdate: dt.date, edate: dt.date, timezone=\"Africa/Nairobi\", max_retries=3, backoff=2):\n    base = \"https://archive-api.open-meteo.com/v1/archive\"\n    daily_vars = \",\".join([\n        \"temperature_2m_max\",\n        \"temperature_2m_min\",\n        \"temperature_2m_mean\",\n        \"precipitation_sum\",\n        \"relative_humidity_2m_mean\",\n        \"wind_speed_10m_max\",\n        \"cloudcover_mean\"\n    ])\n    params = {\n        \"latitude\": lat,\n        \"longitude\": lon,\n        \"start_date\": sdate.strftime(\"%Y-%m-%d\"),\n        \"end_date\": edate.strftime(\"%Y-%m-%d\"),\n        \"daily\": daily_vars,\n        \"timezone\": timezone\n    }\n    for attempt in range(1, max_retries + 1):\n        try:\n            resp = requests.get(base, params=params, timeout=30)\n            resp.raise_for_status()\n            payload = resp.json()\n            if \"daily\" not in payload or \"time\" not in payload[\"daily\"]:\n                raise ValueError(\"API response missing expected fields.\")\n            return payload\n        except Exception as exc:\n            print(f\"Attempt {attempt} failed: {exc}\")\n            if attempt == max_retries:\n                raise\n            time.sleep(backoff ** attempt)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:06:19.912345Z",
     "iopub.execute_input": "2025-12-25T08:06:19.912882Z",
     "iopub.status.idle": "2025-12-25T08:06:19.920375Z",
     "shell.execute_reply.started": "2025-12-25T08:06:19.912851Z",
     "shell.execute_reply": "2025-12-25T08:06:19.919717Z"
    }
   },
   "outputs": [],
   "execution_count": 95
  },
  {
   "id": "b8b45a4d",
   "cell_type": "code",
   "source": "weather_csv = MAIN_DATA_DIR / \"makueni_weather_2008_2025.csv\"\nchunks = split_date_range(start_date, end_date, max_days=365)\n\nif ENABLE_REMOTE_CALLS:\n    dfs = []\n    for s, e in chunks:\n        payload = fetch_chunk(latitude, longitude, s, e, timezone=timezone)\n        daily = payload[\"daily\"]\n        df_chunk = pd.DataFrame({\n            \"date\": daily[\"time\"],\n            \"temp_max\": daily.get(\"temperature_2m_max\"),\n            \"temp_min\": daily.get(\"temperature_2m_min\"),\n            \"temp_mean\": daily.get(\"temperature_2m_mean\"),\n            \"humidity_mean\": daily.get(\"relative_humidity_2m_mean\"),\n            \"rainfall_mm\": daily.get(\"precipitation_sum\"),\n            \"wind_speed_max\": daily.get(\"wind_speed_10m_max\"),\n            \"cloud_cover_percent\": daily.get(\"cloudcover_mean\"),\n        })\n        dfs.append(df_chunk)\n        time.sleep(1)\n    weather_df = pd.concat(dfs, ignore_index=True)\n    weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n    weather_df.sort_values(\"date\", inplace=True)\n    weather_df.to_csv(weather_csv, index=False)\n    print(\"Fetched and saved weather CSV to\", weather_csv)\nelse:\n    if weather_csv.exists():\n        weather_df = pd.read_csv(weather_csv, parse_dates=[\"date\"])\n        print(f\"Loaded cached weather data from {weather_csv}\")\n    else:\n        raise FileNotFoundError(f\"{weather_csv} not found; enable ENABLE_REMOTE_CALLS to regenerate.\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:06:23.180901Z",
     "iopub.execute_input": "2025-12-25T08:06:23.181480Z",
     "iopub.status.idle": "2025-12-25T08:06:51.199916Z",
     "shell.execute_reply.started": "2025-12-25T08:06:23.181454Z",
     "shell.execute_reply": "2025-12-25T08:06:51.199156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Fetched and saved weather CSV to /kaggle/working/content/main-data/makueni_weather_2008_2025.csv\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 96
  },
  {
   "id": "0bd89f0c",
   "cell_type": "code",
   "source": "ENABLE_REMOTE_CALLS = False  # Kaggle notebooks typically block outbound internet.\nndvi_csv = \"/kaggle/input/makueni-ndvi-2008-2025-csv/makueni_ndvi_2008_2025.csv\"\n\nif ENABLE_REMOTE_CALLS:\n    try:\n        ee.Initialize()\n    except Exception:\n        print(\"Authenticating with Earth Engine...\")\n        ee.Authenticate()\n        ee.Initialize()\n\n    point = ee.Geometry.Point([longitude, latitude])\n    modis = ee.ImageCollection(\"MODIS/061/MOD13Q1\").select(\"NDVI\").filterDate(start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")).filterBounds(point)\n\n    def extract_ndvi(image):\n        mean = image.reduceRegion(reducer=ee.Reducer.mean(), geometry=point, scale=250).get(\"NDVI\")\n        date = image.date().format(\"YYYY-MM-dd\")\n        return ee.Feature(None, {\"date\": date, \"ndvi_mean\": mean})\n\n    ndvi_fc = modis.map(extract_ndvi).getInfo()\n    records = [f[\"properties\"] for f in ndvi_fc[\"features\"]]\n    ndvi_df = pd.DataFrame(records)\n    ndvi_df[\"date\"] = pd.to_datetime(ndvi_df[\"date\"])\n    ndvi_df[\"ndvi_mean\"] = ndvi_df[\"ndvi_mean\"].astype(float) / 10000\n    ndvi_df.to_csv(ndvi_csv, index=False)\n    print(\"Fetched NDVI and saved to\", ndvi_csv)\nelse:\n    if ndvi_csv:\n        ndvi_df = pd.read_csv(ndvi_csv, parse_dates=[\"date\"])\n        print(f\"Loaded cached NDVI data from {ndvi_csv}\")\n    else:\n        raise FileNotFoundError(f\"{ndvi_csv} not found; enable ENABLE_REMOTE_CALLS to regenerate.\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:07:18.069254Z",
     "iopub.execute_input": "2025-12-25T08:07:18.069753Z",
     "iopub.status.idle": "2025-12-25T08:07:18.081629Z",
     "shell.execute_reply.started": "2025-12-25T08:07:18.069727Z",
     "shell.execute_reply": "2025-12-25T08:07:18.080990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Loaded cached NDVI data from /kaggle/input/makueni-ndvi-2008-2025-csv/makueni_ndvi_2008_2025.csv\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 97
  },
  {
   "id": "f84d3908",
   "cell_type": "code",
   "source": "df_weather = weather_df.copy()\ndf_ndvi = ndvi_df.copy()\n\ndf_weather[\"date\"] = pd.to_datetime(df_weather[\"date\"])\ndf_ndvi[\"date\"] = pd.to_datetime(df_ndvi[\"date\"])\n\ndf_merged = pd.merge(df_weather, df_ndvi, on=\"date\", how=\"left\").sort_values(\"date\")\nweather_ndvi_path = MAIN_DATA_DIR / \"makueni_weather_ndvi_2008_2025.csv\"\ndf_merged.to_csv(weather_ndvi_path, index=False)\nprint(\"Merged weather+NDVI ->\", weather_ndvi_path)\ndf_merged.head()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:07:23.531668Z",
     "iopub.execute_input": "2025-12-25T08:07:23.532313Z",
     "iopub.status.idle": "2025-12-25T08:07:23.590392Z",
     "shell.execute_reply.started": "2025-12-25T08:07:23.532284Z",
     "shell.execute_reply": "2025-12-25T08:07:23.589842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Merged weather+NDVI -> /kaggle/working/content/main-data/makueni_weather_ndvi_2008_2025.csv\n",
     "output_type": "stream"
    },
    {
     "execution_count": 98,
     "output_type": "execute_result",
     "data": {
      "text/plain": "        date  temp_max  temp_min  temp_mean  humidity_mean  rainfall_mm  \\\n0 2008-01-01      24.9      16.4       20.3             74          1.2   \n1 2008-01-02      25.8      14.1       20.2             71          0.8   \n2 2008-01-03      27.2      15.2       21.3             65          0.0   \n3 2008-01-04      27.6      15.4       22.2             63          0.1   \n4 2008-01-05      27.3      15.2       21.0             75          2.9   \n\n   wind_speed_max  cloud_cover_percent  ndvi_mean  \n0            15.1                   53     0.6805  \n1            14.3                   19        NaN  \n2            12.8                   11        NaN  \n3            12.2                   26        NaN  \n4            13.1                   58        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>temp_max</th>\n      <th>temp_min</th>\n      <th>temp_mean</th>\n      <th>humidity_mean</th>\n      <th>rainfall_mm</th>\n      <th>wind_speed_max</th>\n      <th>cloud_cover_percent</th>\n      <th>ndvi_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-01-01</td>\n      <td>24.9</td>\n      <td>16.4</td>\n      <td>20.3</td>\n      <td>74</td>\n      <td>1.2</td>\n      <td>15.1</td>\n      <td>53</td>\n      <td>0.6805</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-01-02</td>\n      <td>25.8</td>\n      <td>14.1</td>\n      <td>20.2</td>\n      <td>71</td>\n      <td>0.8</td>\n      <td>14.3</td>\n      <td>19</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-01-03</td>\n      <td>27.2</td>\n      <td>15.2</td>\n      <td>21.3</td>\n      <td>65</td>\n      <td>0.0</td>\n      <td>12.8</td>\n      <td>11</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-01-04</td>\n      <td>27.6</td>\n      <td>15.4</td>\n      <td>22.2</td>\n      <td>63</td>\n      <td>0.1</td>\n      <td>12.2</td>\n      <td>26</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-01-05</td>\n      <td>27.3</td>\n      <td>15.2</td>\n      <td>21.0</td>\n      <td>75</td>\n      <td>2.9</td>\n      <td>13.1</td>\n      <td>58</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 98
  },
  {
   "id": "27121437",
   "cell_type": "code",
   "source": "df_month = df_merged.set_index(\"date\").resample(\"ME\").agg({\n    \"rainfall_mm\": \"sum\",\n    \"temp_mean\": \"mean\",\n    \"humidity_mean\": \"mean\",\n    \"ndvi_mean\": \"mean\"\n}).reset_index()\n\nfig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\naxes[0].plot(df_month[\"date\"], df_month[\"rainfall_mm\"], marker=\"o\")\naxes[0].set_title(\"Monthly Rainfall (mm)\")\n\naxes[1].plot(df_month[\"date\"], df_month[\"temp_mean\"], marker=\"o\", color=\"tomato\")\naxes[1].set_title(\"Monthly Mean Temperature (\u00b0C)\")\n\naxes[2].plot(df_month[\"date\"], df_month[\"ndvi_mean\"], marker=\"o\", color=\"green\")\naxes[2].set_title(\"Monthly NDVI Mean\")\n\nfor ax in axes:\n    ax.grid(True, alpha=0.3)\n    ax.set_ylabel(\"Value\")\n\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:07:26.680372Z",
     "iopub.execute_input": "2025-12-25T08:07:26.681026Z",
     "iopub.status.idle": "2025-12-25T08:07:26.956159Z",
     "shell.execute_reply.started": "2025-12-25T08:07:26.680989Z",
     "shell.execute_reply": "2025-12-25T08:07:26.955538Z"
    }
   },
   "outputs": [],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hive Telemetry & Synthetic Augmentation\n",
    "\n",
    "Direct hive telemetry from community partners is still sparse, so the notebook synthesizes weekly hive logs per hive id (Honey yield, Varroa %, hive weight, brood area, stress events). The generator preserves realistic ranges/variances and encodes queen age metadata so the downstream models can learn temporal drift patterns. When actual CSV exports (`hive_logs_2008_2025.csv`) exist they take precedence, keeping the pipeline faithful to the project scope in Chapter 3.\n"
   ]
  },
  {
   "id": "8dea5e59",
   "cell_type": "code",
   "source": "hive_logs_path = MAIN_DATA_DIR / \"hive_logs_2008_2025.csv\"\n\nif hive_logs_path.exists():\n    hive_df = pd.read_csv(hive_logs_path, parse_dates=[\"date\"])\n    print(\"Loaded hive logs from\", hive_logs_path)\nelse:\n    print(\"Generating synthetic hive telemetry...\")\n    start_dt = dt.datetime(2008, 1, 1)\n    end_dt = dt.datetime(2025, 9, 30)\n    dates = pd.date_range(start=start_dt, end=end_dt, freq=\"7D\")\n\n    hive_ids = [\"Hive-A\", \"Hive-B\", \"Hive-C\", \"Hive-D\"]\n    data = []\n    rng = np.random.default_rng(42)\n    for hive in hive_ids:\n        queen_age = rng.integers(3, 20)\n        for date in dates:\n            honey_yield = max(0, rng.normal(12, 3))\n            varroa = np.clip(rng.normal(8, 3), 0, 40)\n            hive_weight = rng.normal(45, 5)\n            brood_area = np.clip(rng.normal(800, 150), 100, 1200)\n            stress_event = rng.choice([\"none\", \"ants\", \"drought\"], p=[0.85, 0.1, 0.05])\n            data.append({\n                \"date\": date,\n                \"hive_id\": hive,\n                \"honey_yield_kg\": honey_yield,\n                \"varroa_pct\": varroa,\n                \"hive_weight_kg\": hive_weight,\n                \"brood_area_cm2\": brood_area,\n                \"stress_event\": stress_event,\n                \"queen_age_months\": queen_age\n            })\n    hive_df = pd.DataFrame(data)\n    hive_df.to_csv(hive_logs_path, index=False)\n    print(\"Synthetic hive logs saved to\", hive_logs_path)\n\nhive_df.head()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:07:31.470925Z",
     "iopub.execute_input": "2025-12-25T08:07:31.471521Z",
     "iopub.status.idle": "2025-12-25T08:07:31.680928Z",
     "shell.execute_reply.started": "2025-12-25T08:07:31.471492Z",
     "shell.execute_reply": "2025-12-25T08:07:31.680312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Generating synthetic hive telemetry...\nSynthetic hive logs saved to /kaggle/working/content/main-data/hive_logs_2008_2025.csv\n",
     "output_type": "stream"
    },
    {
     "execution_count": 100,
     "output_type": "execute_result",
     "data": {
      "text/plain": "        date hive_id  honey_yield_kg  varroa_pct  hive_weight_kg  \\\n0 2008-01-01  Hive-A        8.880048   10.251354       49.702824   \n1 2008-01-08  Hive-A       12.383521    7.051272       44.915994   \n2 2008-01-15  Hive-A       14.333376    8.198092       50.636206   \n3 2008-01-22  Hive-A       13.106252    5.123352       49.392252   \n4 2008-01-29  Hive-A        9.957211   11.667624       44.227353   \n\n   brood_area_cm2 stress_event  queen_age_months  \n0      507.344722      drought                 4  \n1      672.043411         none                 4  \n2      870.126401         none                 4  \n3      792.511113         none                 4  \n4      735.750827         none                 4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>hive_id</th>\n      <th>honey_yield_kg</th>\n      <th>varroa_pct</th>\n      <th>hive_weight_kg</th>\n      <th>brood_area_cm2</th>\n      <th>stress_event</th>\n      <th>queen_age_months</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-01-01</td>\n      <td>Hive-A</td>\n      <td>8.880048</td>\n      <td>10.251354</td>\n      <td>49.702824</td>\n      <td>507.344722</td>\n      <td>drought</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-01-08</td>\n      <td>Hive-A</td>\n      <td>12.383521</td>\n      <td>7.051272</td>\n      <td>44.915994</td>\n      <td>672.043411</td>\n      <td>none</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-01-15</td>\n      <td>Hive-A</td>\n      <td>14.333376</td>\n      <td>8.198092</td>\n      <td>50.636206</td>\n      <td>870.126401</td>\n      <td>none</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-01-22</td>\n      <td>Hive-A</td>\n      <td>13.106252</td>\n      <td>5.123352</td>\n      <td>49.392252</td>\n      <td>792.511113</td>\n      <td>none</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-01-29</td>\n      <td>Hive-A</td>\n      <td>9.957211</td>\n      <td>11.667624</td>\n      <td>44.227353</td>\n      <td>735.750827</td>\n      <td>none</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 100
  },
  {
   "id": "3c6f516c",
   "cell_type": "code",
   "source": "weather_full = pd.read_csv(weather_ndvi_path, parse_dates=[\"date\"])\nhive_df[\"date\"] = pd.to_datetime(hive_df[\"date\"])\nmerged = pd.merge(hive_df, weather_full, on=\"date\", how=\"left\")\nmerged_path = MAIN_DATA_DIR / \"merged_hive_weather_ndvi.csv\"\nmerged.to_csv(merged_path, index=False)\nprint(\"Merged hive + weather ->\", merged_path)\nmerged.head()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:07:34.437703Z",
     "iopub.execute_input": "2025-12-25T08:07:34.437992Z",
     "iopub.status.idle": "2025-12-25T08:07:34.515364Z",
     "shell.execute_reply.started": "2025-12-25T08:07:34.437973Z",
     "shell.execute_reply": "2025-12-25T08:07:34.514813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Merged hive + weather -> /kaggle/working/content/main-data/merged_hive_weather_ndvi.csv\n",
     "output_type": "stream"
    },
    {
     "execution_count": 101,
     "output_type": "execute_result",
     "data": {
      "text/plain": "        date hive_id  honey_yield_kg  varroa_pct  hive_weight_kg  \\\n0 2008-01-01  Hive-A        8.880048   10.251354       49.702824   \n1 2008-01-08  Hive-A       12.383521    7.051272       44.915994   \n2 2008-01-15  Hive-A       14.333376    8.198092       50.636206   \n3 2008-01-22  Hive-A       13.106252    5.123352       49.392252   \n4 2008-01-29  Hive-A        9.957211   11.667624       44.227353   \n\n   brood_area_cm2 stress_event  queen_age_months  temp_max  temp_min  \\\n0      507.344722      drought                 4      24.9      16.4   \n1      672.043411         none                 4      28.1      14.9   \n2      870.126401         none                 4      26.0      18.0   \n3      792.511113         none                 4      25.2      17.3   \n4      735.750827         none                 4      26.2      16.6   \n\n   temp_mean  humidity_mean  rainfall_mm  wind_speed_max  cloud_cover_percent  \\\n0       20.3             74          1.2            15.1                   53   \n1       21.8             61          0.0            13.6                   36   \n2       21.3             73          1.1            12.9                   64   \n3       20.4             79          1.5            13.1                   80   \n4       21.1             68          0.6            15.5                   72   \n\n   ndvi_mean  \n0     0.6805  \n1        NaN  \n2        NaN  \n3        NaN  \n4        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>hive_id</th>\n      <th>honey_yield_kg</th>\n      <th>varroa_pct</th>\n      <th>hive_weight_kg</th>\n      <th>brood_area_cm2</th>\n      <th>stress_event</th>\n      <th>queen_age_months</th>\n      <th>temp_max</th>\n      <th>temp_min</th>\n      <th>temp_mean</th>\n      <th>humidity_mean</th>\n      <th>rainfall_mm</th>\n      <th>wind_speed_max</th>\n      <th>cloud_cover_percent</th>\n      <th>ndvi_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-01-01</td>\n      <td>Hive-A</td>\n      <td>8.880048</td>\n      <td>10.251354</td>\n      <td>49.702824</td>\n      <td>507.344722</td>\n      <td>drought</td>\n      <td>4</td>\n      <td>24.9</td>\n      <td>16.4</td>\n      <td>20.3</td>\n      <td>74</td>\n      <td>1.2</td>\n      <td>15.1</td>\n      <td>53</td>\n      <td>0.6805</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-01-08</td>\n      <td>Hive-A</td>\n      <td>12.383521</td>\n      <td>7.051272</td>\n      <td>44.915994</td>\n      <td>672.043411</td>\n      <td>none</td>\n      <td>4</td>\n      <td>28.1</td>\n      <td>14.9</td>\n      <td>21.8</td>\n      <td>61</td>\n      <td>0.0</td>\n      <td>13.6</td>\n      <td>36</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-01-15</td>\n      <td>Hive-A</td>\n      <td>14.333376</td>\n      <td>8.198092</td>\n      <td>50.636206</td>\n      <td>870.126401</td>\n      <td>none</td>\n      <td>4</td>\n      <td>26.0</td>\n      <td>18.0</td>\n      <td>21.3</td>\n      <td>73</td>\n      <td>1.1</td>\n      <td>12.9</td>\n      <td>64</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-01-22</td>\n      <td>Hive-A</td>\n      <td>13.106252</td>\n      <td>5.123352</td>\n      <td>49.392252</td>\n      <td>792.511113</td>\n      <td>none</td>\n      <td>4</td>\n      <td>25.2</td>\n      <td>17.3</td>\n      <td>20.4</td>\n      <td>79</td>\n      <td>1.5</td>\n      <td>13.1</td>\n      <td>80</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-01-29</td>\n      <td>Hive-A</td>\n      <td>9.957211</td>\n      <td>11.667624</td>\n      <td>44.227353</td>\n      <td>735.750827</td>\n      <td>none</td>\n      <td>4</td>\n      <td>26.2</td>\n      <td>16.6</td>\n      <td>21.1</td>\n      <td>68</td>\n      <td>0.6</td>\n      <td>15.5</td>\n      <td>72</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 101
  },
  {
   "id": "82d3330c",
   "cell_type": "code",
   "source": "floral_data = {\n    \"date\": [\n        \"2025-01-15\",\"2025-02-15\",\"2025-03-15\",\"2025-04-15\",\n        \"2025-05-15\",\"2025-06-15\",\"2025-07-15\",\"2025-08-15\",\"2025-09-15\"\n    ],\n    \"major_flowers\": [\n        \"Acacia tortilis, Mango, Commiphora\",\n        \"Acacia tortilis, Acacia mellifera, Mango\",\n        \"Croton, Acacia mellifera\",\n        \"Croton, Melia volkensii\",\n        \"Citrus, Croton\",\n        \"Aloe, Citrus\",\n        \"Aloe, Pasture weeds\",\n        \"Eucalyptus, Pasture weeds\",\n        \"Eucalyptus camaldulensis\"\n    ],\n    \"nectar_flow_strength\": [\"High\",\"High\",\"Medium\",\"Medium\",\"Medium\",\"Medium\",\"Low\",\"Low-Medium\",\"High\"],\n    \"stress_risk\": [\"Low\",\"Low\",\"Medium\",\"Low\",\"Medium\",\"Medium\",\"High\",\"High\",\"Low\"],\n    \"pest_disease_notes\": [\n        \"Hive beetles active\",\n        \"Wax moth pressure\",\n        \"Varroa buildup\",\n        \"Chalkbrood risk\",\n        \"Nosema risk\",\n        \"Slow brood buildup\",\n        \"Ant invasions\",\n        \"Weak colony pests\",\n        \"Healthy buildup\"\n    ]\n}\nfloral_df = pd.DataFrame(floral_data)\nfloral_df[\"date\"] = pd.to_datetime(floral_df[\"date\"])\nfloral_path = MAIN_DATA_DIR / \"makueni_floral_calendar_2025.csv\"\nfloral_df.to_csv(floral_path, index=False)\nprint(\"Floral calendar saved to\", floral_path)\nfloral_df\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:07:37.412109Z",
     "iopub.execute_input": "2025-12-25T08:07:37.412719Z",
     "iopub.status.idle": "2025-12-25T08:07:37.427621Z",
     "shell.execute_reply.started": "2025-12-25T08:07:37.412693Z",
     "shell.execute_reply": "2025-12-25T08:07:37.426958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Floral calendar saved to /kaggle/working/content/main-data/makueni_floral_calendar_2025.csv\n",
     "output_type": "stream"
    },
    {
     "execution_count": 102,
     "output_type": "execute_result",
     "data": {
      "text/plain": "        date                             major_flowers nectar_flow_strength  \\\n0 2025-01-15        Acacia tortilis, Mango, Commiphora                 High   \n1 2025-02-15  Acacia tortilis, Acacia mellifera, Mango                 High   \n2 2025-03-15                  Croton, Acacia mellifera               Medium   \n3 2025-04-15                   Croton, Melia volkensii               Medium   \n4 2025-05-15                            Citrus, Croton               Medium   \n5 2025-06-15                              Aloe, Citrus               Medium   \n6 2025-07-15                       Aloe, Pasture weeds                  Low   \n7 2025-08-15                 Eucalyptus, Pasture weeds           Low-Medium   \n8 2025-09-15                  Eucalyptus camaldulensis                 High   \n\n  stress_risk   pest_disease_notes  \n0         Low  Hive beetles active  \n1         Low    Wax moth pressure  \n2      Medium       Varroa buildup  \n3         Low      Chalkbrood risk  \n4      Medium          Nosema risk  \n5      Medium   Slow brood buildup  \n6        High        Ant invasions  \n7        High    Weak colony pests  \n8         Low      Healthy buildup  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>major_flowers</th>\n      <th>nectar_flow_strength</th>\n      <th>stress_risk</th>\n      <th>pest_disease_notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2025-01-15</td>\n      <td>Acacia tortilis, Mango, Commiphora</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Hive beetles active</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2025-02-15</td>\n      <td>Acacia tortilis, Acacia mellifera, Mango</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Wax moth pressure</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2025-03-15</td>\n      <td>Croton, Acacia mellifera</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Varroa buildup</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2025-04-15</td>\n      <td>Croton, Melia volkensii</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>Chalkbrood risk</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2025-05-15</td>\n      <td>Citrus, Croton</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Nosema risk</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2025-06-15</td>\n      <td>Aloe, Citrus</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Slow brood buildup</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2025-07-15</td>\n      <td>Aloe, Pasture weeds</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Ant invasions</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2025-08-15</td>\n      <td>Eucalyptus, Pasture weeds</td>\n      <td>Low-Medium</td>\n      <td>High</td>\n      <td>Weak colony pests</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2025-09-15</td>\n      <td>Eucalyptus camaldulensis</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Healthy buildup</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 102
  },
  {
   "id": "5f5ec06d",
   "cell_type": "code",
   "source": "merged_full = merged.merge(floral_df, on=\"date\", how=\"left\")\nmerged_full_path = MAIN_DATA_DIR / \"merged_hive_weather_floral_2025.csv\"\nmerged_full.to_csv(merged_full_path, index=False)\nprint(\"Merged hive/weather/floral ->\", merged_full_path)\nmerged_full.head()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:07:42.245894Z",
     "iopub.execute_input": "2025-12-25T08:07:42.246512Z",
     "iopub.status.idle": "2025-12-25T08:07:42.313630Z",
     "shell.execute_reply.started": "2025-12-25T08:07:42.246488Z",
     "shell.execute_reply": "2025-12-25T08:07:42.313031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Merged hive/weather/floral -> /kaggle/working/content/main-data/merged_hive_weather_floral_2025.csv\n",
     "output_type": "stream"
    },
    {
     "execution_count": 103,
     "output_type": "execute_result",
     "data": {
      "text/plain": "        date hive_id  honey_yield_kg  varroa_pct  hive_weight_kg  \\\n0 2008-01-01  Hive-A        8.880048   10.251354       49.702824   \n1 2008-01-08  Hive-A       12.383521    7.051272       44.915994   \n2 2008-01-15  Hive-A       14.333376    8.198092       50.636206   \n3 2008-01-22  Hive-A       13.106252    5.123352       49.392252   \n4 2008-01-29  Hive-A        9.957211   11.667624       44.227353   \n\n   brood_area_cm2 stress_event  queen_age_months  temp_max  temp_min  \\\n0      507.344722      drought                 4      24.9      16.4   \n1      672.043411         none                 4      28.1      14.9   \n2      870.126401         none                 4      26.0      18.0   \n3      792.511113         none                 4      25.2      17.3   \n4      735.750827         none                 4      26.2      16.6   \n\n   temp_mean  humidity_mean  rainfall_mm  wind_speed_max  cloud_cover_percent  \\\n0       20.3             74          1.2            15.1                   53   \n1       21.8             61          0.0            13.6                   36   \n2       21.3             73          1.1            12.9                   64   \n3       20.4             79          1.5            13.1                   80   \n4       21.1             68          0.6            15.5                   72   \n\n   ndvi_mean major_flowers nectar_flow_strength stress_risk pest_disease_notes  \n0     0.6805           NaN                  NaN         NaN                NaN  \n1        NaN           NaN                  NaN         NaN                NaN  \n2        NaN           NaN                  NaN         NaN                NaN  \n3        NaN           NaN                  NaN         NaN                NaN  \n4        NaN           NaN                  NaN         NaN                NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>hive_id</th>\n      <th>honey_yield_kg</th>\n      <th>varroa_pct</th>\n      <th>hive_weight_kg</th>\n      <th>brood_area_cm2</th>\n      <th>stress_event</th>\n      <th>queen_age_months</th>\n      <th>temp_max</th>\n      <th>temp_min</th>\n      <th>temp_mean</th>\n      <th>humidity_mean</th>\n      <th>rainfall_mm</th>\n      <th>wind_speed_max</th>\n      <th>cloud_cover_percent</th>\n      <th>ndvi_mean</th>\n      <th>major_flowers</th>\n      <th>nectar_flow_strength</th>\n      <th>stress_risk</th>\n      <th>pest_disease_notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-01-01</td>\n      <td>Hive-A</td>\n      <td>8.880048</td>\n      <td>10.251354</td>\n      <td>49.702824</td>\n      <td>507.344722</td>\n      <td>drought</td>\n      <td>4</td>\n      <td>24.9</td>\n      <td>16.4</td>\n      <td>20.3</td>\n      <td>74</td>\n      <td>1.2</td>\n      <td>15.1</td>\n      <td>53</td>\n      <td>0.6805</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-01-08</td>\n      <td>Hive-A</td>\n      <td>12.383521</td>\n      <td>7.051272</td>\n      <td>44.915994</td>\n      <td>672.043411</td>\n      <td>none</td>\n      <td>4</td>\n      <td>28.1</td>\n      <td>14.9</td>\n      <td>21.8</td>\n      <td>61</td>\n      <td>0.0</td>\n      <td>13.6</td>\n      <td>36</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-01-15</td>\n      <td>Hive-A</td>\n      <td>14.333376</td>\n      <td>8.198092</td>\n      <td>50.636206</td>\n      <td>870.126401</td>\n      <td>none</td>\n      <td>4</td>\n      <td>26.0</td>\n      <td>18.0</td>\n      <td>21.3</td>\n      <td>73</td>\n      <td>1.1</td>\n      <td>12.9</td>\n      <td>64</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-01-22</td>\n      <td>Hive-A</td>\n      <td>13.106252</td>\n      <td>5.123352</td>\n      <td>49.392252</td>\n      <td>792.511113</td>\n      <td>none</td>\n      <td>4</td>\n      <td>25.2</td>\n      <td>17.3</td>\n      <td>20.4</td>\n      <td>79</td>\n      <td>1.5</td>\n      <td>13.1</td>\n      <td>80</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-01-29</td>\n      <td>Hive-A</td>\n      <td>9.957211</td>\n      <td>11.667624</td>\n      <td>44.227353</td>\n      <td>735.750827</td>\n      <td>none</td>\n      <td>4</td>\n      <td>26.2</td>\n      <td>16.6</td>\n      <td>21.1</td>\n      <td>68</td>\n      <td>0.6</td>\n      <td>15.5</td>\n      <td>72</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering & Gradient Boosting Baseline\n",
    "\n",
    "We fuse hive logs, weather+NDVI aggregates, and floral calendar context into `model_df`, then derive rolling statistics per hive, calendar effects (month/year/weekofyear), and impute missing values with a median strategy. HistGradientBoostingClassifier serves as the interpretable baseline occupancy/stress model. It leverages class weights derived from the imbalanced target and outputs ROC curves + classification reports that the research findings section can quote.\n"
   ]
  },
  {
   "id": "43772c05",
   "cell_type": "code",
   "source": [
    "model_df = merged_full.copy()\n",
    "model_df[\"stress_event\"] = model_df[\"stress_event\"].fillna(\"none\")\n",
    "model_df[\"stress_target\"] = (model_df[\"stress_event\"] != \"none\").astype(int)\n",
    "model_df[\"date\"] = pd.to_datetime(model_df[\"date\"])\n",
    "model_df[\"month\"] = model_df[\"date\"].dt.month\n",
    "model_df[\"year\"] = model_df[\"date\"].dt.year\n",
    "model_df[\"weekofyear\"] = model_df[\"date\"].dt.isocalendar().week.astype(int)\n",
    "\n",
    "rolling_features = [\"honey_yield_kg\", \"varroa_pct\", \"hive_weight_kg\", \"brood_area_cm2\"]\n",
    "for feature in rolling_features:\n",
    "    if feature in model_df.columns:\n",
    "        model_df[f\"{feature}_rolling_mean\"] = (\n",
    "            model_df.groupby(\"hive_id\")[feature]\n",
    "            .transform(lambda s: s.rolling(window=4, min_periods=1).mean())\n",
    "        )\n",
    "        model_df[f\"{feature}_rolling_std\"] = (\n",
    "            model_df.groupby(\"hive_id\")[feature]\n",
    "            .transform(lambda s: s.rolling(window=4, min_periods=1).std())\n",
    "        )\n",
    "\n",
    "numeric_cols = model_df.select_dtypes(include=[np.number]).columns\n",
    "exclude_cols = {\"stress_target\"}\n",
    "feature_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "X = model_df[feature_cols].copy()\n",
    "X = X.dropna(axis=1, how=\"all\")\n",
    "feature_cols = list(X.columns)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=feature_cols, index=model_df.index)\n",
    "y = model_df[\"stress_target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(classes, class_weights)}\n",
    "\n",
    "hb_model = HistGradientBoostingClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.08,\n",
    "    max_iter=400,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "hb_model.fit(X_train, y_train)\n",
    "y_pred = hb_model.predict(X_test)\n",
    "y_prob = hb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "report_text = classification_report(y_test, y_pred)\n",
    "print(report_text)\n",
    "report_path = FIGURE_DIR / \"tabular_hgb_classification_report.txt\"\n",
    "report_path.write_text(report_text)\n",
    "report_csv_path = FIGURE_DIR / \"tabular_hgb_classification_report.csv\"\n",
    "pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).T.to_csv(report_csv_path)\n",
    "print(\"Saved HGB classification reports ->\", report_path, report_csv_path)\n",
    "\n",
    "roc_auc_value = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC-AUC:\", roc_auc_value)\n",
    "roc_disp = RocCurveDisplay.from_predictions(y_test, y_prob)\n",
    "roc_fig = roc_disp.figure_\n",
    "roc_path = FIGURE_DIR / \"tabular_hgb_roc.png\"\n",
    "roc_fig.savefig(roc_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved HGB ROC curve ->\", roc_path)\n",
    "\n",
    "summary_path = FIGURE_DIR / \"tabular_hgb_metrics.json\"\n",
    "summary_path.write_text(json.dumps({\"roc_auc\": float(roc_auc_value)}, indent=2))\n",
    "print(\"Saved HGB metrics summary ->\", summary_path)\n",
    "\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:07:44.817295Z",
     "iopub.execute_input": "2025-12-25T08:07:44.818010Z",
     "iopub.status.idle": "2025-12-25T08:07:45.760304Z",
     "shell.execute_reply.started": "2025-12-25T08:07:44.817984Z",
     "shell.execute_reply": "2025-12-25T08:07:45.759441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n           0       0.84      0.95      0.89       625\n           1       0.14      0.04      0.06       117\n\n    accuracy                           0.81       742\n   macro avg       0.49      0.50      0.48       742\nweighted avg       0.73      0.81      0.76       742\n\nROC-AUC: 0.4957128205128205\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Sequence Modeling (CNN vs CNN-GRU)\n",
    "\n",
    "While gradient boosting handles tabular aggregates, BeeUnity also experiments with temporal deep learning on sliding windows of hive telemetry. `SEQUENCE_MODEL_VARIANT` toggles between a pure 1D CNN head (fast, robust) and a conv+bi-GRU hybrid (captures temporal order). Windows are stratified, oversampled with a WeightedRandomSampler, and trained under BCE-with-logits using class-balanced weights. Logged AUC, threshold scans, and classification reports expose the limits of the current data (especially stress recall), giving the manuscript concrete evidence for the discussion and future-work sections.\n"
   ]
  },
  {
   "id": "38cc1701",
   "cell_type": "code",
   "source": [
    "\n",
    "WINDOW_SIZE = 12\n",
    "SEQUENCE_MODEL_VARIANT = \"cnn\"  # Options: \"cnn\", \"cnn_gru\"\n",
    "\n",
    "feature_columns = [col for col in feature_cols if col in model_df.columns]\n",
    "sequence_features = model_df[feature_columns].fillna(model_df[feature_columns].median()).copy()\n",
    "sequence_targets = model_df['stress_target'].values\n",
    "\n",
    "X_sequences = []\n",
    "y_sequences = []\n",
    "metadata = []\n",
    "for hive_id, group in model_df.groupby('hive_id'):\n",
    "    group = group.sort_values('date')\n",
    "    features = group[feature_columns].fillna(group[feature_columns].median()).values\n",
    "    targets = group['stress_target'].values\n",
    "    dates = group['date'].values\n",
    "    if len(group) <= WINDOW_SIZE:\n",
    "        continue\n",
    "    for idx in range(WINDOW_SIZE, len(group)):\n",
    "        window = features[idx-WINDOW_SIZE:idx]\n",
    "        X_sequences.append(window)\n",
    "        y_sequences.append(targets[idx])\n",
    "        metadata.append({\"hive_id\": hive_id, \"date\": dates[idx]})\n",
    "\n",
    "X_sequences = np.array(X_sequences, dtype=np.float32)\n",
    "y_sequences = np.array(y_sequences, dtype=np.float32)\n",
    "print(f'Total sequences: {X_sequences.shape[0]} | window shape: {X_sequences.shape[1:]}')\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.X = torch.tensor(sequences, dtype=torch.float32)\n",
    "        self.y = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(\n",
    "    X_sequences, y_sequences, test_size=0.2, random_state=42, stratify=y_sequences\n",
    ")\n",
    "\n",
    "train_dataset = SequenceDataset(X_train_seq, y_train_seq)\n",
    "val_dataset = SequenceDataset(X_test_seq, y_test_seq)\n",
    "\n",
    "train_class_counts = np.bincount(y_train_seq.astype(int))\n",
    "train_class_counts = np.pad(train_class_counts, (0, max(0, 2 - len(train_class_counts))), constant_values=0)\n",
    "print(\"Train class distribution:\", {cls: int(count) for cls, count in enumerate(train_class_counts)})\n",
    "\n",
    "samples_weight = np.array([1.0 / max(train_class_counts[int(label)], 1) for label in y_train_seq])\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=torch.tensor(samples_weight, dtype=torch.double),\n",
    "    num_samples=len(samples_weight),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "input_channels = X_sequences.shape[-1]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class HiveCNNBaseline(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "class HiveCNNRecurrent(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(128)\n",
    "        self.gru = nn.GRU(128, 64, batch_first=True, bidirectional=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.layer_norm(x)\n",
    "        _, h_n = self.gru(x)\n",
    "        h_n = h_n.transpose(0, 1).reshape(x.size(0), -1)\n",
    "        x = self.classifier(h_n)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "MODEL_FACTORY = {\n",
    "    \"cnn\": HiveCNNBaseline,\n",
    "    \"cnn_gru\": HiveCNNRecurrent,\n",
    "}\n",
    "if SEQUENCE_MODEL_VARIANT not in MODEL_FACTORY:\n",
    "    raise ValueError(f\"Unknown SEQUENCE_MODEL_VARIANT={SEQUENCE_MODEL_VARIANT}\")\n",
    "\n",
    "model_cls = MODEL_FACTORY[SEQUENCE_MODEL_VARIANT]\n",
    "model = model_cls(input_channels).to(device)\n",
    "base_lr = 1e-3 if SEQUENCE_MODEL_VARIANT == \"cnn\" else 5e-4\n",
    "print(f\"Training sequence variant: {SEQUENCE_MODEL_VARIANT} (lr={base_lr})\")\n",
    "\n",
    "pos_weight_value = float(max(1.0, (len(y_train_seq) - y_train_seq.sum()) / max(1.0, y_train_seq.sum())))\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight_value, device=device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=base_lr, weight_decay=1e-4)\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train(train)\n",
    "    total_loss = 0\n",
    "    preds, targets = [], []\n",
    "    for batch_X, batch_y in loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = model(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        total_loss += loss.item() * batch_X.size(0)\n",
    "        preds.append(torch.sigmoid(logits).detach().cpu().numpy())\n",
    "        targets.append(batch_y.detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "    return total_loss / len(loader.dataset), roc_auc_score(targets, preds)\n",
    "\n",
    "epochs = 50\n",
    "best_auc = 0\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "model_path = MAIN_DATA_DIR / \"hive_cnn_torch.pt\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_auc = run_epoch(train_loader, train=True)\n",
    "    val_loss, val_auc = run_epoch(val_loader, train=False)\n",
    "    print(f\"Epoch {epoch+1:02d}: train_loss={train_loss:.4f} AUC={train_auc:.3f} | val_loss={val_loss:.4f} AUC={val_auc:.3f}\")\n",
    "    if val_auc > best_auc + 1e-3:\n",
    "        best_auc = val_auc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = []\n",
    "    labels = []\n",
    "    for batch_X, batch_y in val_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        logits.append(model(batch_X).cpu())\n",
    "        labels.append(batch_y)\n",
    "    logits = torch.cat(logits)\n",
    "    labels = torch.cat(labels)\n",
    "    probs = torch.sigmoid(logits).numpy()\n",
    "    labels_np = labels.numpy()\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(labels_np, probs)\n",
    "f_scores = (2 * precision * recall) / np.clip(precision + recall, 1e-8, None)\n",
    "best_idx = np.argmax(f_scores)\n",
    "best_threshold = thresholds[max(best_idx - 1, 0)] if best_idx < len(thresholds) else 0.5\n",
    "preds = (probs >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"Best threshold based on F1: {best_threshold:.3f}\")\n",
    "report_text = classification_report(labels_np, preds)\n",
    "print('Sequence classification report:\n",
    "', report_text)\n",
    "seq_report_path = FIGURE_DIR / f\"sequence_{SEQUENCE_MODEL_VARIANT}_classification_report.txt\"\n",
    "seq_report_path.write_text(report_text)\n",
    "roc_auc_value = roc_auc_score(labels_np, probs)\n",
    "seq_metrics_path = FIGURE_DIR / f\"sequence_{SEQUENCE_MODEL_VARIANT}_metrics.json\"\n",
    "seq_metrics_path.write_text(json.dumps({\"roc_auc\": float(roc_auc_value), \"best_threshold\": float(best_threshold)}, indent=2))\n",
    "print('Test ROC-AUC:', roc_auc_value)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].plot(recall, precision)\n",
    "axes[0].set_title('Precision-Recall')\n",
    "axes[0].set_xlabel('Recall')\n",
    "axes[0].set_ylabel('Precision')\n",
    "RocCurveDisplay.from_predictions(labels_np, probs, ax=axes[1])\n",
    "axes[1].set_title('ROC Curve')\n",
    "plt.tight_layout()\n",
    "seq_fig_path = FIGURE_DIR / f\"sequence_{SEQUENCE_MODEL_VARIANT}_pr_roc.png\"\n",
    "fig.savefig(seq_fig_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved sequence evaluation figure ->', seq_fig_path)\n",
    "print('Best model weights saved to', model_path)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-25T08:08:01.932197Z",
     "iopub.execute_input": "2025-12-25T08:08:01.932673Z",
     "iopub.status.idle": "2025-12-25T08:08:04.794414Z",
     "shell.execute_reply.started": "2025-12-25T08:08:01.932645Z",
     "shell.execute_reply": "2025-12-25T08:08:04.793841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Total sequences: 3660 | window shape: (12, 24)\nTrain class distribution: {0: 2468, 1: 460}\nEpoch 01: train_loss=1.5770 AUC=0.486 | val_loss=1.6154 AUC=0.553\nEpoch 02: train_loss=1.4431 AUC=0.513 | val_loss=1.4029 AUC=0.524\nEpoch 03: train_loss=1.4032 AUC=0.557 | val_loss=1.5364 AUC=0.548\nEpoch 04: train_loss=1.3525 AUC=0.636 | val_loss=1.2314 AUC=0.540\nEpoch 05: train_loss=1.2980 AUC=0.692 | val_loss=1.8166 AUC=0.555\nEpoch 06: train_loss=1.2151 AUC=0.748 | val_loss=3.1202 AUC=0.486\nEpoch 07: train_loss=1.1138 AUC=0.795 | val_loss=1.2588 AUC=0.520\nEpoch 08: train_loss=1.0710 AUC=0.814 | val_loss=1.8144 AUC=0.529\nEpoch 09: train_loss=0.8801 AUC=0.871 | val_loss=2.2834 AUC=0.576\nEpoch 10: train_loss=0.8744 AUC=0.870 | val_loss=1.7548 AUC=0.533\nEpoch 11: train_loss=0.8229 AUC=0.887 | val_loss=1.9230 AUC=0.527\nEpoch 12: train_loss=0.8051 AUC=0.890 | val_loss=2.1982 AUC=0.511\nEpoch 13: train_loss=0.5264 AUC=0.947 | val_loss=3.0869 AUC=0.523\nEpoch 14: train_loss=0.5934 AUC=0.940 | val_loss=3.3008 AUC=0.506\nEarly stopping triggered.\nBest threshold based on F1: 0.030\n              precision    recall  f1-score   support\n\n         0.0       0.92      0.24      0.39       617\n         1.0       0.18      0.88      0.30       115\n\n    accuracy                           0.34       732\n   macro avg       0.55      0.56      0.34       732\nweighted avg       0.80      0.34      0.37       732\n\nTest ROC-AUC: 0.5763089281939258\nBest model weights saved to /kaggle/working/content/main-data/hive_cnn_torch.pt\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 105
  }
 ]
}