{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 12134294,
     "sourceType": "datasetVersion",
     "datasetId": 7505074
    },
    {
     "sourceId": 14288414,
     "sourceType": "datasetVersion",
     "datasetId": 9120225
    },
    {
     "sourceId": 461059,
     "sourceType": "datasetVersion",
     "datasetId": 166904
    }
   ],
   "dockerImageVersionId": 31234,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "fdc48dcf",
   "cell_type": "markdown",
   "source": "# Kaggle Cloud Ops: Queen Bee Acoustics + Makueni Apiary Intelligence",
   "metadata": {}
  },
  {
   "id": "9325b117",
   "cell_type": "markdown",
   "source": "This unified notebook stitches together:\n\n1. **Queen Bee acoustic detection (CNN + hyperparameter tuning)**\n2. **Makueni Apiary intelligence workflows (weather, NDVI, telemetry, hive stress ML)**\n\n> **Kaggle usage:** Attach the `harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen` dataset plus any `content/main-data` exports as Kaggle data sources. All intermediate files are written under `content/` so the same notebook also works locally.",
   "metadata": {}
  },
  {
   "id": "2f36f683-6666-4169-9339-6b24eb66bc8e",
   "cell_type": "markdown",
   "source": "## BeeUnity System Blueprint\n\nBeeUnity couples two complementary sensing/analytics tracks inside a single reproducible notebook.\n\n- **Acoustic intelligence (Sections \u00a73-15)** ingests the Kaggle beehive audio corpus, generates mel spectrograms, and trains/ tunes a convolutional network for multi-class queen state detection. The outputs are calibrated probabilities + decision thresholds that can be streamed into downstream alerting or fusion models.\n- **Makueni apiary intelligence (Sections \u00a717 onwards)** orchestrates weather/NDVI staging, hive log synthesis, and two tiers of ML models (sklearn HistGradientBoosting + PyTorch temporal CNN/GRU) to estimate hive stress / occupancy risk.\n\nEvery block includes deterministic filesystem staging and writes intermediate products to `/kaggle/working` or `content/` so the research report can quote exact metrics while Kaggle submissions remain GPU safe.\n",
   "metadata": {}
  },
  {
   "id": "ffc483a3",
   "cell_type": "code",
   "source": "!pip install -q earthengine-api ipyleaflet ipywidgets keras-tuner librosa tqdm",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:45:56.429038Z",
     "iopub.execute_input": "2025-12-28T13:45:56.429383Z",
     "iopub.status.idle": "2025-12-28T13:46:00.027046Z",
     "shell.execute_reply.started": "2025-12-28T13:45:56.429354Z",
     "shell.execute_reply": "2025-12-28T13:46:00.026240Z"
    }
   },
   "outputs": [],
   "execution_count": 183
  },
  {
   "id": "422e9772",
   "cell_type": "code",
   "source": "import os\nimport shutil\nfrom pathlib import Path\n\nPROJECT_ROOT = Path.cwd()\nDEFAULT_CONTENT = PROJECT_ROOT / \"content\"\nKAGGLE_WORKING = Path(\"/kaggle/working\")\n\nif DEFAULT_CONTENT.exists():\n    CONTENT_ROOT = DEFAULT_CONTENT.resolve()\nelse:\n    CONTENT_ROOT = (KAGGLE_WORKING / \"content\").resolve()\n    CONTENT_ROOT.mkdir(parents=True, exist_ok=True)\n\nos.environ[\"MERGED_CONTENT_ROOT\"] = str(CONTENT_ROOT)\nMAIN_DATA_DIR = (CONTENT_ROOT / \"main-data\")\nMAIN_DATA_DIR.mkdir(parents=True, exist_ok=True)\n\nKAGGLE_INPUT_ROOT = Path(\"/kaggle/input\")\n\ndef _stage_dataset(keyword, target_subdir):\n    if not KAGGLE_INPUT_ROOT.exists():\n        return None\n    matches = [p for p in KAGGLE_INPUT_ROOT.iterdir() if keyword in p.name.lower()]\n    if not matches:\n        print(f\"[setup] Kaggle input dataset containing '{keyword}' not found.\")\n        return None\n    source = matches[0]\n    target = CONTENT_ROOT / target_subdir\n    shutil.rmtree(target, ignore_errors=True)\n    shutil.copytree(source, target, dirs_exist_ok=True)\n    print(f\"[setup] Staged {source.name} -> {target}\")\n    return target\n\ndef _maybe_stage(keyword, subdir):\n    try:\n        _stage_dataset(keyword, subdir)\n    except Exception as exc:\n        print(f\"[setup] Skipping auto-stage for {keyword}: {exc}\")\n\n_maybe_stage(\"beehive\", \"beehive_audio\")\n_maybe_stage(\"makueni\", \"main-data\")\n\nprint(f\"CONTENT_ROOT -> {CONTENT_ROOT}\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:46:00.029256Z",
     "iopub.execute_input": "2025-12-28T13:46:00.029656Z",
     "iopub.status.idle": "2025-12-28T13:47:21.677642Z",
     "shell.execute_reply.started": "2025-12-28T13:46:00.029625Z",
     "shell.execute_reply": "2025-12-28T13:47:21.676867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "[setup] Staged beehive-audio-dataset-with-queen-and-without-queen -> /kaggle/working/content/beehive_audio\n[setup] Staged makueni-ndvi-2008-2025-csv -> /kaggle/working/content/main-data\nCONTENT_ROOT -> /kaggle/working/content\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 184
  },
  {
   "id": "e8446e4b",
   "cell_type": "code",
   "source": "import calendar\nimport datetime as dt\nimport gc\nimport io\nimport json\nimport math\nimport os\nimport time\nimport warnings\nfrom pathlib import Path\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport keras_tuner as kt\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom sklearn.metrics import (\n    accuracy_score,\n    average_precision_score,\n    classification_report,\n    confusion_matrix,\n    f1_score,\n    precision_recall_curve,\n    precision_score,\n    recall_score,\n    roc_auc_score,\n    RocCurveDisplay\n)\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nimport requests\nwarnings.filterwarnings(\"ignore\")\nsns.set(style=\"whitegrid\")\nplt.rcParams[\"figure.figsize\"] = (8, 4)\nCONTENT_ROOT = Path(os.environ[\"MERGED_CONTENT_ROOT\"])\nMAIN_DATA_DIR = CONTENT_ROOT / \"main-data\"\nfrom pathlib import Path\nFIGURE_DIR = Path('artifacts/figures')\nFIGURE_DIR.mkdir(parents=True, exist_ok=True)\nprint('Saving figures and tables to', FIGURE_DIR.resolve())\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:47:21.678574Z",
     "iopub.execute_input": "2025-12-28T13:47:21.678879Z",
     "iopub.status.idle": "2025-12-28T13:47:21.688640Z",
     "shell.execute_reply.started": "2025-12-28T13:47:21.678844Z",
     "shell.execute_reply": "2025-12-28T13:47:21.687943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Saving figures and tables to /kaggle/working/artifacts/figures\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 185
  },
  {
   "id": "c0841127-3c28-43d2-9771-c8fa7896202a",
   "cell_type": "code",
   "source": "from pathlib import Path\nFIGURE_DIR = Path('artifacts/figures')\nFIGURE_DIR.mkdir(parents=True, exist_ok=True)\nprint('Saving figures and tables to', FIGURE_DIR.resolve())\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:47:21.689813Z",
     "iopub.execute_input": "2025-12-28T13:47:21.690261Z",
     "iopub.status.idle": "2025-12-28T13:47:21.703162Z",
     "shell.execute_reply.started": "2025-12-28T13:47:21.690240Z",
     "shell.execute_reply": "2025-12-28T13:47:21.702447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Saving figures and tables to /kaggle/working/artifacts/figures\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 186
  },
  {
   "id": "65370be7-7ace-4303-9e7c-da72d1989ebe",
   "cell_type": "code",
   "source": "FIGURE_DIR = Path('/kaggle/working/figures')\nFIGURE_DIR.mkdir(parents=True, exist_ok=True)\nprint('Saving figures and tables to', FIGURE_DIR)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:47:21.705179Z",
     "iopub.execute_input": "2025-12-28T13:47:21.705572Z",
     "iopub.status.idle": "2025-12-28T13:47:21.713240Z",
     "shell.execute_reply.started": "2025-12-28T13:47:21.705463Z",
     "shell.execute_reply": "2025-12-28T13:47:21.712629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Saving figures and tables to /kaggle/working/figures\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 187
  },
  {
   "id": "00311da8",
   "cell_type": "markdown",
   "source": "## Queen Bee Acoustic Detection Pipeline",
   "metadata": {}
  },
  {
   "id": "673125f9-a703-4f88-bdd9-5f5491598d9d",
   "cell_type": "markdown",
   "source": "### Acoustic Dataset Staging & Lineage\n\nThe queen-bee classifier is trained from the Kaggle dataset `harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen`. We avoid copying raw WAVs into writable storage unless needed; instead, `_discover_audio_dataset` crawls the mounted `/kaggle/input` tree, validates the folder structure, and exposes canonical paths for the `QueenBee Present`, `QueenBee Absent`, and `External Noise` subsets. This guarantees that every spectrogram (and therefore every model checkpoint) can be traced back to a known dataset version, satisfying the reproducibility requirement in the BeeUnity methodology.\n",
   "metadata": {}
  },
  {
   "id": "1c46188a",
   "cell_type": "code",
   "source": "from pathlib import Path\n\ndef _discover_audio_dataset(content_root: Path) -> Path:\n    search_root = Path(\"/kaggle/input/beehive-audio-dataset-with-queen-and-without-queen\")\n    if not search_root.exists():\n        raise FileNotFoundError(\n            \"Dataset not staged. Attach Kaggle dataset \"\n            \"'harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen'.\"\n        )\n\n    for candidate in sorted(search_root.rglob(\"Dataset\")):\n        if (candidate / \"Bee Hive Audios\").exists():\n            return candidate\n\n    raise FileNotFoundError(\"Could not locate 'Dataset/Bee Hive Audios'.\")\n\n# Discover dataset (READ-ONLY)\nAUDIO_DATASET_ROOT = _discover_audio_dataset(None)\n\nBEEHIVE_AUDIO_DIR = next(AUDIO_DATASET_ROOT.glob(\"**/Bee Hive Audios\"))\nQUEEN_PRESENT_DIR = BEEHIVE_AUDIO_DIR / \"QueenBee Present\"\nQUEEN_ABSENT_DIR = BEEHIVE_AUDIO_DIR / \"QueenBee Absent\"\nEXTERNAL_DIR = AUDIO_DATASET_ROOT / \"External Noise\"\n\n# WRITEABLE spectrogram directory\nSPECTROGRAM_DIR = Path(\"/kaggle/working/spectrograms\")\nSPECTROGRAM_PRESENT = SPECTROGRAM_DIR / \"present\"\nSPECTROGRAM_ABSENT = SPECTROGRAM_DIR / \"absent\"\nSPECTROGRAM_EXTERNAL = SPECTROGRAM_DIR / \"external\"\n\nfor path in [SPECTROGRAM_PRESENT, SPECTROGRAM_ABSENT, SPECTROGRAM_EXTERNAL]:\n    path.mkdir(parents=True, exist_ok=True)\n\nprint(\"Audio dataset root (read-only):\", AUDIO_DATASET_ROOT)\nprint(\"Spectrogram cache (writable):\", SPECTROGRAM_DIR)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:47:21.714213Z",
     "iopub.execute_input": "2025-12-28T13:47:21.714485Z",
     "iopub.status.idle": "2025-12-28T13:47:25.968425Z",
     "shell.execute_reply.started": "2025-12-28T13:47:21.714457Z",
     "shell.execute_reply": "2025-12-28T13:47:25.967783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Audio dataset root (read-only): /kaggle/input/beehive-audio-dataset-with-queen-and-without-queen/Dataset\nSpectrogram cache (writable): /kaggle/working/spectrograms\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 188
  },
  {
   "id": "5601ca8a",
   "cell_type": "code",
   "source": "try:\n    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu_resolver)\n    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n    strategy = tf.distribute.TPUStrategy(tpu_resolver)\n    ACCELERATOR = \"TPU\"\nexcept (ValueError, tf.errors.NotFoundError):\n    gpus = tf.config.list_physical_devices(\"GPU\")\n    if gpus:\n        for gpu in gpus:\n            try:\n                tf.config.experimental.set_memory_growth(gpu, True)\n            except Exception:\n                pass\n        # Default to single-replica strategy for Kaggle GPU stability\n        strategy = tf.distribute.get_strategy()\n        ACCELERATOR = \"GPU\"\n    else:\n        strategy = tf.distribute.get_strategy()\n        ACCELERATOR = \"CPU\"\n\nprint(f\"Using {ACCELERATOR} via {strategy.__class__.__name__}\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:47:25.969292Z",
     "iopub.execute_input": "2025-12-28T13:47:25.969602Z",
     "iopub.status.idle": "2025-12-28T13:47:25.975993Z",
     "shell.execute_reply.started": "2025-12-28T13:47:25.969580Z",
     "shell.execute_reply": "2025-12-28T13:47:25.975362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Using GPU via _DefaultDistributionStrategy\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 189
  },
  {
   "id": "774287bd-fb49-4d52-a455-1f09f6ff707b",
   "cell_type": "markdown",
   "source": "### Audio Conditioning & Spectrogram Cache\n\nTo stabilize CNN training we transform each WAV into a fixed 3-second mono clip sampled at 22.05 kHz. The `preprocess_and_save_spectrogram` routine trims silence, enforces constant-length padding, normalizes amplitude, and renders a 128\u00d7128 mel-spectrogram using librosa. Spectrograms land under `/kaggle/working/spectrograms/<class>/` and the generators only touch PNGs, eliminating expensive audio decoding during model fit. Progress-aware helpers (e.g., `_compute_progress`) let reruns skip already materialized windows so Kaggle GPU runtime stays within budget.\n",
   "metadata": {}
  },
  {
   "id": "20b2348e",
   "cell_type": "code",
   "source": "SAMPLE_RATE = 22050\nDURATION = 3\nSAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n\nlibrosa.cache.clear()\nplt.switch_backend(\"Agg\")\n\ndef preprocess_and_save_spectrogram(audio_path: Path, output_image_path: Path, sr=SAMPLE_RATE, duration=DURATION):\n    try:\n        y, _ = librosa.load(audio_path, sr=sr)\n        y, _ = librosa.effects.trim(y)\n        y = librosa.to_mono(y) if y.ndim > 1 else y\n        y = librosa.util.normalize(y)\n\n        expected_samples = sr * duration\n        if len(y) < expected_samples:\n            y = np.pad(y, (0, expected_samples - len(y)), mode=\"constant\")\n        else:\n            y = y[:expected_samples]\n\n        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n        mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n\n        plt.figure(figsize=(2, 2), dpi=64)\n        librosa.display.specshow(mel_db, sr=sr, cmap=\"magma\")\n        plt.axis(\"off\")\n        output_image_path.parent.mkdir(parents=True, exist_ok=True)\n        plt.savefig(output_image_path, bbox_inches=\"tight\", pad_inches=0)\n        plt.close()\n    except Exception as exc:\n        print(f\"[spectrogram] Failed on {audio_path}: {exc}\")\n\ndef _compute_progress(files, output_dir: Path):\n    total = len(files)\n    processed = sum((output_dir / f\"{Path(f).stem}.png\").exists() for f in files)\n    return total, processed\n\ndef process_audio_folder(input_dir: Path, output_dir: Path, desc: str):\n    if not input_dir.exists():\n        print(f\"[spectrogram] {input_dir} missing, skipping {desc}.\")\n        return\n    wav_files = sorted([f for f in input_dir.iterdir() if f.suffix.lower() == \".wav\"])\n    total, processed = _compute_progress([f.name for f in wav_files], output_dir)\n    with tqdm(total=total, initial=processed, desc=desc, unit=\"file\") as pbar:\n        for wav_path in wav_files:\n            out_path = output_dir / f\"{wav_path.stem}.png\"\n            if out_path.exists():\n                pbar.update(1)\n                continue\n            preprocess_and_save_spectrogram(wav_path, out_path)\n            gc.collect()\n            pbar.update(1)\n\ndef process_external_folder(input_dir: Path, output_dir: Path):\n    if not input_dir.exists():\n        print(\"[spectrogram] External noise folder missing, skipping.\")\n        return\n    audio_paths = []\n    for root, _, files in os.walk(input_dir):\n        audio_paths += [Path(root) / f for f in files if f.lower().endswith(\".wav\")]\n    with tqdm(total=len(audio_paths), desc=\"External noise\", unit=\"file\") as pbar:\n        for wav_path in audio_paths:\n            out_path = output_dir / f\"{wav_path.stem}.png\"\n            if out_path.exists():\n                pbar.update(1)\n                continue\n            preprocess_and_save_spectrogram(wav_path, out_path)\n            pbar.update(1)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:47:25.976906Z",
     "iopub.execute_input": "2025-12-28T13:47:25.977172Z",
     "iopub.status.idle": "2025-12-28T13:47:25.994216Z",
     "shell.execute_reply.started": "2025-12-28T13:47:25.977153Z",
     "shell.execute_reply": "2025-12-28T13:47:25.993541Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "[Memory(location=None)]: Flushing completely the cache\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 190
  },
  {
   "id": "5194f6d3",
   "cell_type": "code",
   "source": "process_audio_folder(QUEEN_PRESENT_DIR, SPECTROGRAM_PRESENT, \"QueenBee Present\")\nprocess_audio_folder(QUEEN_ABSENT_DIR, SPECTROGRAM_ABSENT, \"QueenBee Absent\")\nprocess_external_folder(EXTERNAL_DIR, SPECTROGRAM_EXTERNAL)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:47:25.995214Z",
     "iopub.execute_input": "2025-12-28T13:47:25.995507Z",
     "iopub.status.idle": "2025-12-28T13:47:26.853423Z",
     "shell.execute_reply.started": "2025-12-28T13:47:25.995479Z",
     "shell.execute_reply": "2025-12-28T13:47:26.852737Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "QueenBee Present: 8000file [00:00, 80482.86file/s]             \nQueenBee Absent: 4000file [00:00, 77831.56file/s]             \nExternal noise: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:00<00:00, 55305.74file/s]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 191
  },
  {
   "id": "fb90b30b",
   "cell_type": "code",
   "source": "def count_pngs(folder: Path):\n    return len([f for f in folder.glob(\"*.png\")])\n\nclass_labels = [\"present\", \"absent\", \"external\"]\ncounts = [\n    count_pngs(SPECTROGRAM_PRESENT),\n    count_pngs(SPECTROGRAM_ABSENT),\n    count_pngs(SPECTROGRAM_EXTERNAL),\n]\n\nplt.figure(figsize=(6, 4))\nbars = plt.bar(class_labels, counts, color=[\"sienna\", \"peru\", \"gray\"], edgecolor=\"black\")\nplt.ylim(0, max(counts) * 1.1 if counts else 10)\nplt.title(\"Spectrogram Count per Class\")\nplt.ylabel(\"Images\")\nfor bar in bars:\n    y = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width() / 2, y + max(1, y ** 0.5), int(y), ha=\"center\", va=\"bottom\")\nplt.show()\n\nprint(dict(zip(class_labels, counts)))\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:47:26.854269Z",
     "iopub.execute_input": "2025-12-28T13:47:26.854461Z",
     "iopub.status.idle": "2025-12-28T13:47:26.940529Z",
     "shell.execute_reply.started": "2025-12-28T13:47:26.854443Z",
     "shell.execute_reply": "2025-12-28T13:47:26.939996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "{'present': 4000, 'absent': 2000, 'external': 2000}\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 192
  },
  {
   "id": "070b018d-7e72-48c5-adc2-467d285d21e3",
   "cell_type": "markdown",
   "source": "### Stratified DataFrames, Augmentation, and Class Weights\n\nThe original ImageDataGenerator split approach caused leakage between validation/test folds. We now build a pandas catalog of every spectrogram file, stratify it into train/val/test via `train_test_split`, and feed `flow_from_dataframe` generators. Light-weight augmentations (flip + shifts) only touch the training subset. Class imbalance (present:absent:external = 4000:2000:2000) is mitigated through `compute_class_weight` and a custom `SparseClassRecall` metric that explicitly tracks recall on the underrepresented `absent` class; both feed into every Keras fit/tuning call so the notebook\u2019s metrics align with the research objective of catching queen loss events.\n",
   "metadata": {}
  },
  {
   "id": "b1438348",
   "cell_type": "code",
   "source": "IMG_SIZE = (128, 128)\nBASE_BATCH_SIZE = 32\nBATCH_SIZE = BASE_BATCH_SIZE  # Keep per-device batch size stable on Kaggle\nSEED = 42\n\nspectro_records = []\nfor class_dir in sorted(SPECTROGRAM_DIR.iterdir()):\n    if class_dir.is_dir():\n        label = class_dir.name\n        for img_path in class_dir.glob(\"*.png\"):\n            spectro_records.append({\"filepath\": str(img_path), \"label\": label})\n\nif not spectro_records:\n    raise RuntimeError(\"No spectrograms were generated; run preprocessing above first.\")\n\nspectro_df = pd.DataFrame(spectro_records)\nCLASS_NAMES = sorted(spectro_df[\"label\"].unique())\n\ntrain_df, temp_df = train_test_split(\n    spectro_df,\n    test_size=0.4,\n    stratify=spectro_df[\"label\"],\n    random_state=SEED\n)\nval_df, test_df = train_test_split(\n    temp_df,\n    test_size=0.5,\n    stratify=temp_df[\"label\"],\n    random_state=SEED\n)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    horizontal_flip=True,\n    width_shift_range=0.05,\n    height_shift_range=0.05\n)\neval_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_gen = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"sparse\",\n    classes=CLASS_NAMES,\n    shuffle=True,\n    seed=SEED\n)\n\nval_gen = eval_datagen.flow_from_dataframe(\n    val_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"sparse\",\n    classes=CLASS_NAMES,\n    shuffle=False,\n    seed=SEED\n)\n\ntest_gen = eval_datagen.flow_from_dataframe(\n    test_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"sparse\",\n    classes=CLASS_NAMES,\n    shuffle=False,\n    seed=SEED\n)\n\nraw_class_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.array(CLASS_NAMES),\n    y=train_df[\"label\"]\n)\nCLASS_WEIGHTS = {\n    train_gen.class_indices[label]: weight for label, weight in zip(CLASS_NAMES, raw_class_weights)\n}\nprint(\"Class indices:\", train_gen.class_indices)\nprint(\"Class weights:\", CLASS_WEIGHTS)\n\nABSENT_CLASS_INDEX = train_gen.class_indices[\"absent\"]\n\nclass SparseClassRecall(tf.keras.metrics.Metric):\n    def __init__(self, class_id, name=\"sparse_class_recall\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.class_id = class_id\n        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.false_negatives = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.cast(tf.reshape(y_true, [-1]), tf.int32)\n        y_pred = tf.cast(tf.argmax(y_pred, axis=-1), tf.int32)\n        class_mask = tf.cast(tf.equal(y_true, self.class_id), self.dtype)\n        pred_mask = tf.cast(tf.equal(y_pred, self.class_id), self.dtype)\n        if sample_weight is None:\n            weights = tf.ones_like(class_mask)\n        else:\n            weights = tf.cast(tf.reshape(sample_weight, [-1]), self.dtype)\n            weights = tf.broadcast_to(weights, tf.shape(class_mask))\n        weighted_mask = class_mask * weights\n        tp = tf.reduce_sum(pred_mask * weighted_mask)\n        fn = tf.reduce_sum((1.0 - pred_mask) * weighted_mask)\n        self.true_positives.assign_add(tp)\n        self.false_negatives.assign_add(fn)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\"class_id\": int(self.class_id)})\n        return config\n\n    def result(self):\n        return tf.math.divide_no_nan(self.true_positives, self.true_positives + self.false_negatives)\n\n    def reset_states(self):\n        self.true_positives.assign(0.0)\n        self.false_negatives.assign(0.0)\n\ndef make_absent_recall(name=\"recall_absent\"):\n    return SparseClassRecall(class_id=ABSENT_CLASS_INDEX, name=name)\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:47:26.941412Z",
     "iopub.execute_input": "2025-12-28T13:47:26.941708Z",
     "iopub.status.idle": "2025-12-28T13:47:27.066601Z",
     "shell.execute_reply.started": "2025-12-28T13:47:26.941680Z",
     "shell.execute_reply": "2025-12-28T13:47:27.065916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Found 4800 validated image filenames belonging to 3 classes.\nFound 1600 validated image filenames belonging to 3 classes.\nFound 1600 validated image filenames belonging to 3 classes.\nClass indices: {'absent': 0, 'external': 1, 'present': 2}\nClass weights: {0: np.float64(1.3333333333333333), 1: np.float64(1.3333333333333333), 2: np.float64(0.6666666666666666)}\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 193
  },
  {
   "id": "58a40d5d-8bf8-4979-9c60-01cf60be727b",
   "cell_type": "markdown",
   "source": "### Baseline CNN Training Plan\n\nThe baseline network is intentionally compact so it trains quickly on Kaggle GPUs yet captures salient spectral patterns: three Conv-BN-Pool stages followed by GAP and a 64-unit dense head. Training runs under the selected `strategy` with class weights + early stopping keyed to `val_recall_absent` to bias the model toward correctly flagging queen-absent clips. This baseline establishes the minimum viable performance before hyperparameter search.\n",
   "metadata": {}
  },
  {
   "id": "a233e93a",
   "cell_type": "code",
   "source": "from tensorflow.keras.callbacks import EarlyStopping\n\ndef build_baseline_model():\n    model = models.Sequential([\n        layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\", input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(64, activation=\"relu\"),\n        layers.Dropout(0.5),\n        layers.Dense(3, activation=\"softmax\"),\n    ])\n    model.compile(\n        optimizer=\"adam\",\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\", make_absent_recall()]\n    )\n    return model\n\nwith strategy.scope():\n    baseline_model = build_baseline_model()\n\nbaseline_callbacks = [\n    EarlyStopping(monitor=\"val_recall_absent\", mode=\"max\", patience=3, restore_best_weights=True)\n]\n\nbaseline_history = baseline_model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=20,\n    class_weight=CLASS_WEIGHTS,\n    callbacks=baseline_callbacks\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:47:27.067605Z",
     "iopub.execute_input": "2025-12-28T13:47:27.067891Z",
     "iopub.status.idle": "2025-12-28T13:49:37.061436Z",
     "shell.execute_reply.started": "2025-12-28T13:47:27.067869Z",
     "shell.execute_reply": "2025-12-28T13:49:37.060650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 143ms/step - accuracy: 0.6849 - loss: 0.6948 - recall_absent: 0.7364 - val_accuracy: 0.5000 - val_loss: 1.5472 - val_recall_absent: 0.0000e+00\nEpoch 2/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 139ms/step - accuracy: 0.8847 - loss: 0.3151 - recall_absent: 0.8471 - val_accuracy: 0.5000 - val_loss: 3.8994 - val_recall_absent: 0.0000e+00\nEpoch 3/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9380 - loss: 0.1852 - recall_absent: 0.9162 - val_accuracy: 0.7019 - val_loss: 1.3134 - val_recall_absent: 0.9100\nEpoch 4/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 138ms/step - accuracy: 0.9482 - loss: 0.1418 - recall_absent: 0.9398 - val_accuracy: 0.4269 - val_loss: 2.2550 - val_recall_absent: 0.6975\nEpoch 5/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9465 - loss: 0.1541 - recall_absent: 0.9442 - val_accuracy: 0.2537 - val_loss: 3.2978 - val_recall_absent: 0.0125\nEpoch 6/20\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9591 - loss: 0.1150 - recall_absent: 0.9518 - val_accuracy: 0.2500 - val_loss: 6.3733 - val_recall_absent: 0.0000e+00\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 194
  },
  {
   "id": "04506242-d867-47f5-8efb-c7452a7fa19b",
   "cell_type": "markdown",
   "source": "### KerasTuner Hyperband Search & Fine-Tune\n\nHyperparameter tuning explores filter widths, dense units, dropout, and optimizer choice via `kt.Hyperband`, again optimizing `val_recall_absent`. The tuner runs outside the distribution `strategy` scope (per TensorFlow guidance) while the search/ fine-tune phases inherit the same class weights + early stopping regime as the baseline. The best trial is persisted as a `.keras` artifact under `/kaggle/working` for downstream deployment / report inclusion.\n",
   "metadata": {}
  },
  {
   "id": "75194ab4",
   "cell_type": "code",
   "source": "from tensorflow.keras.callbacks import EarlyStopping\nfrom pathlib import Path\n\ndef build_tunable_model(hp):\n    model = models.Sequential([\n        layers.Conv2D(\n            hp.Choice(\"conv1\", [32, 64]), 3,\n            activation=\"relu\", padding=\"same\",\n            input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n        ),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.Conv2D(hp.Choice(\"conv2\", [64, 128]), 3, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.Conv2D(hp.Choice(\"conv3\", [128, 256]), 3, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(hp.Int(\"dense_units\", 64, 128, step=32), activation=\"relu\"),\n        layers.Dropout(hp.Float(\"dropout\", 0.3, 0.6, step=0.1)),\n        layers.Dense(3, activation=\"softmax\"),\n    ])\n\n    model.compile(\n        optimizer=hp.Choice(\"optimizer\", [\"adam\", \"nadam\"]),\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\", make_absent_recall()]\n    )\n    return model\n\n\n# Strategy ONLY for tuner creation\nwith strategy.scope():\n    tuner = kt.Hyperband(\n        build_tunable_model,\n        objective=kt.Objective(\"val_recall_absent\", direction=\"max\"),\n        max_epochs=15,\n        factor=3,\n        directory=\"/kaggle/working/queenbee_tuning\",\n        project_name=\"queenbee_cnn\"\n    )\n\nstopper = EarlyStopping(\n    monitor=\"val_recall_absent\",\n    mode=\"max\",\n    patience=3,\n    restore_best_weights=True\n)\n\n# Search OUTSIDE strategy scope\ntuner.search(\n    train_gen,\n    validation_data=val_gen,\n    epochs=15,\n    class_weight=CLASS_WEIGHTS,\n    callbacks=[stopper]\n)\n\n# NO strategy scope here\nbest_model = tuner.get_best_models(num_models=1)[0]\n\nfine_tune_history = best_model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=15,\n    class_weight=CLASS_WEIGHTS,\n    callbacks=[stopper]\n)\n\n# Writable save path\nbest_model_path = Path(\"/kaggle/working/queenbee_final_tuned_model.keras\")\nbest_model.save(best_model_path)\n\nprint(\"Saved tuned model to\", best_model_path)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:49:37.062722Z",
     "iopub.execute_input": "2025-12-28T13:49:37.062945Z",
     "iopub.status.idle": "2025-12-28T13:52:33.379778Z",
     "shell.execute_reply.started": "2025-12-28T13:49:37.062923Z",
     "shell.execute_reply": "2025-12-28T13:52:33.378920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Reloading Tuner from /kaggle/working/queenbee_tuning/queenbee_cnn/tuner0.json\nEpoch 1/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 144ms/step - accuracy: 0.8890 - loss: 0.3432 - recall_absent: 0.8700 - val_accuracy: 0.2700 - val_loss: 5.6630 - val_recall_absent: 0.0800\nEpoch 2/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 142ms/step - accuracy: 0.9605 - loss: 0.1017 - recall_absent: 0.9544 - val_accuracy: 0.5750 - val_loss: 2.0354 - val_recall_absent: 0.9725\nEpoch 3/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 141ms/step - accuracy: 0.9706 - loss: 0.0704 - recall_absent: 0.9691 - val_accuracy: 0.3206 - val_loss: 3.5317 - val_recall_absent: 0.1650\nEpoch 4/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 143ms/step - accuracy: 0.9754 - loss: 0.0572 - recall_absent: 0.9757 - val_accuracy: 0.2669 - val_loss: 4.7368 - val_recall_absent: 0.0000e+00\nEpoch 5/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 139ms/step - accuracy: 0.9752 - loss: 0.0620 - recall_absent: 0.9723 - val_accuracy: 0.9269 - val_loss: 0.1680 - val_recall_absent: 0.9975\nEpoch 6/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 140ms/step - accuracy: 0.9769 - loss: 0.0583 - recall_absent: 0.9799 - val_accuracy: 0.7950 - val_loss: 0.5838 - val_recall_absent: 0.9300\nEpoch 7/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 140ms/step - accuracy: 0.9824 - loss: 0.0471 - recall_absent: 0.9936 - val_accuracy: 0.7944 - val_loss: 0.7620 - val_recall_absent: 0.8875\nEpoch 8/15\n\u001b[1m150/150\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 139ms/step - accuracy: 0.9821 - loss: 0.0468 - recall_absent: 0.9741 - val_accuracy: 0.6481 - val_loss: 1.0932 - val_recall_absent: 0.0425\nSaved tuned model to /kaggle/working/queenbee_final_tuned_model.keras\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 195
  },
  {
   "id": "2e8f7167",
   "cell_type": "code",
   "source": "from tensorflow.keras.models import load_model\n\nmodel_for_eval = load_model(\n    best_model_path,\n    custom_objects={\"SparseClassRecall\": SparseClassRecall}\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:52:33.382536Z",
     "iopub.execute_input": "2025-12-28T13:52:33.382857Z",
     "iopub.status.idle": "2025-12-28T13:52:33.628418Z",
     "shell.execute_reply.started": "2025-12-28T13:52:33.382832Z",
     "shell.execute_reply": "2025-12-28T13:52:33.627675Z"
    }
   },
   "outputs": [],
   "execution_count": 196
  },
  {
   "id": "890403d2-2bac-4feb-925a-09b27723c576",
   "cell_type": "markdown",
   "source": "### Probability Calibration & Threshold Selection\n\nRaw softmax scores tend to collapse onto the majority `present` class. After loading the tuned CNN we perform two evaluation modes: standard argmax and calibrated predictions. Validation probabilities drive per-class precision-recall curves, from which we select F1-optimal thresholds. Those calibrated thresholds are then applied to the held-out test generator, yielding confusion matrices, detailed classification reports, and macro ROC/PR AUC metrics that the manuscript can cite when describing queen-state detection performance.\n",
   "metadata": {}
  },
  {
   "id": "921011f7",
   "cell_type": "code",
   "source": "def run_inference(model, generator):\n    generator.reset()\n    y_prob = model.predict(generator, verbose=1)\n    y_true = generator.classes\n    return y_prob, y_true\n\n\ndef derive_thresholds(y_true, y_prob, class_names):\n    y_true_oh = tf.keras.utils.to_categorical(y_true, num_classes=len(class_names))\n    thresholds = {}\n    for idx, name in enumerate(class_names):\n        precision, recall, thresh = precision_recall_curve(y_true_oh[:, idx], y_prob[:, idx])\n        if thresh.size == 0:\n            thresholds[name] = 0.5\n            continue\n        f1 = 2 * precision * recall / np.clip(precision + recall, 1e-8, None)\n        best_idx = np.nanargmax(f1)\n        thresholds[name] = float(thresh[min(best_idx, len(thresh) - 1)])\n    return thresholds\n\n\ndef predict_with_thresholds(y_prob, class_names, thresholds):\n    calibrated = []\n    for row in y_prob:\n        chosen_idx = None\n        chosen_score = -1.0\n        for idx, name in enumerate(class_names):\n            threshold = thresholds.get(name, 0.5)\n            if row[idx] >= threshold and row[idx] > chosen_score:\n                chosen_idx = idx\n                chosen_score = row[idx]\n        if chosen_idx is None:\n            chosen_idx = int(np.argmax(row))\n        calibrated.append(chosen_idx)\n    return np.array(calibrated)\n\n\ndef summarize_metrics(y_true, y_pred, label):\n    return {\n        \"Mode\": label,\n        \"Accuracy\": accuracy_score(y_true, y_pred),\n        \"Macro Precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n        \"Macro Recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n        \"Macro F1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n    }\n\nval_prob, val_true = run_inference(model_for_eval, val_gen)\nclass_names = list(test_gen.class_indices.keys())\nthresholds = derive_thresholds(val_true, val_prob, class_names)\nprint(\"Calibrated probability thresholds:\")\nfor name in class_names:\n    print(f\"  {name}: {thresholds[name]:.3f}\")\n\nmetrics = []\ntest_prob, test_true = run_inference(model_for_eval, test_gen)\ndefault_pred = np.argmax(test_prob, axis=1)\ncalibrated_pred = predict_with_thresholds(test_prob, class_names, thresholds)\n\nmetrics_table = pd.DataFrame([\n    summarize_metrics(test_true, default_pred, \"Argmax\"),\n    summarize_metrics(test_true, calibrated_pred, \"Calibrated\")\n])\ndisplay(metrics_table)\nmetrics_table_path = FIGURE_DIR / \"acoustic_metrics_table.csv\"\nmetrics_table.to_csv(metrics_table_path, index=False)\nprint(\"Saved acoustic metrics table ->\", metrics_table_path)\n\ncm = confusion_matrix(test_true, calibrated_pred)\ncm_fig, ax = plt.subplots(figsize=(5, 4))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, ax=ax)\nax.set_xlabel(\"Predicted\")\nax.set_ylabel(\"True\")\nax.set_title(\"Confusion Matrix (Calibrated)\")\ncm_path = FIGURE_DIR / \"acoustic_confusion_matrix.png\"\ncm_fig.savefig(cm_path, dpi=300, bbox_inches=\"tight\")\nplt.show()\nprint(\"Saved acoustic confusion matrix ->\", cm_path)\n\nreport_text = classification_report(test_true, calibrated_pred, target_names=class_names, zero_division=0)\nprint(\"Calibrated classification report:\", report_text)\nreport_path = FIGURE_DIR / \"acoustic_classification_report.txt\"\nreport_path.write_text(report_text)\n\nroc_auc = roc_auc_score(\n    pd.get_dummies(test_true, drop_first=False).values,\n    test_prob,\n    average=\"macro\",\n    multi_class=\"ovr\"\n)\npr_auc = average_precision_score(\n    pd.get_dummies(test_true, drop_first=False).values,\n    test_prob,\n    average=\"macro\"\n)\nauc_path = FIGURE_DIR / \"acoustic_auc_summary.json\"\nauc_path.write_text(json.dumps({\"roc_auc\": float(roc_auc), \"pr_auc\": float(pr_auc)}, indent=2))\nprint(f\"ROC-AUC: {roc_auc:.4f} | PR-AUC: {pr_auc:.4f}\")\nprint(\"Saved acoustic AUC summary ->\", auc_path)\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:53:07.453028Z",
     "iopub.execute_input": "2025-12-28T13:53:07.453593Z",
     "iopub.status.idle": "2025-12-28T13:53:11.564688Z",
     "shell.execute_reply.started": "2025-12-28T13:53:07.453564Z",
     "shell.execute_reply": "2025-12-28T13:53:11.563999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001b[1m50/50\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\nCalibrated probability thresholds:\n  absent: 0.923\n  external: 0.950\n  present: 0.064\n\u001b[1m50/50\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "         Mode  Accuracy  Macro Precision  Macro Recall  Macro F1\n0      Argmax  0.928125         0.922011      0.951667  0.931063\n1  Calibrated  0.985000         0.983476      0.986250  0.984832",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mode</th>\n      <th>Accuracy</th>\n      <th>Macro Precision</th>\n      <th>Macro Recall</th>\n      <th>Macro F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Argmax</td>\n      <td>0.928125</td>\n      <td>0.922011</td>\n      <td>0.951667</td>\n      <td>0.931063</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Calibrated</td>\n      <td>0.985000</td>\n      <td>0.983476</td>\n      <td>0.986250</td>\n      <td>0.984832</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Saved acoustic metrics table -> /kaggle/working/figures/acoustic_metrics_table.csv\nSaved acoustic confusion matrix -> /kaggle/working/figures/acoustic_confusion_matrix.png\nCalibrated classification report:               precision    recall  f1-score   support\n\n      absent       0.97      0.99      0.98       400\n    external       0.99      0.99      0.99       400\n     present       0.99      0.98      0.99       800\n\n    accuracy                           0.98      1600\n   macro avg       0.98      0.99      0.98      1600\nweighted avg       0.99      0.98      0.99      1600\n\nROC-AUC: 0.9995 | PR-AUC: 0.9990\nSaved acoustic AUC summary -> /kaggle/working/figures/acoustic_auc_summary.json\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 198
  },
  {
   "id": "8a188280",
   "cell_type": "code",
   "source": "SR = 22050\n\ndef audio_to_spectrogram_image(audio_path: Path):\n    y, sr = librosa.load(audio_path, sr=SR)\n    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=512)\n    S_dB = librosa.power_to_db(S, ref=np.max)\n\n    fig = plt.figure(figsize=(2, 2), dpi=64)\n    librosa.display.specshow(S_dB, sr=sr, cmap=\"magma\")\n    plt.axis(\"off\")\n\n    buf = io.BytesIO()\n    plt.savefig(buf, format=\"png\", bbox_inches=\"tight\", pad_inches=0)\n    plt.close(fig)\n    buf.seek(0)\n\n    img = Image.open(buf).convert(\"RGB\").resize(IMG_SIZE)\n    img_array = np.array(img, dtype=np.float32) / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\ndef visualize_audio_prediction(audio_path: Path, model):\n    mel_input = audio_to_spectrogram_image(audio_path)\n    prediction = model.predict(mel_input)\n    class_names = list(test_gen.class_indices.keys())\n    pred_idx = int(np.argmax(prediction))\n    confidence = float(np.max(prediction))\n\n    y, sr = librosa.load(audio_path, sr=SR)\n    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n    mel_db = librosa.power_to_db(mel, ref=np.max)\n\n    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n    times = np.linspace(0, len(y)/sr, len(y))\n    axes[0,0].plot(times, y)\n    axes[0,0].set_title(\"Waveform\")\n\n    img = axes[0,1].imshow(mel_db, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n    axes[0,1].set_title(\"Mel Spectrogram\")\n    plt.colorbar(img, ax=axes[0,1], fraction=0.046, pad=0.04)\n\n    axes[1,0].bar(class_names, prediction[0], color=\"teal\")\n    axes[1,0].set_ylim(0, 1)\n    axes[1,0].set_title(\"Prediction Probabilities\")\n\n    axes[1,1].axis(\"off\")\n    axes[1,1].text(0.1, 0.5, f\"Predicted: {class_names[pred_idx]}\\nConfidence: {confidence:.2%}\", fontsize=14)\n\n    plt.tight_layout()\n    plt.show()\n\n    return {\"prediction\": class_names[pred_idx], \"confidence\": confidence}\n\nsample_audio = next(QUEEN_PRESENT_DIR.glob('*.wav'))\nvisualize_audio_prediction(sample_audio, model_for_eval)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:53:11.565960Z",
     "iopub.execute_input": "2025-12-28T13:53:11.566214Z",
     "iopub.status.idle": "2025-12-28T13:53:12.674253Z",
     "shell.execute_reply.started": "2025-12-28T13:53:11.566191Z",
     "shell.execute_reply": "2025-12-28T13:53:12.673635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
     "output_type": "stream"
    },
    {
     "execution_count": 199,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'prediction': 'present', 'confidence': 0.9530753493309021}"
     },
     "metadata": {}
    }
   ],
   "execution_count": 199
  },
  {
   "id": "86e1ed93",
   "cell_type": "markdown",
   "source": "## Makueni Climate-Informed Forecasting\n\nWe now project yield and occupancy directly from climate/NDVI sequences using W\u00fcrzburg-pretrained models.\n",
   "metadata": {}
  },
  {
   "id": "07adc57a-7308-41ca-bd31-e6b6396ddade",
   "cell_type": "markdown",
   "source": "## Makueni Apiary Intelligence Pipeline\n\nThe second half of BeeUnity focuses on environmental + hive telemetry analytics for Makueni County. Users can optionally pick a geometry via ipyleaflet; however, Kaggle\u2019s environment rarely ships the `jupyter-leaflet` extension, so we default to fixed coordinates while preserving the widget wiring for local notebooks. This section obeys Kaggle\u2019s outbound-network policy via the `ENABLE_REMOTE_CALLS` flag and falls back to cached CSV exports inside `content/main-data/`.\n",
   "metadata": {}
  },
  {
   "id": "6c6b0129",
   "cell_type": "code",
   "source": "DEFAULT_CENTER = (-1.8048, 37.62)\nENABLE_LEAFLET_WIDGETS = False  # Set True only if jupyter-leaflet widgets are installed.\n\ntry:\n    import ipywidgets as widgets\n    from ipyleaflet import Map, Marker, DrawControl, basemaps\nexcept Exception:\n    print(\"ipyleaflet not available; using default coordinates.\")\n    lat_widget = lon_widget = geometry_widget = None\nelse:\n    lat_widget = widgets.FloatText(value=DEFAULT_CENTER[0], description=\"Latitude\", step=0.0001)\n    lon_widget = widgets.FloatText(value=DEFAULT_CENTER[1], description=\"Longitude\", step=0.0001)\n    geometry_widget = widgets.Textarea(\n        value=\"\",\n        description=\"Geometry\",\n        placeholder=\"Draw a polygon/rectangle on the map.\",\n        layout=widgets.Layout(width=\"100%\", height=\"140px\"),\n        disabled=True,\n    )\n\n    leaflet_map = Map(center=DEFAULT_CENTER, zoom=8, basemap=basemaps.OpenStreetMap.Mapnik, scroll_wheel_zoom=True)\n    marker = Marker(location=DEFAULT_CENTER, draggable=True)\n    leaflet_map.add_layer(marker)\n\n    draw_control = DrawControl(\n        polygon={\"shapeOptions\": {\"color\": \"#2563eb\", \"weight\": 2, \"fillOpacity\": 0.2}},\n        rectangle={\"shapeOptions\": {\"color\": \"#f97316\", \"weight\": 2, \"fillOpacity\": 0.15}},\n        circle={},\n        circlemarker={},\n        polyline={},\n    )\n    leaflet_map.add_control(draw_control)\n\n    def _update_marker(change):\n        marker.location = (lat_widget.value, lon_widget.value)\n\n    lat_widget.observe(_update_marker, names=\"value\")\n    lon_widget.observe(_update_marker, names=\"value\")\n\n    display(widgets.HBox([lat_widget, lon_widget]))\n    display(geometry_widget)\n    display(leaflet_map)\n\nlat_widget_available = 'lat_widget' in globals() and lat_widget is not None\nlon_widget_available = 'lon_widget' in globals() and lon_widget is not None\n\nif lat_widget_available and lon_widget_available:\n    latitude = float(lat_widget.value)\n    longitude = float(lon_widget.value)\nelse:\n    latitude, longitude = DEFAULT_CENTER\n    print(\"Using default coordinates:\", DEFAULT_CENTER)\n\nselected_geometry_geojson = globals().get('selected_geometry_geojson')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:53:12.675121Z",
     "iopub.execute_input": "2025-12-28T13:53:12.675345Z",
     "iopub.status.idle": "2025-12-28T13:53:12.704295Z",
     "shell.execute_reply.started": "2025-12-28T13:53:12.675324Z",
     "shell.execute_reply": "2025-12-28T13:53:12.703449Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatText(value=-1.8048, description='Latitude', step=0.0001), FloatText(value=37.62, descripti\u2026",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7cfb5ef3effb4949a083c0f4de115239"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Textarea(value='', description='Geometry', disabled=True, layout=Layout(height='140px', width='100%'), placeho\u2026",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68a19b2076c3426e8e2b3318c3b7c632"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Map(center=[-1.8048, 37.62], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom\u2026",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9459c5d101824a7894b718bcecaf743a"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": 200
  },
  {
   "id": "86325237-f19b-4d81-9413-14c99b9be32a",
   "cell_type": "markdown",
   "source": "### Weather/NDVI Acquisition Strategy\n\nWe scope the modeling window via `normalize_date_string`, clamp requests to the latest Open-Meteo archive availability, and split long ranges into 365-day chunks. When `ENABLE_REMOTE_CALLS` is false (the Kaggle default), we load pre-exported weather and NDVI CSVs staged under `content/main-data/`. When high-trust compute is available, the notebook can re-fetch ERA5/Open-Meteo and MODIS NDVI slices, persisting them with consistent schemas so report figures remain reproducible.\n",
   "metadata": {}
  },
  {
   "id": "13f4ff43",
   "cell_type": "code",
   "source": "import ee\n\nraw_start_date = \"2008-01-01\"\nraw_end_date = \"2025-12-05\"\ntimezone = \"Africa/Nairobi\"\n\ndef normalize_date_string(d: str) -> dt.date:\n    parts = d.split(\"-\")\n    if len(parts) != 3:\n        raise ValueError(\"Date must be YYYY-MM-DD\")\n    y, m, day = [int(p) for p in parts]\n    m = max(1, min(12, m))\n    last_day = calendar.monthrange(y, m)[1]\n    day = max(1, min(last_day, day))\n    return dt.date(y, m, day)\n\nstart_date = normalize_date_string(raw_start_date)\nend_date = normalize_date_string(raw_end_date)\n\ntoday = dt.date.today()\napi_latest = dt.date(2025, 12, 20)\nmax_allowed = min(today, api_latest)\n\nif end_date > max_allowed:\n    print(f\"Clamping end_date {end_date} -> {max_allowed}\")\n    end_date = max_allowed\nif start_date > end_date:\n    raise ValueError(\"start_date must be before end_date\")\n\nprint(\"Using date range:\", start_date, \"\u2192\", end_date)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:53:12.705452Z",
     "iopub.execute_input": "2025-12-28T13:53:12.705763Z",
     "iopub.status.idle": "2025-12-28T13:53:12.718786Z",
     "shell.execute_reply.started": "2025-12-28T13:53:12.705728Z",
     "shell.execute_reply": "2025-12-28T13:53:12.718174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Using date range: 2008-01-01 \u2192 2025-12-05\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 201
  },
  {
   "id": "f651dd70",
   "cell_type": "code",
   "source": "ENABLE_REMOTE_CALLS = True  # Kaggle notebooks typically block outbound internet.\n\ndef split_date_range(start: dt.date, end: dt.date, max_days: int = 365):\n    chunks = []\n    current = start\n    while current <= end:\n        chunk_end = min(end, current + dt.timedelta(days=max_days - 1))\n        chunks.append((current, chunk_end))\n        current = chunk_end + dt.timedelta(days=1)\n    return chunks\n\ndef fetch_chunk(lat, lon, sdate: dt.date, edate: dt.date, timezone=\"Africa/Nairobi\", max_retries=3, backoff=2):\n    base = \"https://archive-api.open-meteo.com/v1/archive\"\n    daily_vars = \",\".join([\n        \"temperature_2m_max\",\n        \"temperature_2m_min\",\n        \"temperature_2m_mean\",\n        \"precipitation_sum\",\n        \"relative_humidity_2m_mean\",\n        \"wind_speed_10m_max\",\n        \"cloudcover_mean\"\n    ])\n    params = {\n        \"latitude\": lat,\n        \"longitude\": lon,\n        \"start_date\": sdate.strftime(\"%Y-%m-%d\"),\n        \"end_date\": edate.strftime(\"%Y-%m-%d\"),\n        \"daily\": daily_vars,\n        \"timezone\": timezone\n    }\n    for attempt in range(1, max_retries + 1):\n        try:\n            resp = requests.get(base, params=params, timeout=30)\n            resp.raise_for_status()\n            payload = resp.json()\n            if \"daily\" not in payload or \"time\" not in payload[\"daily\"]:\n                raise ValueError(\"API response missing expected fields.\")\n            return payload\n        except Exception as exc:\n            print(f\"Attempt {attempt} failed: {exc}\")\n            if attempt == max_retries:\n                raise\n            time.sleep(backoff ** attempt)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:53:12.720278Z",
     "iopub.execute_input": "2025-12-28T13:53:12.720631Z",
     "iopub.status.idle": "2025-12-28T13:53:12.732329Z",
     "shell.execute_reply.started": "2025-12-28T13:53:12.720586Z",
     "shell.execute_reply": "2025-12-28T13:53:12.731604Z"
    }
   },
   "outputs": [],
   "execution_count": 202
  },
  {
   "id": "b8b45a4d",
   "cell_type": "code",
   "source": "weather_csv = MAIN_DATA_DIR / \"makueni_weather_2008_2025.csv\"\nchunks = split_date_range(start_date, end_date, max_days=365)\n\nif ENABLE_REMOTE_CALLS:\n    dfs = []\n    for s, e in chunks:\n        payload = fetch_chunk(latitude, longitude, s, e, timezone=timezone)\n        daily = payload[\"daily\"]\n        df_chunk = pd.DataFrame({\n            \"date\": daily[\"time\"],\n            \"temp_max\": daily.get(\"temperature_2m_max\"),\n            \"temp_min\": daily.get(\"temperature_2m_min\"),\n            \"temp_mean\": daily.get(\"temperature_2m_mean\"),\n            \"humidity_mean\": daily.get(\"relative_humidity_2m_mean\"),\n            \"rainfall_mm\": daily.get(\"precipitation_sum\"),\n            \"wind_speed_max\": daily.get(\"wind_speed_10m_max\"),\n            \"cloud_cover_percent\": daily.get(\"cloudcover_mean\"),\n        })\n        dfs.append(df_chunk)\n        time.sleep(1)\n    weather_df = pd.concat(dfs, ignore_index=True)\n    weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n    weather_df.sort_values(\"date\", inplace=True)\n    weather_df.to_csv(weather_csv, index=False)\n    print(\"Fetched and saved weather CSV to\", weather_csv)\nelse:\n    if weather_csv.exists():\n        weather_df = pd.read_csv(weather_csv, parse_dates=[\"date\"])\n        print(f\"Loaded cached weather data from {weather_csv}\")\n    else:\n        raise FileNotFoundError(f\"{weather_csv} not found; enable ENABLE_REMOTE_CALLS to regenerate.\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:53:12.733175Z",
     "iopub.execute_input": "2025-12-28T13:53:12.733421Z",
     "iopub.status.idle": "2025-12-28T13:53:39.910364Z",
     "shell.execute_reply.started": "2025-12-28T13:53:12.733396Z",
     "shell.execute_reply": "2025-12-28T13:53:39.909563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Fetched and saved weather CSV to /kaggle/working/content/main-data/makueni_weather_2008_2025.csv\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 203
  },
  {
   "id": "0bd89f0c",
   "cell_type": "code",
   "source": "ENABLE_REMOTE_CALLS = False  # Kaggle notebooks typically block outbound internet.\nndvi_csv = \"/kaggle/input/makueni-ndvi-2008-2025-csv/makueni_ndvi_2008_2025.csv\"\n\nif ENABLE_REMOTE_CALLS:\n    try:\n        ee.Initialize()\n    except Exception:\n        print(\"Authenticating with Earth Engine...\")\n        ee.Authenticate()\n        ee.Initialize()\n\n    point = ee.Geometry.Point([longitude, latitude])\n    modis = ee.ImageCollection(\"MODIS/061/MOD13Q1\").select(\"NDVI\").filterDate(start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")).filterBounds(point)\n\n    def extract_ndvi(image):\n        mean = image.reduceRegion(reducer=ee.Reducer.mean(), geometry=point, scale=250).get(\"NDVI\")\n        date = image.date().format(\"YYYY-MM-dd\")\n        return ee.Feature(None, {\"date\": date, \"ndvi_mean\": mean})\n\n    ndvi_fc = modis.map(extract_ndvi).getInfo()\n    records = [f[\"properties\"] for f in ndvi_fc[\"features\"]]\n    ndvi_df = pd.DataFrame(records)\n    ndvi_df[\"date\"] = pd.to_datetime(ndvi_df[\"date\"])\n    ndvi_df[\"ndvi_mean\"] = ndvi_df[\"ndvi_mean\"].astype(float) / 10000\n    ndvi_df.to_csv(ndvi_csv, index=False)\n    print(\"Fetched NDVI and saved to\", ndvi_csv)\nelse:\n    if ndvi_csv:\n        ndvi_df = pd.read_csv(ndvi_csv, parse_dates=[\"date\"])\n        print(f\"Loaded cached NDVI data from {ndvi_csv}\")\n    else:\n        raise FileNotFoundError(f\"{ndvi_csv} not found; enable ENABLE_REMOTE_CALLS to regenerate.\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:53:39.911366Z",
     "iopub.execute_input": "2025-12-28T13:53:39.911938Z",
     "iopub.status.idle": "2025-12-28T13:53:39.928461Z",
     "shell.execute_reply.started": "2025-12-28T13:53:39.911915Z",
     "shell.execute_reply": "2025-12-28T13:53:39.927919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Loaded cached NDVI data from /kaggle/input/makueni-ndvi-2008-2025-csv/makueni_ndvi_2008_2025.csv\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 204
  },
  {
   "id": "f84d3908",
   "cell_type": "code",
   "source": "merged = weather_full.copy()\nmerged_path = MAIN_DATA_DIR / \"makueni_climate_features.csv\"\nmerged.to_csv(merged_path, index=False)\nprint(\"Saved climate feature table ->\", merged_path)\nmerged.head()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:53:39.929192Z",
     "iopub.execute_input": "2025-12-28T13:53:39.929743Z",
     "iopub.status.idle": "2025-12-28T13:53:39.972556Z",
     "shell.execute_reply.started": "2025-12-28T13:53:39.929722Z",
     "shell.execute_reply": "2025-12-28T13:53:39.971875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Saved climate feature table -> /kaggle/working/content/main-data/makueni_climate_features.csv\n",
     "output_type": "stream"
    },
    {
     "execution_count": 205,
     "output_type": "execute_result",
     "data": {
      "text/plain": "        date  temp_max  temp_min  temp_mean  humidity_mean  rainfall_mm  \\\n0 2008-01-01      24.9      16.4       20.3             74          1.2   \n1 2008-01-02      25.8      14.1       20.2             71          0.8   \n2 2008-01-03      27.2      15.2       21.3             65          0.0   \n3 2008-01-04      27.6      15.4       22.2             63          0.1   \n4 2008-01-05      27.3      15.2       21.0             75          2.9   \n\n   wind_speed_max  cloud_cover_percent  ndvi_mean  \n0            15.1                   53     0.6805  \n1            14.3                   19        NaN  \n2            12.8                   11        NaN  \n3            12.2                   26        NaN  \n4            13.1                   58        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>temp_max</th>\n      <th>temp_min</th>\n      <th>temp_mean</th>\n      <th>humidity_mean</th>\n      <th>rainfall_mm</th>\n      <th>wind_speed_max</th>\n      <th>cloud_cover_percent</th>\n      <th>ndvi_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-01-01</td>\n      <td>24.9</td>\n      <td>16.4</td>\n      <td>20.3</td>\n      <td>74</td>\n      <td>1.2</td>\n      <td>15.1</td>\n      <td>53</td>\n      <td>0.6805</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-01-02</td>\n      <td>25.8</td>\n      <td>14.1</td>\n      <td>20.2</td>\n      <td>71</td>\n      <td>0.8</td>\n      <td>14.3</td>\n      <td>19</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-01-03</td>\n      <td>27.2</td>\n      <td>15.2</td>\n      <td>21.3</td>\n      <td>65</td>\n      <td>0.0</td>\n      <td>12.8</td>\n      <td>11</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-01-04</td>\n      <td>27.6</td>\n      <td>15.4</td>\n      <td>22.2</td>\n      <td>63</td>\n      <td>0.1</td>\n      <td>12.2</td>\n      <td>26</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-01-05</td>\n      <td>27.3</td>\n      <td>15.2</td>\n      <td>21.0</td>\n      <td>75</td>\n      <td>2.9</td>\n      <td>13.1</td>\n      <td>58</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 205
  },
  {
   "id": "a59ea8ad-f1eb-4f9f-8c1c-65a3ae8b9e2c",
   "cell_type": "code",
   "source": "weather_full = df_merged.copy()\nprint('Weather+NDVI rows:', weather_full.shape)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:53:39.973413Z",
     "iopub.execute_input": "2025-12-28T13:53:39.973747Z",
     "iopub.status.idle": "2025-12-28T13:53:39.978146Z",
     "shell.execute_reply.started": "2025-12-28T13:53:39.973726Z",
     "shell.execute_reply": "2025-12-28T13:53:39.977414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Weather+NDVI rows: (6549, 9)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 206
  },
  {
   "id": "27121437",
   "cell_type": "code",
   "source": "df_month = df_merged.set_index(\"date\").resample(\"ME\").agg({\n    \"rainfall_mm\": \"sum\",\n    \"temp_mean\": \"mean\",\n    \"humidity_mean\": \"mean\",\n    \"ndvi_mean\": \"mean\"\n}).reset_index()\n\nfig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\naxes[0].plot(df_month[\"date\"], df_month[\"rainfall_mm\"], marker=\"o\")\naxes[0].set_title(\"Monthly Rainfall (mm)\")\n\naxes[1].plot(df_month[\"date\"], df_month[\"temp_mean\"], marker=\"o\", color=\"tomato\")\naxes[1].set_title(\"Monthly Mean Temperature (\u00b0C)\")\n\naxes[2].plot(df_month[\"date\"], df_month[\"ndvi_mean\"], marker=\"o\", color=\"green\")\naxes[2].set_title(\"Monthly NDVI Mean\")\n\nfor ax in axes:\n    ax.grid(True, alpha=0.3)\n    ax.set_ylabel(\"Value\")\n\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:53:39.979012Z",
     "iopub.execute_input": "2025-12-28T13:53:39.979254Z",
     "iopub.status.idle": "2025-12-28T13:53:40.240005Z",
     "shell.execute_reply.started": "2025-12-28T13:53:39.979235Z",
     "shell.execute_reply": "2025-12-28T13:53:40.239262Z"
    }
   },
   "outputs": [],
   "execution_count": 207
  },
  {
   "id": "70539f43-e972-4695-82b4-a1e06a65162d",
   "cell_type": "markdown",
   "source": "### Climate Feature Extraction\n\nDerive clean hourly climate+NDVI features ready for inference.\n",
   "metadata": {}
  },
  {
   "id": "c853922d-75e9-471f-8d84-101dd83f9bb8",
   "cell_type": "code",
   "source": "climate_features = df_merged[['date','rainfall_mm','temp_mean','humidity_mean','ndvi_mean']].copy()\nclimate_features = climate_features.sort_values('date').set_index('date')\nclimate_features = climate_features.interpolate(limit_direction='both')\nproxy_features = pd.DataFrame(index=climate_features.index)\nproxy_features['weight'] = climate_features['rainfall_mm']\nproxy_features['temperature'] = climate_features['temp_mean']\nproxy_features['humidity'] = climate_features['humidity_mean']\nproxy_features['flow'] = climate_features['ndvi_mean']\nproxy_features['weight_delta_24h'] = proxy_features['weight'].diff(24).fillna(0)\nprint('Climate feature frame:', climate_features.shape)\nprint('Proxy feature frame:', proxy_features.shape)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T13:53:40.240947Z",
     "iopub.execute_input": "2025-12-28T13:53:40.241241Z",
     "iopub.status.idle": "2025-12-28T13:53:40.254898Z",
     "shell.execute_reply.started": "2025-12-28T13:53:40.241212Z",
     "shell.execute_reply": "2025-12-28T13:53:40.254266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Climate feature frame: (6549, 4)\nProxy feature frame: (6549, 5)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 208
  },
  {
   "id": "488e7157-d47c-440d-92d6-6ac6836aebb7",
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device\", device)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:05:46.159243Z",
     "iopub.execute_input": "2025-12-28T14:05:46.160317Z",
     "iopub.status.idle": "2025-12-28T14:05:46.164931Z",
     "shell.execute_reply.started": "2025-12-28T14:05:46.160280Z",
     "shell.execute_reply": "2025-12-28T14:05:46.164265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Using device cuda\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 210
  },
  {
   "id": "fdf170ba-8cf9-44c0-9d1c-59a8a3fbdcff",
   "cell_type": "markdown",
   "source": "### W\u00fcrzburg Dataset Staging\n\nOn Kaggle, stage the W\u00fcrzburg datasets just like the acoustic source: attach a dataset named `wurzb-hive-telemetry` (or similar) under `/kaggle/input`, then copy it into `content/wurzburg/` so the pretraining block can load from both local runs and Kaggle sessions.\n",
   "metadata": {}
  },
  {
   "id": "89eddb70-2b84-4d27-bbed-ec0fdd56ca76",
   "cell_type": "code",
   "source": "WURZBURG_INPUT_ROOT = Path('/kaggle/input')\nWURZBURG_TARGET = CONTENT_ROOT / 'bee-hive-metrics'\nif WURZBURG_INPUT_ROOT.exists():\n    candidates = [p for p in WURZBURG_INPUT_ROOT.iterdir() if 'bee-hive-metrics' in p.name.lower() or 'bee-hive-metrics' in p.name.lower()]\n    if candidates:\n        source = candidates[0]\n        WURZBURG_TARGET.mkdir(parents=True, exist_ok=True)\n        for csv_path in source.glob('*.csv'):\n            target_path = WURZBURG_TARGET / csv_path.name\n            if not target_path.exists():\n                shutil.copy(csv_path, target_path)\n        print(f\"Staged W\u00fcrzburg telemetry from {source} -> {WURZBURG_TARGET}\")\n    else:\n        print('No W\u00fcrzburg dataset attached under /kaggle/input; using existing content/wurzburg if present.')\nelse:\n    WURZBURG_TARGET.mkdir(parents=True, exist_ok=True)\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:05:46.174227Z",
     "iopub.execute_input": "2025-12-28T14:05:46.174659Z",
     "iopub.status.idle": "2025-12-28T14:05:46.220319Z",
     "shell.execute_reply.started": "2025-12-28T14:05:46.174627Z",
     "shell.execute_reply": "2025-12-28T14:05:46.219804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Staged W\u00fcrzburg telemetry from /kaggle/input/bee-hive-metrics -> /kaggle/working/content/bee-hive-metrics\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 211
  },
  {
   "id": "fc6876c4-1d4c-4aae-92ba-5b749bf787e0",
   "cell_type": "markdown",
   "source": "### W\u00fcrzburg/Schwartau Hive Telemetry Pretraining\n\nTo ground our synthetic Makueni logs in real telemetry, we ingest the W\u00fcrzburg/Schwartau sensor datasets (`content/wurzburg/*`). These CSVs provide minute-level hive weight, entrance flow, and local temperature/humidity measurements from 2017\u20132019. We aggregate them into hourly/daily features, derive proxy yield/ stress labels via rolling weight deltas, and use them to pretrain the tabular and sequence models before adapting to Makueni's climate distribution.\n",
   "metadata": {}
  },
  {
   "id": "af2f8cae-9c2d-46db-9936-10453d6b3b4c",
   "cell_type": "code",
   "source": "from pathlib import Path\nimport pandas as pd\n\nWURZBURG_DIR = CONTENT_ROOT / 'bee-hive-metrics'\nif not WURZBURG_DIR.exists():\n    raise FileNotFoundError(f\"Missing W\u00fcrzburg data at {WURZBURG_DIR}\")\n\n# Helper loader keeps timestamps sorted for consistent resampling\ndef load_sensor(name):\n    path = WURZBURG_DIR / name\n    df = pd.read_csv(path, parse_dates=['timestamp'])\n    df = df.sort_values('timestamp').set_index('timestamp')\n    return df\n\nweight_df = load_sensor('weight_wurzburg.csv')\ntemp_df = load_sensor('temperature_wurzburg.csv')\nhumidity_df = load_sensor('humidity_wurzburg.csv')\nflow_df = load_sensor('flow_wurzburg.csv')\n\nprint('Loaded sensors:', {\n    'weight': weight_df.shape,\n    'temperature': temp_df.shape,\n    'humidity': humidity_df.shape,\n    'flow': flow_df.shape\n})\n\n# Resample to hourly means and align\nhourly = pd.DataFrame({\n    'weight': weight_df['weight'].resample('1H').mean(),\n    'temperature': temp_df['temperature'].resample('1H').mean(),\n    'humidity': humidity_df['humidity'].resample('1H').mean(),\n    'flow': flow_df['flow'].resample('1H').mean(),\n})\nhourly = hourly.interpolate(limit_direction='both')\n\n# Derive proxy labels: positive weight change over 24h indicates nectar intake (yield), negative sustained drop indicates stress/harvest\nhourly['weight_delta_24h'] = hourly['weight'].diff(24)\nhourly['yield_positive'] = (hourly['weight_delta_24h'] > 0.5).astype(int)\nhourly['stress_event'] = (hourly['weight_delta_24h'] < -1.0).astype(int)\n\nhourly.reset_index(inplace=True)\nprint('Hourly feature set:', hourly.shape)\nhourly.head()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:05:46.221507Z",
     "iopub.execute_input": "2025-12-28T14:05:46.221747Z",
     "iopub.status.idle": "2025-12-28T14:05:50.006190Z",
     "shell.execute_reply.started": "2025-12-28T14:05:46.221727Z",
     "shell.execute_reply": "2025-12-28T14:05:50.005490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Loaded sensors: {'weight': (1035861, 1), 'temperature': (958831, 1), 'humidity': (20845, 1), 'flow': (2071720, 1)}\nHourly feature set: (20865, 8)\n",
     "output_type": "stream"
    },
    {
     "execution_count": 212,
     "output_type": "execute_result",
     "data": {
      "text/plain": "            timestamp     weight  temperature   humidity  flow  \\\n0 2017-01-01 05:00:00  52.695098    -0.327590  92.406667   0.0   \n1 2017-01-01 06:00:00  52.685200    -0.409250  92.270000   0.0   \n2 2017-01-01 07:00:00  52.688667    -0.668364  92.575000   0.0   \n3 2017-01-01 08:00:00  52.674267    -0.966858  92.840000   0.0   \n4 2017-01-01 09:00:00  52.595320    -1.623189  93.640000   0.0   \n\n   weight_delta_24h  yield_positive  stress_event  \n0               NaN               0             0  \n1               NaN               0             0  \n2               NaN               0             0  \n3               NaN               0             0  \n4               NaN               0             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>weight</th>\n      <th>temperature</th>\n      <th>humidity</th>\n      <th>flow</th>\n      <th>weight_delta_24h</th>\n      <th>yield_positive</th>\n      <th>stress_event</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-01-01 05:00:00</td>\n      <td>52.695098</td>\n      <td>-0.327590</td>\n      <td>92.406667</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-01-01 06:00:00</td>\n      <td>52.685200</td>\n      <td>-0.409250</td>\n      <td>92.270000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-01-01 07:00:00</td>\n      <td>52.688667</td>\n      <td>-0.668364</td>\n      <td>92.575000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-01-01 08:00:00</td>\n      <td>52.674267</td>\n      <td>-0.966858</td>\n      <td>92.840000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-01-01 09:00:00</td>\n      <td>52.595320</td>\n      <td>-1.623189</td>\n      <td>93.640000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 212
  },
  {
   "id": "32fe6dbf-e98f-4f4e-b1c9-93b7e3a48835",
   "cell_type": "markdown",
   "source": "#### W\u00fcrzburg Tabular Pretraining\n\nWe treat the hourly temperature/humidity/flow/weight statistics plus rolling deltas as features and pretrain a HistGradientBoostingClassifier to predict the proxy `yield_positive` label. This serves as an initialization for the Makueni model (via warm-start) and quantifies how real telemetry behaves before domain adaptation.\n",
   "metadata": {}
  },
  {
   "id": "4f85e72a-759a-4abf-8bfa-caf9283db893",
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score\n\nfeature_cols_w = ['weight', 'temperature', 'humidity', 'flow', 'weight_delta_24h']\nX_w = hourly[feature_cols_w].fillna(method='ffill').fillna(method='bfill')\ny_w = hourly['yield_positive']\n\nX_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X_w, y_w, test_size=0.2, random_state=42, stratify=y_w)\n\nhgb_w = HistGradientBoostingClassifier(max_depth=6, learning_rate=0.08, max_iter=300, class_weight='balanced')\nhgb_w.fit(X_train_w, y_train_w)\n\ny_pred_w = hgb_w.predict(X_test_w)\ny_prob_w = hgb_w.predict_proba(X_test_w)[:, 1]\n\nprint(classification_report(y_test_w, y_pred_w))\nprint('ROC-AUC:', roc_auc_score(y_test_w, y_prob_w))\n\n# Persist for transfer learning\nWURZBURG_MODEL_PATH = MAIN_DATA_DIR / 'wurzb_hgb_yield.pkl'\npd.to_pickle(hgb_w, WURZBURG_MODEL_PATH)\nprint('Saved W\u00fcrzburg HGB model ->', WURZBURG_MODEL_PATH)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:05:50.007200Z",
     "iopub.execute_input": "2025-12-28T14:05:50.007486Z",
     "iopub.status.idle": "2025-12-28T14:05:50.264143Z",
     "shell.execute_reply.started": "2025-12-28T14:05:50.007460Z",
     "shell.execute_reply": "2025-12-28T14:05:50.263433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      3940\n           1       0.97      0.99      0.98       233\n\n    accuracy                           1.00      4173\n   macro avg       0.99      0.99      0.99      4173\nweighted avg       1.00      1.00      1.00      4173\n\nROC-AUC: 0.9999635084202958\nSaved W\u00fcrzburg HGB model -> /kaggle/working/content/main-data/wurzb_hgb_yield.pkl\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 213
  },
  {
   "id": "7cd973b8-8a6c-4c54-afde-5cc428f2566b",
   "cell_type": "markdown",
   "source": "### W\u00fcrzburg Tabular Inference\n\nApply pretrained HGB to climate features for yield probability curves.\n",
   "metadata": {}
  },
  {
   "id": "1373c8bd-1431-4f82-96d1-399161705ba2",
   "cell_type": "code",
   "source": "WURZBURG_MODEL_PATH = MAIN_DATA_DIR / 'wurzb_hgb_yield.pkl'\nif not WURZBURG_MODEL_PATH.exists():\n    raise FileNotFoundError('Pretrained W\u00fcrzburg HGB missing')\nhgb_w = pd.read_pickle(WURZBURG_MODEL_PATH)\nclimate_X = proxy_features[['weight','temperature','humidity','flow','weight_delta_24h']]\nyield_probs = hgb_w.predict_proba(climate_X)[:,1]\nproxy_features['predicted_yield_prob'] = yield_probs\nyield_forecast_path = MAIN_DATA_DIR / 'makueni_climate_yield_forecast.csv'\nproxy_features[['predicted_yield_prob']].to_csv(yield_forecast_path)\nprint('Saved climate yield forecast ->', yield_forecast_path)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:05:50.265582Z",
     "iopub.execute_input": "2025-12-28T14:05:50.265900Z",
     "iopub.status.idle": "2025-12-28T14:05:50.314342Z",
     "shell.execute_reply.started": "2025-12-28T14:05:50.265880Z",
     "shell.execute_reply": "2025-12-28T14:05:50.313827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Saved climate yield forecast -> /kaggle/working/content/main-data/makueni_climate_yield_forecast.csv\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 214
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "yield_forecast = pd.read_csv(yield_forecast_path, parse_dates=['date'], index_col='date') if 'date' in pd.read_csv(yield_forecast_path, nrows=1).columns else pd.read_csv(yield_forecast_path)\n",
    "yield_fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.plot(yield_forecast.index if 'date' in yield_forecast.columns else yield_forecast.index, yield_forecast['predicted_yield_prob'], label='Yield probability')\n",
    "ax.set_title('Climate-informed Yield Forecast')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.legend()\n",
    "yield_plot_path = FIGURE_DIR / 'climate_yield_forecast.png'\n",
    "yield_fig.savefig(yield_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "yield_metrics_path = FIGURE_DIR / 'climate_yield_metrics.json'\n",
    "yield_metrics_path.write_text(json.dumps({\"mean_probability\": float(yield_forecast['predicted_yield_prob'].mean())}, indent=2))\n",
    "print('Saved climate yield artifacts ->', yield_plot_path, yield_metrics_path)\n"
   ]
  },
  {
   "id": "900f2fba-0dab-4136-b504-40cdfc80c4d5",
   "cell_type": "markdown",
   "source": "#### Transfer to Makueni Tabular Model\n\nWe reuse the W\u00fcrzburg-trained gradient boosting model as initialization for the Makueni stress prediction: load `wurzb_hgb_yield.pkl`, continue training on the Makueni feature matrix, and compare against training-from-scratch baselines. This simple warm-start helps incorporate learned environmental response patterns despite limited local telemetry.\n",
   "metadata": {}
  },
  {
   "id": "541d34ec-5036-4a7c-9915-777541c8a68f",
   "cell_type": "markdown",
   "source": "#### W\u00fcrzburg Sequence Pretraining\n\nWe also slice the W\u00fcrzburg hourly features into temporal windows to pretrain the PyTorch sequence backbone. This yields a model familiar with real hive dynamics before fine-tuning on Makueni's synthetic/log-based sequences.\n",
   "metadata": {}
  },
  {
   "id": "107d5add-5eee-4ab3-8ccb-7bff8b68266d",
   "cell_type": "code",
   "source": "class HiveCNNBaseline(nn.Module):\n    def __init__(self, input_channels):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv1d(input_channels, 64, kernel_size=3, padding=1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.MaxPool1d(2),\n            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool1d(1)\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(64, 1)\n        )\n    def forward(self, x):\n        x = x.transpose(1, 2)\n        x = self.features(x)\n        x = self.classifier(x)\n        return x.squeeze(-1)\nclass HiveCNNRecurrent(nn.Module):\n    def __init__(self, input_channels):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv1d(input_channels, 64, kernel_size=3, padding=1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.MaxPool1d(2),\n            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm1d(128),\n            nn.ReLU()\n        )\n        self.layer_norm = nn.LayerNorm(128)\n        self.gru = nn.GRU(128, 64, batch_first=True, bidirectional=True)\n        self.classifier = nn.Sequential(\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(64, 1)\n        )\n    def forward(self, x):\n        x = x.transpose(1, 2)\n        x = self.conv(x)\n        x = x.transpose(1, 2)\n        x = self.layer_norm(x)\n        _, h_n = self.gru(x)\n        h_n = h_n.transpose(0, 1).reshape(x.size(0), -1)\n        x = self.classifier(h_n)\n        return x.squeeze(-1)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:05:50.315110Z",
     "iopub.execute_input": "2025-12-28T14:05:50.315425Z",
     "iopub.status.idle": "2025-12-28T14:05:50.324886Z",
     "shell.execute_reply.started": "2025-12-28T14:05:50.315390Z",
     "shell.execute_reply": "2025-12-28T14:05:50.324256Z"
    }
   },
   "outputs": [],
   "execution_count": 215
  },
  {
   "id": "5a2a89e8-a62d-4a36-9234-93d5d8292741",
   "cell_type": "code",
   "source": "# Slice W\u00fcrzburg hourly features into fixed windows for sequence pretraining\nWURZ_WINDOW = 24\nsequence_cols_w = ['weight', 'temperature', 'humidity', 'flow', 'weight_delta_24h']\nwurz_sequences = []\nwurz_labels = []\nfor i in range(WURZ_WINDOW, len(hourly)):\n    window = hourly.iloc[i-WURZ_WINDOW:i][sequence_cols_w].values\n    label = hourly.iloc[i]['yield_positive']\n    if not np.any(np.isnan(window)):\n        wurz_sequences.append(window)\n        wurz_labels.append(label)\n\nwurz_sequences = np.array(wurz_sequences, dtype=np.float32)\nwurz_labels = np.array(wurz_labels, dtype=np.float32)\nprint('W\u00fcrzburg sequences:', wurz_sequences.shape)\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:05:50.325789Z",
     "iopub.execute_input": "2025-12-28T14:05:50.326066Z",
     "iopub.status.idle": "2025-12-28T14:06:01.879036Z",
     "shell.execute_reply.started": "2025-12-28T14:05:50.326039Z",
     "shell.execute_reply": "2025-12-28T14:06:01.878368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "W\u00fcrzburg sequences: (20817, 24, 5)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 216
  },
  {
   "id": "520dc390-14ea-4a32-a804-200158026e7b",
   "cell_type": "markdown",
   "source": "##### Pretraining the Temporal CNN\n\nWe reuse the `SEQUENCE_MODEL_VARIANT='cnn'` architecture to pretrain on the W\u00fcrzburg sequences, save the weights, and later load them as initialization for the Makueni sequence training.\n",
   "metadata": {}
  },
  {
   "id": "76106549-72c3-43c3-b54b-51405eb37996",
   "cell_type": "code",
   "source": "from torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\n# Lightweight dataset wrapper so PyTorch loaders can stream W\u00fcrzburg sequences\nclass WurzburgDataset(Dataset):\n    def __init__(self, sequences, labels):\n        self.X = torch.tensor(sequences, dtype=torch.float32)\n        self.y = torch.tensor(labels, dtype=torch.float32)\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\nX_train_wseq, X_val_wseq, y_train_wseq, y_val_wseq = train_test_split(\n    wurz_sequences, wurz_labels, test_size=0.2, random_state=42, stratify=wurz_labels)\n\nw_train_ds = WurzburgDataset(X_train_wseq, y_train_wseq)\nw_val_ds = WurzburgDataset(X_val_wseq, y_val_wseq)\nw_train_loader = DataLoader(w_train_ds, batch_size=128, shuffle=True)\nw_val_loader = DataLoader(w_val_ds, batch_size=128, shuffle=False)\n\npretrain_model = HiveCNNBaseline(input_channels=len(sequence_cols_w)).to(device)\npretrain_optimizer = torch.optim.Adam(pretrain_model.parameters(), lr=1e-3, weight_decay=1e-4)\npretrain_criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor((len(y_train_wseq)-y_train_wseq.sum())/max(y_train_wseq.sum(),1), device=device))\n\ndef run_pretrain_epoch(loader, train=True):\n    pretrain_model.train(train)\n    total_loss=0\n    preds=[]\n    targets=[]\n    for batch_X, batch_y in loader:\n        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n        pretrain_optimizer.zero_grad()\n        with torch.set_grad_enabled(train):\n            logits = pretrain_model(batch_X)\n            loss = pretrain_criterion(logits, batch_y)\n            if train:\n                loss.backward()\n                pretrain_optimizer.step()\n        total_loss += loss.item()*batch_X.size(0)\n        preds.append(torch.sigmoid(logits).detach().cpu().numpy())\n        targets.append(batch_y.detach().cpu().numpy())\n    preds = np.concatenate(preds)\n    targets = np.concatenate(targets)\n    return total_loss/len(loader.dataset), roc_auc_score(targets, preds)\n\n# Train for a few epochs and persist the best validation AUC weights\nprint('Pretraining sequence model on W\u00fcrzburg data...')\nbest_auc = 0\nfor epoch in range(20):\n    train_loss, train_auc = run_pretrain_epoch(w_train_loader, True)\n    val_loss, val_auc = run_pretrain_epoch(w_val_loader, False)\n    print(f'Epoch {epoch+1:02d}: train_loss={train_loss:.4f} AUC={train_auc:.3f} | val_loss={val_loss:.4f} AUC={val_auc:.3f}')\n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(pretrain_model.state_dict(), MAIN_DATA_DIR / 'wurzburg_sequence_pretrain.pt')\nprint('Saved W\u00fcrzburg sequence weights ->', MAIN_DATA_DIR / 'wurzburg_sequence_pretrain.pt')\n\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:06:39.176123Z",
     "iopub.execute_input": "2025-12-28T14:06:39.176665Z",
     "iopub.status.idle": "2025-12-28T14:06:51.205171Z",
     "shell.execute_reply.started": "2025-12-28T14:06:39.176636Z",
     "shell.execute_reply": "2025-12-28T14:06:51.204337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Pretraining sequence model on W\u00fcrzburg data...\nEpoch 01: train_loss=0.7007 AUC=0.918 | val_loss=0.4948 AUC=0.950\nEpoch 02: train_loss=0.4480 AUC=0.961 | val_loss=0.4035 AUC=0.967\nEpoch 03: train_loss=0.4166 AUC=0.965 | val_loss=0.5110 AUC=0.961\nEpoch 04: train_loss=0.3792 AUC=0.972 | val_loss=0.6019 AUC=0.965\nEpoch 05: train_loss=0.3501 AUC=0.976 | val_loss=0.6150 AUC=0.964\nEpoch 06: train_loss=0.3206 AUC=0.980 | val_loss=0.6039 AUC=0.950\nEpoch 07: train_loss=0.3092 AUC=0.981 | val_loss=0.3395 AUC=0.978\nEpoch 08: train_loss=0.3515 AUC=0.977 | val_loss=0.3536 AUC=0.975\nEpoch 09: train_loss=0.2843 AUC=0.984 | val_loss=0.3307 AUC=0.980\nEpoch 10: train_loss=0.2769 AUC=0.985 | val_loss=0.4163 AUC=0.975\nEpoch 11: train_loss=0.3747 AUC=0.974 | val_loss=0.4098 AUC=0.978\nEpoch 12: train_loss=0.3247 AUC=0.980 | val_loss=0.3059 AUC=0.984\nEpoch 13: train_loss=0.2544 AUC=0.988 | val_loss=0.2987 AUC=0.984\nEpoch 14: train_loss=0.2225 AUC=0.990 | val_loss=0.2558 AUC=0.984\nEpoch 15: train_loss=0.2207 AUC=0.990 | val_loss=0.2464 AUC=0.986\nEpoch 16: train_loss=0.2123 AUC=0.991 | val_loss=0.2670 AUC=0.987\nEpoch 17: train_loss=0.2201 AUC=0.991 | val_loss=0.2538 AUC=0.989\nEpoch 18: train_loss=0.1930 AUC=0.993 | val_loss=0.2626 AUC=0.988\nEpoch 19: train_loss=0.1610 AUC=0.994 | val_loss=0.2595 AUC=0.987\nEpoch 20: train_loss=0.1915 AUC=0.993 | val_loss=0.5194 AUC=0.988\nSaved W\u00fcrzburg sequence weights -> /kaggle/working/content/main-data/wurzburg_sequence_pretrain.pt\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 219
  },
  {
   "id": "968489c6-85a9-42ad-8179-daf48df87790",
   "cell_type": "markdown",
   "source": "### W\u00fcrzburg CNN Inference\n\nConvert climate sequences to windows and run the pretrained CNN to estimate occupancy risk.\n",
   "metadata": {}
  },
  {
   "id": "bd039058-154c-4847-b612-0793d5837d7a",
   "cell_type": "code",
   "source": "WINDOW = 24  # match W\u00fcrzburg pretraining window\nclimate_sequences = []\nfor i in range(WINDOW, len(proxy_features)):\n    window = proxy_features.iloc[i-WINDOW:i][['weight','temperature','humidity','flow','weight_delta_24h']].values\n    if not np.any(np.isnan(window)):\n        climate_sequences.append(window)\nclimate_sequences = np.array(climate_sequences, dtype=np.float32)\nprint('Climate sequences:', climate_sequences.shape)\ncnn_model = HiveCNNBaseline(climate_sequences.shape[-1]).to(device)\npretrain_path = MAIN_DATA_DIR / 'wurzburg_sequence_pretrain.pt'\ncnn_model.load_state_dict(torch.load(pretrain_path, map_location=device), strict=False)\ncnn_model.eval()\nwith torch.no_grad():\n    occupancy = torch.sigmoid(cnn_model(torch.tensor(climate_sequences).to(device))).cpu().numpy()\nforecast = proxy_features.iloc[WINDOW:].copy()\nforecast['occupancy_risk'] = occupancy\nclimate_forecast_path = MAIN_DATA_DIR / 'makueni_climate_occupancy_forecast.csv'\nforecast[['occupancy_risk']].to_csv(climate_forecast_path)\nprint('Saved occupancy forecast ->', climate_forecast_path)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:07:01.150233Z",
     "iopub.execute_input": "2025-12-28T14:07:01.150554Z",
     "iopub.status.idle": "2025-12-28T14:07:04.644841Z",
     "shell.execute_reply.started": "2025-12-28T14:07:01.150528Z",
     "shell.execute_reply": "2025-12-28T14:07:04.643956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Climate sequences: (6525, 24, 5)\nSaved occupancy forecast -> /kaggle/working/content/main-data/makueni_climate_occupancy_forecast.csv\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 220
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "occupancy_forecast = pd.read_csv(climate_forecast_path, parse_dates=['date'], index_col='date') if 'date' in pd.read_csv(climate_forecast_path, nrows=1).columns else pd.read_csv(climate_forecast_path)\n",
    "occ_fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.plot(occupancy_forecast.index if 'date' in occupancy_forecast.columns else occupancy_forecast.index, occupancy_forecast['occupancy_risk'], label='Occupancy risk')\n",
    "ax.set_title('Climate-informed Occupancy Risk')\n",
    "ax.set_ylabel('Risk')\n",
    "ax.legend()\n",
    "occ_plot_path = FIGURE_DIR / 'climate_occupancy_forecast.png'\n",
    "occ_fig.savefig(occ_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "occ_metrics_path = FIGURE_DIR / 'climate_occupancy_metrics.json'\n",
    "occ_metrics_path.write_text(json.dumps({\"mean_risk\": float(occupancy_forecast['occupancy_risk'].mean())}, indent=2))\n",
    "print('Saved climate occupancy artifacts ->', occ_plot_path, occ_metrics_path)\n"
   ]
  }
 ]
}