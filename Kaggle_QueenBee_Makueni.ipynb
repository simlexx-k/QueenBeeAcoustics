{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc48dcf",
   "metadata": {},
   "source": [
    "# Kaggle Cloud Ops: Queen Bee Acoustics + Makueni Apiary Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b117",
   "metadata": {},
   "source": [
    "This unified notebook stitches together:\n",
    "\n",
    "1. **Queen Bee acoustic detection (CNN + hyperparameter tuning)**\n",
    "2. **Makueni Apiary intelligence workflows (weather, NDVI, telemetry, hive stress ML)**\n",
    "\n",
    "> **Kaggle usage:** Attach the `harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen` dataset plus any `content/main-data` exports as Kaggle data sources. All intermediate files are written under `content/` so the same notebook also works locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc483a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q earthengine-api ipyleaflet ipywidgets keras-tuner librosa tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DEFAULT_CONTENT = PROJECT_ROOT / \"content\"\n",
    "KAGGLE_WORKING = Path(\"/kaggle/working\")\n",
    "\n",
    "if DEFAULT_CONTENT.exists():\n",
    "    CONTENT_ROOT = DEFAULT_CONTENT.resolve()\n",
    "else:\n",
    "    CONTENT_ROOT = (KAGGLE_WORKING / \"content\").resolve()\n",
    "    CONTENT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ[\"MERGED_CONTENT_ROOT\"] = str(CONTENT_ROOT)\n",
    "MAIN_DATA_DIR = (CONTENT_ROOT / \"main-data\")\n",
    "MAIN_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "KAGGLE_INPUT_ROOT = Path(\"/kaggle/input\")\n",
    "\n",
    "def _stage_dataset(keyword, target_subdir):\n",
    "    if not KAGGLE_INPUT_ROOT.exists():\n",
    "        return None\n",
    "    matches = [p for p in KAGGLE_INPUT_ROOT.iterdir() if keyword in p.name.lower()]\n",
    "    if not matches:\n",
    "        print(f\"[setup] Kaggle input dataset containing '{keyword}' not found.\")\n",
    "        return None\n",
    "    source = matches[0]\n",
    "    target = CONTENT_ROOT / target_subdir\n",
    "    shutil.rmtree(target, ignore_errors=True)\n",
    "    shutil.copytree(source, target, dirs_exist_ok=True)\n",
    "    print(f\"[setup] Staged {source.name} -> {target}\")\n",
    "    return target\n",
    "\n",
    "def _maybe_stage(keyword, subdir):\n",
    "    try:\n",
    "        _stage_dataset(keyword, subdir)\n",
    "    except Exception as exc:\n",
    "        print(f\"[setup] Skipping auto-stage for {keyword}: {exc}\")\n",
    "\n",
    "_maybe_stage(\"beehive\", \"beehive_audio\")\n",
    "_maybe_stage(\"makueni\", \"main-data\")\n",
    "\n",
    "print(f\"CONTENT_ROOT -> {CONTENT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8446e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import datetime as dt\n",
    "import gc\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras_tuner as kt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    RocCurveDisplay\n",
    ")\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import requests\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "\n",
    "CONTENT_ROOT = Path(os.environ[\"MERGED_CONTENT_ROOT\"])\n",
    "MAIN_DATA_DIR = CONTENT_ROOT / \"main-data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00311da8",
   "metadata": {},
   "source": [
    "## Queen Bee Acoustic Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _discover_audio_dataset(content_root: Path) -> Path:\n",
    "    search_root = content_root / \"beehive_audio\"\n",
    "    if not search_root.exists():\n",
    "        raise FileNotFoundError(\n",
    "            \"beehive_audio dataset not staged. Attach the Kaggle dataset 'harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen' or copy the folder into content/beehive_audio.\"\n",
    "        )\n",
    "    for candidate in sorted(search_root.rglob(\"Dataset\")):\n",
    "        if (candidate / \"Bee Hive Audios\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"Could not locate 'Dataset/Bee Hive Audios' inside beehive_audio.\")\n",
    "\n",
    "AUDIO_DATASET_ROOT = _discover_audio_dataset(CONTENT_ROOT)\n",
    "BEEHIVE_AUDIO_DIR = next(AUDIO_DATASET_ROOT.glob(\"**/Bee Hive Audios\"))\n",
    "QUEEN_PRESENT_DIR = BEEHIVE_AUDIO_DIR / \"QueenBee Present\"\n",
    "QUEEN_ABSENT_DIR = BEEHIVE_AUDIO_DIR / \"QueenBee Absent\"\n",
    "EXTERNAL_DIR = AUDIO_DATASET_ROOT / \"External Noise\"\n",
    "\n",
    "SPECTROGRAM_DIR = AUDIO_DATASET_ROOT / \"Spectograms\"\n",
    "SPECTROGRAM_PRESENT = SPECTROGRAM_DIR / \"present\"\n",
    "SPECTROGRAM_ABSENT = SPECTROGRAM_DIR / \"absent\"\n",
    "SPECTROGRAM_EXTERNAL = SPECTROGRAM_DIR / \"external\"\n",
    "for path in [SPECTROGRAM_PRESENT, SPECTROGRAM_ABSENT, SPECTROGRAM_EXTERNAL]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Audio dataset root:\", AUDIO_DATASET_ROOT)\n",
    "print(\"Spectrogram cache:\", SPECTROGRAM_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu_resolver)\n",
    "    ACCELERATOR = \"TPU\"\n",
    "except (ValueError, tf.errors.NotFoundError):\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            try:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            except Exception:\n",
    "                pass\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        ACCELERATOR = f\"{strategy.num_replicas_in_sync}xGPU\"\n",
    "    else:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        ACCELERATOR = \"CPU\"\n",
    "\n",
    "print(f\"Using {ACCELERATOR} via {strategy.__class__.__name__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "DURATION = 3\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "librosa.cache.clear()\n",
    "plt.switch_backend(\"Agg\")\n",
    "\n",
    "def preprocess_and_save_spectrogram(audio_path: Path, output_image_path: Path, sr=SAMPLE_RATE, duration=DURATION):\n",
    "    try:\n",
    "        y, _ = librosa.load(audio_path, sr=sr)\n",
    "        y, _ = librosa.effects.trim(y)\n",
    "        y = librosa.to_mono(y) if y.ndim > 1 else y\n",
    "        y = librosa.util.normalize(y)\n",
    "\n",
    "        expected_samples = sr * duration\n",
    "        if len(y) < expected_samples:\n",
    "            y = np.pad(y, (0, expected_samples - len(y)), mode=\"constant\")\n",
    "        else:\n",
    "            y = y[:expected_samples]\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n",
    "        mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "        plt.figure(figsize=(2, 2), dpi=64)\n",
    "        librosa.display.specshow(mel_db, sr=sr, cmap=\"magma\")\n",
    "        plt.axis(\"off\")\n",
    "        output_image_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(output_image_path, bbox_inches=\"tight\", pad_inches=0)\n",
    "        plt.close()\n",
    "    except Exception as exc:\n",
    "        print(f\"[spectrogram] Failed on {audio_path}: {exc}\")\n",
    "\n",
    "def _compute_progress(files, output_dir: Path):\n",
    "    total = len(files)\n",
    "    processed = sum((output_dir / f\"{Path(f).stem}.png\").exists() for f in files)\n",
    "    return total, processed\n",
    "\n",
    "def process_audio_folder(input_dir: Path, output_dir: Path, desc: str):\n",
    "    if not input_dir.exists():\n",
    "        print(f\"[spectrogram] {input_dir} missing, skipping {desc}.\")\n",
    "        return\n",
    "    wav_files = sorted([f for f in input_dir.iterdir() if f.suffix.lower() == \".wav\"])\n",
    "    total, processed = _compute_progress([f.name for f in wav_files], output_dir)\n",
    "    with tqdm(total=total, initial=processed, desc=desc, unit=\"file\") as pbar:\n",
    "        for wav_path in wav_files:\n",
    "            out_path = output_dir / f\"{wav_path.stem}.png\"\n",
    "            if out_path.exists():\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            preprocess_and_save_spectrogram(wav_path, out_path)\n",
    "            gc.collect()\n",
    "            pbar.update(1)\n",
    "\n",
    "def process_external_folder(input_dir: Path, output_dir: Path):\n",
    "    if not input_dir.exists():\n",
    "        print(\"[spectrogram] External noise folder missing, skipping.\")\n",
    "        return\n",
    "    audio_paths = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        audio_paths += [Path(root) / f for f in files if f.lower().endswith(\".wav\")]\n",
    "    with tqdm(total=len(audio_paths), desc=\"External noise\", unit=\"file\") as pbar:\n",
    "        for wav_path in audio_paths:\n",
    "            out_path = output_dir / f\"{wav_path.stem}.png\"\n",
    "            if out_path.exists():\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            preprocess_and_save_spectrogram(wav_path, out_path)\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_audio_folder(QUEEN_PRESENT_DIR, SPECTROGRAM_PRESENT, \"QueenBee Present\")\n",
    "process_audio_folder(QUEEN_ABSENT_DIR, SPECTROGRAM_ABSENT, \"QueenBee Absent\")\n",
    "process_external_folder(EXTERNAL_DIR, SPECTROGRAM_EXTERNAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb90b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pngs(folder: Path):\n",
    "    return len([f for f in folder.glob(\"*.png\")])\n",
    "\n",
    "class_labels = [\"present\", \"absent\", \"external\"]\n",
    "counts = [\n",
    "    count_pngs(SPECTROGRAM_PRESENT),\n",
    "    count_pngs(SPECTROGRAM_ABSENT),\n",
    "    count_pngs(SPECTROGRAM_EXTERNAL),\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = plt.bar(class_labels, counts, color=[\"sienna\", \"peru\", \"gray\"], edgecolor=\"black\")\n",
    "plt.ylim(0, max(counts) * 1.1 if counts else 10)\n",
    "plt.title(\"Spectrogram Count per Class\")\n",
    "plt.ylabel(\"Images\")\n",
    "for bar in bars:\n",
    "    y = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, y + max(1, y ** 0.5), int(y), ha=\"center\", va=\"bottom\")\n",
    "plt.show()\n",
    "\n",
    "print(dict(zip(class_labels, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1438348",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (128, 128)\n",
    "BASE_BATCH_SIZE = 32\n",
    "BATCH_SIZE = BASE_BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "SEED = 42\n",
    "\n",
    "data_dir = SPECTROGRAM_DIR\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.30)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    subset=\"training\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "datagen_val_test = ImageDataGenerator(rescale=1./255, validation_split=0.5)\n",
    "\n",
    "val_gen = datagen_val_test.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    subset=\"training\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_gen = datagen_val_test.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "print(\"Class indices:\", train_gen.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_baseline_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\", input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "with strategy.scope():\n",
    "    baseline_model = build_baseline_model()\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75194ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_tunable_model(hp):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(hp.Choice(\"conv1\", [32, 64]), 3, activation=\"relu\", padding=\"same\", input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(hp.Choice(\"conv2\", [64, 128]), 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(hp.Choice(\"conv3\", [128, 256]), 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(hp.Int(\"dense_units\", 64, 128, step=32), activation=\"relu\"),\n",
    "        layers.Dropout(hp.Float(\"dropout\", 0.3, 0.6, step=0.1)),\n",
    "        layers.Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=hp.Choice(\"optimizer\", [\"adam\", \"nadam\"]),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "with strategy.scope():\n",
    "    tuner = kt.Hyperband(\n",
    "        build_tunable_model,\n",
    "        objective=\"val_accuracy\",\n",
    "        max_epochs=15,\n",
    "        factor=3,\n",
    "        directory=str(CONTENT_ROOT / \"queenbee_tuning\"),\n",
    "        project_name=\"queenbee_cnn\"\n",
    "    )\n",
    "\n",
    "stopper = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
    "\n",
    "tuner.search(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=15,\n",
    "    callbacks=[stopper]\n",
    ")\n",
    "\n",
    "with strategy.scope():\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "datagen_full = ImageDataGenerator(rescale=1./255, validation_split=0.15)\n",
    "\n",
    "final_train_gen = datagen_full.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "final_val_gen = datagen_full.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "fine_tune_history = best_model.fit(\n",
    "    final_train_gen,\n",
    "    validation_data=final_val_gen,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "best_model_path = AUDIO_DATASET_ROOT / \"queenbee_final_tuned_model.h5\"\n",
    "best_model.save(best_model_path)\n",
    "print(\"Saved tuned model to\", best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_for_eval = load_model(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921011f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, generator):\n",
    "    generator.reset()\n",
    "    y_prob = model.predict(generator, verbose=1)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    y_true = generator.classes\n",
    "    return y_pred, y_prob, y_true\n",
    "\n",
    "y_pred, y_prob, y_true = run_inference(model_for_eval, test_gen)\n",
    "class_names = list(test_gen.class_indices.keys())\n",
    "\n",
    "metrics_table = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Macro Precision\", \"Macro Recall\", \"Macro F1\"],\n",
    "    \"Score\": [\n",
    "        accuracy_score(y_true, y_pred),\n",
    "        precision_score(y_true, y_pred, average=\"macro\"),\n",
    "        recall_score(y_true, y_pred, average=\"macro\"),\n",
    "        f1_score(y_true, y_pred, average=\"macro\"),\n",
    "    ]\n",
    "})\n",
    "display(metrics_table)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "roc_auc = roc_auc_score(\n",
    "    pd.get_dummies(y_true, drop_first=False).values,\n",
    "    y_prob,\n",
    "    average=\"macro\",\n",
    "    multi_class=\"ovr\"\n",
    ")\n",
    "pr_auc = average_precision_score(\n",
    "    pd.get_dummies(y_true, drop_first=False).values,\n",
    "    y_prob,\n",
    "    average=\"macro\"\n",
    ")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f} | PR-AUC: {pr_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a188280",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 22050\n",
    "\n",
    "def audio_to_spectrogram_image(audio_path: Path):\n",
    "    y, sr = librosa.load(audio_path, sr=SR)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=512)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    fig = plt.figure(figsize=(2, 2), dpi=64)\n",
    "    librosa.display.specshow(S_dB, sr=sr, cmap=\"magma\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "\n",
    "    img = Image.open(buf).convert(\"RGB\").resize(IMG_SIZE)\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "def visualize_audio_prediction(audio_path: Path, model):\n",
    "    mel_input = audio_to_spectrogram_image(audio_path)\n",
    "    prediction = model.predict(mel_input)\n",
    "    class_names = list(test_gen.class_indices.keys())\n",
    "    pred_idx = int(np.argmax(prediction))\n",
    "    confidence = float(np.max(prediction))\n",
    "\n",
    "    y, sr = librosa.load(audio_path, sr=SR)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    times = np.linspace(0, len(y)/sr, len(y))\n",
    "    axes[0,0].plot(times, y)\n",
    "    axes[0,0].set_title(\"Waveform\")\n",
    "\n",
    "    img = axes[0,1].imshow(mel_db, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n",
    "    axes[0,1].set_title(\"Mel Spectrogram\")\n",
    "    plt.colorbar(img, ax=axes[0,1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    axes[1,0].bar(class_names, prediction[0], color=\"teal\")\n",
    "    axes[1,0].set_ylim(0, 1)\n",
    "    axes[1,0].set_title(\"Prediction Probabilities\")\n",
    "\n",
    "    axes[1,1].axis(\"off\")\n",
    "    axes[1,1].text(0.1, 0.5, f\"Predicted: {class_names[pred_idx]}\\nConfidence: {confidence:.2%}\", fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\"prediction\": class_names[pred_idx], \"confidence\": confidence}\n",
    "\n",
    "# sample_audio = next(QUEEN_PRESENT_DIR.glob('*.wav'))\n",
    "# visualize_audio_prediction(sample_audio, model_for_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1ed93",
   "metadata": {},
   "source": [
    "## Makueni Apiary Intelligence Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CENTER = (-1.8048, 37.62)\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from ipyleaflet import Map, Marker, DrawControl, basemaps\n",
    "except Exception:\n",
    "    print(\"ipyleaflet not available; using default coordinates.\")\n",
    "    lat_widget = lon_widget = geometry_widget = None\n",
    "else:\n",
    "    lat_widget = widgets.FloatText(value=DEFAULT_CENTER[0], description=\"Latitude\", step=0.0001)\n",
    "    lon_widget = widgets.FloatText(value=DEFAULT_CENTER[1], description=\"Longitude\", step=0.0001)\n",
    "    geometry_widget = widgets.Textarea(\n",
    "        value=\"\",\n",
    "        description=\"Geometry\",\n",
    "        placeholder=\"Draw a polygon/rectangle on the map.\",\n",
    "        layout=widgets.Layout(width=\"100%\", height=\"140px\"),\n",
    "        disabled=True,\n",
    "    )\n",
    "\n",
    "    leaflet_map = Map(center=DEFAULT_CENTER, zoom=8, basemap=basemaps.OpenStreetMap.Mapnik, scroll_wheel_zoom=True)\n",
    "    marker = Marker(location=DEFAULT_CENTER, draggable=True)\n",
    "    leaflet_map.add_layer(marker)\n",
    "\n",
    "    draw_control = DrawControl(\n",
    "        polygon={\"shapeOptions\": {\"color\": \"#2563eb\", \"weight\": 2, \"fillOpacity\": 0.2}},\n",
    "        rectangle={\"shapeOptions\": {\"color\": \"#f97316\", \"weight\": 2, \"fillOpacity\": 0.15}},\n",
    "        circle={},\n",
    "        circlemarker={},\n",
    "        polyline={},\n",
    "    )\n",
    "    leaflet_map.add_control(draw_control)\n",
    "\n",
    "    def _update_marker(change):\n",
    "        marker.location = (lat_widget.value, lon_widget.value)\n",
    "\n",
    "    lat_widget.observe(_update_marker, names=\"value\")\n",
    "    lon_widget.observe(_update_marker, names=\"value\")\n",
    "\n",
    "    display(widgets.HBox([lat_widget, lon_widget]))\n",
    "    display(geometry_widget)\n",
    "    display(leaflet_map)\n",
    "\n",
    "lat_widget_available = 'lat_widget' in globals() and lat_widget is not None\n",
    "lon_widget_available = 'lon_widget' in globals() and lon_widget is not None\n",
    "\n",
    "if lat_widget_available and lon_widget_available:\n",
    "    latitude = float(lat_widget.value)\n",
    "    longitude = float(lon_widget.value)\n",
    "else:\n",
    "    latitude, longitude = DEFAULT_CENTER\n",
    "    print(\"Using default coordinates:\", DEFAULT_CENTER)\n",
    "\n",
    "selected_geometry_geojson = globals().get('selected_geometry_geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f4ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_start_date = \"2008-01-01\"\n",
    "raw_end_date = \"2025-12-05\"\n",
    "timezone = \"Africa/Nairobi\"\n",
    "\n",
    "def normalize_date_string(d: str) -> dt.date:\n",
    "    parts = d.split(\"-\")\n",
    "    if len(parts) != 3:\n",
    "        raise ValueError(\"Date must be YYYY-MM-DD\")\n",
    "    y, m, day = [int(p) for p in parts]\n",
    "    m = max(1, min(12, m))\n",
    "    last_day = calendar.monthrange(y, m)[1]\n",
    "    day = max(1, min(last_day, day))\n",
    "    return dt.date(y, m, day)\n",
    "\n",
    "start_date = normalize_date_string(raw_start_date)\n",
    "end_date = normalize_date_string(raw_end_date)\n",
    "\n",
    "today = dt.date.today()\n",
    "api_latest = dt.date(2025, 12, 20)\n",
    "max_allowed = min(today, api_latest)\n",
    "\n",
    "if end_date > max_allowed:\n",
    "    print(f\"Clamping end_date {end_date} -> {max_allowed}\")\n",
    "    end_date = max_allowed\n",
    "if start_date > end_date:\n",
    "    raise ValueError(\"start_date must be before end_date\")\n",
    "\n",
    "print(\"Using date range:\", start_date, \"→\", end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_REMOTE_CALLS = False  # Kaggle notebooks typically block outbound internet.\n",
    "\n",
    "def split_date_range(start: dt.date, end: dt.date, max_days: int = 365):\n",
    "    chunks = []\n",
    "    current = start\n",
    "    while current <= end:\n",
    "        chunk_end = min(end, current + dt.timedelta(days=max_days - 1))\n",
    "        chunks.append((current, chunk_end))\n",
    "        current = chunk_end + dt.timedelta(days=1)\n",
    "    return chunks\n",
    "\n",
    "def fetch_chunk(lat, lon, sdate: dt.date, edate: dt.date, timezone=\"Africa/Nairobi\", max_retries=3, backoff=2):\n",
    "    base = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    daily_vars = \",\".join([\n",
    "        \"temperature_2m_max\",\n",
    "        \"temperature_2m_min\",\n",
    "        \"temperature_2m_mean\",\n",
    "        \"precipitation_sum\",\n",
    "        \"relative_humidity_2m_mean\",\n",
    "        \"wind_speed_10m_max\",\n",
    "        \"cloudcover_mean\"\n",
    "    ])\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": sdate.strftime(\"%Y-%m-%d\"),\n",
    "        \"end_date\": edate.strftime(\"%Y-%m-%d\"),\n",
    "        \"daily\": daily_vars,\n",
    "        \"timezone\": timezone\n",
    "    }\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            resp = requests.get(base, params=params, timeout=30)\n",
    "            resp.raise_for_status()\n",
    "            payload = resp.json()\n",
    "            if \"daily\" not in payload or \"time\" not in payload[\"daily\"]:\n",
    "                raise ValueError(\"API response missing expected fields.\")\n",
    "            return payload\n",
    "        except Exception as exc:\n",
    "            print(f\"Attempt {attempt} failed: {exc}\")\n",
    "            if attempt == max_retries:\n",
    "                raise\n",
    "            time.sleep(backoff ** attempt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b45a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_csv = MAIN_DATA_DIR / \"makueni_weather_2008_2025.csv\"\n",
    "chunks = split_date_range(start_date, end_date, max_days=365)\n",
    "\n",
    "if ENABLE_REMOTE_CALLS:\n",
    "    dfs = []\n",
    "    for s, e in chunks:\n",
    "        payload = fetch_chunk(latitude, longitude, s, e, timezone=timezone)\n",
    "        daily = payload[\"daily\"]\n",
    "        df_chunk = pd.DataFrame({\n",
    "            \"date\": daily[\"time\"],\n",
    "            \"temp_max\": daily.get(\"temperature_2m_max\"),\n",
    "            \"temp_min\": daily.get(\"temperature_2m_min\"),\n",
    "            \"temp_mean\": daily.get(\"temperature_2m_mean\"),\n",
    "            \"humidity_mean\": daily.get(\"relative_humidity_2m_mean\"),\n",
    "            \"rainfall_mm\": daily.get(\"precipitation_sum\"),\n",
    "            \"wind_speed_max\": daily.get(\"wind_speed_10m_max\"),\n",
    "            \"cloud_cover_percent\": daily.get(\"cloudcover_mean\"),\n",
    "        })\n",
    "        dfs.append(df_chunk)\n",
    "        time.sleep(1)\n",
    "    weather_df = pd.concat(dfs, ignore_index=True)\n",
    "    weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "    weather_df.sort_values(\"date\", inplace=True)\n",
    "    weather_df.to_csv(weather_csv, index=False)\n",
    "    print(\"Fetched and saved weather CSV to\", weather_csv)\n",
    "else:\n",
    "    if weather_csv.exists():\n",
    "        weather_df = pd.read_csv(weather_csv, parse_dates=[\"date\"])\n",
    "        print(f\"Loaded cached weather data from {weather_csv}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{weather_csv} not found; enable ENABLE_REMOTE_CALLS to regenerate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd89f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_csv = MAIN_DATA_DIR / \"makueni_ndvi_2008_2025.csv\"\n",
    "\n",
    "if ENABLE_REMOTE_CALLS:\n",
    "    try:\n",
    "        ee.Initialize()\n",
    "    except Exception:\n",
    "        print(\"Authenticating with Earth Engine...\")\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "\n",
    "    point = ee.Geometry.Point([longitude, latitude])\n",
    "    modis = ee.ImageCollection(\"MODIS/061/MOD13Q1\").select(\"NDVI\").filterDate(start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")).filterBounds(point)\n",
    "\n",
    "    def extract_ndvi(image):\n",
    "        mean = image.reduceRegion(reducer=ee.Reducer.mean(), geometry=point, scale=250).get(\"NDVI\")\n",
    "        date = image.date().format(\"YYYY-MM-dd\")\n",
    "        return ee.Feature(None, {\"date\": date, \"ndvi_mean\": mean})\n",
    "\n",
    "    ndvi_fc = modis.map(extract_ndvi).getInfo()\n",
    "    records = [f[\"properties\"] for f in ndvi_fc[\"features\"]]\n",
    "    ndvi_df = pd.DataFrame(records)\n",
    "    ndvi_df[\"date\"] = pd.to_datetime(ndvi_df[\"date\"])\n",
    "    ndvi_df[\"ndvi_mean\"] = ndvi_df[\"ndvi_mean\"].astype(float) / 10000\n",
    "    ndvi_df.to_csv(ndvi_csv, index=False)\n",
    "    print(\"Fetched NDVI and saved to\", ndvi_csv)\n",
    "else:\n",
    "    if ndvi_csv.exists():\n",
    "        ndvi_df = pd.read_csv(ndvi_csv, parse_dates=[\"date\"])\n",
    "        print(f\"Loaded cached NDVI data from {ndvi_csv}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{ndvi_csv} not found; enable ENABLE_REMOTE_CALLS to regenerate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = weather_df.copy()\n",
    "df_ndvi = ndvi_df.copy()\n",
    "\n",
    "df_weather[\"date\"] = pd.to_datetime(df_weather[\"date\"])\n",
    "df_ndvi[\"date\"] = pd.to_datetime(df_ndvi[\"date\"])\n",
    "\n",
    "df_merged = pd.merge(df_weather, df_ndvi, on=\"date\", how=\"left\").sort_values(\"date\")\n",
    "weather_ndvi_path = MAIN_DATA_DIR / \"makueni_weather_ndvi_2008_2025.csv\"\n",
    "df_merged.to_csv(weather_ndvi_path, index=False)\n",
    "print(\"Merged weather+NDVI ->\", weather_ndvi_path)\n",
    "df_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27121437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month = df_merged.set_index(\"date\").resample(\"ME\").agg({\n",
    "    \"rainfall_mm\": \"sum\",\n",
    "    \"temp_mean\": \"mean\",\n",
    "    \"humidity_mean\": \"mean\",\n",
    "    \"ndvi_mean\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "axes[0].plot(df_month[\"date\"], df_month[\"rainfall_mm\"], marker=\"o\")\n",
    "axes[0].set_title(\"Monthly Rainfall (mm)\")\n",
    "\n",
    "axes[1].plot(df_month[\"date\"], df_month[\"temp_mean\"], marker=\"o\", color=\"tomato\")\n",
    "axes[1].set_title(\"Monthly Mean Temperature (°C)\")\n",
    "\n",
    "axes[2].plot(df_month[\"date\"], df_month[\"ndvi_mean\"], marker=\"o\", color=\"green\")\n",
    "axes[2].set_title(\"Monthly NDVI Mean\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylabel(\"Value\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea5e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "hive_logs_path = MAIN_DATA_DIR / \"hive_logs_2008_2025.csv\"\n",
    "\n",
    "if hive_logs_path.exists():\n",
    "    hive_df = pd.read_csv(hive_logs_path, parse_dates=[\"date\"])\n",
    "    print(\"Loaded hive logs from\", hive_logs_path)\n",
    "else:\n",
    "    print(\"Generating synthetic hive telemetry...\")\n",
    "    start_dt = dt.datetime(2008, 1, 1)\n",
    "    end_dt = dt.datetime(2025, 9, 30)\n",
    "    dates = pd.date_range(start=start_dt, end=end_dt, freq=\"7D\")\n",
    "\n",
    "    hive_ids = [\"Hive-A\", \"Hive-B\", \"Hive-C\", \"Hive-D\"]\n",
    "    data = []\n",
    "    rng = np.random.default_rng(42)\n",
    "    for hive in hive_ids:\n",
    "        queen_age = rng.integers(3, 20)\n",
    "        for date in dates:\n",
    "            honey_yield = max(0, rng.normal(12, 3))\n",
    "            varroa = np.clip(rng.normal(8, 3), 0, 40)\n",
    "            hive_weight = rng.normal(45, 5)\n",
    "            brood_area = np.clip(rng.normal(800, 150), 100, 1200)\n",
    "            stress_event = rng.choice([\"none\", \"ants\", \"drought\"], p=[0.85, 0.1, 0.05])\n",
    "            data.append({\n",
    "                \"date\": date,\n",
    "                \"hive_id\": hive,\n",
    "                \"honey_yield_kg\": honey_yield,\n",
    "                \"varroa_pct\": varroa,\n",
    "                \"hive_weight_kg\": hive_weight,\n",
    "                \"brood_area_cm2\": brood_area,\n",
    "                \"stress_event\": stress_event,\n",
    "                \"queen_age_months\": queen_age\n",
    "            })\n",
    "    hive_df = pd.DataFrame(data)\n",
    "    hive_df.to_csv(hive_logs_path, index=False)\n",
    "    print(\"Synthetic hive logs saved to\", hive_logs_path)\n",
    "\n",
    "hive_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_full = pd.read_csv(weather_ndvi_path, parse_dates=[\"date\"])\n",
    "hive_df[\"date\"] = pd.to_datetime(hive_df[\"date\"])\n",
    "merged = pd.merge(hive_df, weather_full, on=\"date\", how=\"left\")\n",
    "merged_path = MAIN_DATA_DIR / \"merged_hive_weather_ndvi.csv\"\n",
    "merged.to_csv(merged_path, index=False)\n",
    "print(\"Merged hive + weather ->\", merged_path)\n",
    "merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d3330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "floral_data = {\n",
    "    \"date\": [\n",
    "        \"2025-01-15\",\"2025-02-15\",\"2025-03-15\",\"2025-04-15\",\n",
    "        \"2025-05-15\",\"2025-06-15\",\"2025-07-15\",\"2025-08-15\",\"2025-09-15\"\n",
    "    ],\n",
    "    \"major_flowers\": [\n",
    "        \"Acacia tortilis, Mango, Commiphora\",\n",
    "        \"Acacia tortilis, Acacia mellifera, Mango\",\n",
    "        \"Croton, Acacia mellifera\",\n",
    "        \"Croton, Melia volkensii\",\n",
    "        \"Citrus, Croton\",\n",
    "        \"Aloe, Citrus\",\n",
    "        \"Aloe, Pasture weeds\",\n",
    "        \"Eucalyptus, Pasture weeds\",\n",
    "        \"Eucalyptus camaldulensis\"\n",
    "    ],\n",
    "    \"nectar_flow_strength\": [\"High\",\"High\",\"Medium\",\"Medium\",\"Medium\",\"Medium\",\"Low\",\"Low-Medium\",\"High\"],\n",
    "    \"stress_risk\": [\"Low\",\"Low\",\"Medium\",\"Low\",\"Medium\",\"Medium\",\"High\",\"High\",\"Low\"],\n",
    "    \"pest_disease_notes\": [\n",
    "        \"Hive beetles active\",\n",
    "        \"Wax moth pressure\",\n",
    "        \"Varroa buildup\",\n",
    "        \"Chalkbrood risk\",\n",
    "        \"Nosema risk\",\n",
    "        \"Slow brood buildup\",\n",
    "        \"Ant invasions\",\n",
    "        \"Weak colony pests\",\n",
    "        \"Healthy buildup\"\n",
    "    ]\n",
    "}\n",
    "floral_df = pd.DataFrame(floral_data)\n",
    "floral_df[\"date\"] = pd.to_datetime(floral_df[\"date\"])\n",
    "floral_path = MAIN_DATA_DIR / \"makueni_floral_calendar_2025.csv\"\n",
    "floral_df.to_csv(floral_path, index=False)\n",
    "print(\"Floral calendar saved to\", floral_path)\n",
    "floral_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ec06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_full = merged.merge(floral_df, on=\"date\", how=\"left\")\n",
    "merged_full_path = MAIN_DATA_DIR / \"merged_hive_weather_floral_2025.csv\"\n",
    "merged_full.to_csv(merged_full_path, index=False)\n",
    "print(\"Merged hive/weather/floral ->\", merged_full_path)\n",
    "merged_full.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43772c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = merged_full.copy()\n",
    "model_df[\"stress_event\"] = model_df[\"stress_event\"].fillna(\"none\")\n",
    "model_df[\"stress_target\"] = (model_df[\"stress_event\"] != \"none\").astype(int)\n",
    "model_df[\"date\"] = pd.to_datetime(model_df[\"date\"])\n",
    "model_df[\"month\"] = model_df[\"date\"].dt.month\n",
    "model_df[\"year\"] = model_df[\"date\"].dt.year\n",
    "model_df[\"weekofyear\"] = model_df[\"date\"].dt.isocalendar().week.astype(int)\n",
    "\n",
    "rolling_features = [\"honey_yield_kg\", \"varroa_pct\", \"hive_weight_kg\", \"brood_area_cm2\"]\n",
    "for feature in rolling_features:\n",
    "    if feature in model_df.columns:\n",
    "        model_df[f\"{feature}_rolling_mean\"] = (\n",
    "            model_df.groupby(\"hive_id\")[feature]\n",
    "            .transform(lambda s: s.rolling(window=4, min_periods=1).mean())\n",
    "        )\n",
    "        model_df[f\"{feature}_rolling_std\"] = (\n",
    "            model_df.groupby(\"hive_id\")[feature]\n",
    "            .transform(lambda s: s.rolling(window=4, min_periods=1).std())\n",
    "        )\n",
    "\n",
    "numeric_cols = model_df.select_dtypes(include=[np.number]).columns\n",
    "exclude_cols = {\"stress_target\"}\n",
    "feature_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "X = model_df[feature_cols].copy()\n",
    "X = X.dropna(axis=1, how=\"all\")\n",
    "feature_cols = list(X.columns)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=feature_cols, index=model_df.index)\n",
    "y = model_df[\"stress_target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(classes, class_weights)}\n",
    "\n",
    "hb_model = HistGradientBoostingClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.08,\n",
    "    max_iter=400,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "hb_model.fit(X_train, y_train)\n",
    "y_pred = hb_model.predict(X_test)\n",
    "y_prob = hb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_prob)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 12\n",
    "feature_columns = [col for col in feature_cols if col in model_df.columns]\n",
    "sequence_features = model_df[feature_columns].fillna(model_df[feature_columns].median()).copy()\n",
    "sequence_targets = model_df['stress_target'].values\n",
    "\n",
    "X_sequences = []\n",
    "y_sequences = []\n",
    "metadata = []\n",
    "for hive_id, group in model_df.groupby('hive_id'):\n",
    "    group = group.sort_values('date')\n",
    "    features = group[feature_columns].fillna(group[feature_columns].median()).values\n",
    "    targets = group['stress_target'].values\n",
    "    dates = group['date'].values\n",
    "    if len(group) <= WINDOW_SIZE:\n",
    "        continue\n",
    "    for idx in range(WINDOW_SIZE, len(group)):\n",
    "        window = features[idx-WINDOW_SIZE:idx]\n",
    "        X_sequences.append(window)\n",
    "        y_sequences.append(targets[idx])\n",
    "        metadata.append({\"hive_id\": hive_id, \"date\": dates[idx]})\n",
    "\n",
    "X_sequences = np.array(X_sequences, dtype=np.float32)\n",
    "y_sequences = np.array(y_sequences, dtype=np.float32)\n",
    "print(f'Total sequences: {X_sequences.shape[0]} | window shape: {X_sequences.shape[1:]}')\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.X = torch.tensor(sequences, dtype=torch.float32)\n",
    "        self.y = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(\n",
    "    X_sequences, y_sequences, test_size=0.2, random_state=42, stratify=y_sequences\n",
    ")\n",
    "\n",
    "train_dataset = SequenceDataset(X_train_seq, y_train_seq)\n",
    "val_dataset = SequenceDataset(X_test_seq, y_test_seq)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "input_channels = X_sequences.shape[-1]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class HiveCNN(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "model = HiveCNN(input_channels).to(device)\n",
    "pos_weight_value = float(max(1.0, (len(y_train_seq) - y_train_seq.sum()) / max(1.0, y_train_seq.sum())))\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight_value, device=device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train(train)\n",
    "    total_loss = 0\n",
    "    preds, targets = [], []\n",
    "    for batch_X, batch_y in loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = model(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        total_loss += loss.item() * batch_X.size(0)\n",
    "        preds.append(torch.sigmoid(logits).detach().cpu().numpy())\n",
    "        targets.append(batch_y.detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "    return total_loss / len(loader.dataset), roc_auc_score(targets, preds)\n",
    "\n",
    "epochs = 50\n",
    "best_auc = 0\n",
    "patience = 8\n",
    "patience_counter = 0\n",
    "model_path = MAIN_DATA_DIR / \"hive_cnn_torch.pt\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_auc = run_epoch(train_loader, train=True)\n",
    "    val_loss, val_auc = run_epoch(val_loader, train=False)\n",
    "    print(f\"Epoch {epoch+1:02d}: train_loss={train_loss:.4f} AUC={train_auc:.3f} | val_loss={val_loss:.4f} AUC={val_auc:.3f}\")\n",
    "    if val_auc > best_auc + 1e-3:\n",
    "        best_auc = val_auc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = []\n",
    "    labels = []\n",
    "    for batch_X, batch_y in val_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        logits.append(model(batch_X).cpu())\n",
    "        labels.append(batch_y)\n",
    "    logits = torch.cat(logits)\n",
    "    labels = torch.cat(labels)\n",
    "    probs = torch.sigmoid(logits).numpy()\n",
    "    labels_np = labels.numpy()\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(labels_np, probs)\n",
    "f_scores = (2 * precision * recall) / np.clip(precision + recall, 1e-8, None)\n",
    "best_idx = np.argmax(f_scores)\n",
    "best_threshold = thresholds[max(best_idx - 1, 0)] if best_idx < len(thresholds) else 0.5\n",
    "preds = (probs >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"Best threshold based on F1: {best_threshold:.3f}\")\n",
    "print(classification_report(labels_np, preds))\n",
    "print('Test ROC-AUC:', roc_auc_score(labels_np, probs))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].plot(recall, precision)\n",
    "axes[0].set_title('Precision-Recall')\n",
    "axes[0].set_xlabel('Recall')\n",
    "axes[0].set_ylabel('Precision')\n",
    "RocCurveDisplay.from_predictions(labels_np, probs, ax=axes[1])\n",
    "axes[1].set_title('ROC Curve')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Best model weights saved to', model_path)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
