{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 12134294,
     "sourceType": "datasetVersion",
     "datasetId": 7505074
    }
   ],
   "dockerImageVersionId": 31040,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "colab": {
   "name": "Queen Bee detection using CNN",
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning Pipeline for Queen Bee Acoustic Monitoring Using CNN\n",
    "\n",
    "A complete end-to-end prototype to detect **Queen Bee Presence** from **Hive audio recordings** using a Machine Learning pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "## Live Demo (CNN prototype is in progress)\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Note:\n",
    "You can try the deployed model (Model used Random Forest Classifier in this prototype) and download a sample audio file to test it.\n",
    "\n",
    "</div>\n",
    "\n",
    "<span style=\"display: inline-block;\">\n",
    "  <a href=\"http://3.109.237.216\">\n",
    "    <img src=\"https://img.shields.io/badge/Live-Demo-blue\" alt=\"Live Demo\">\n",
    "  </a>\n",
    "</span>\n",
    "\n",
    "<span style=\"display: inline-block;\" >\n",
    "<a href=\"https://drive.google.com/drive/folders/1KFmHH304soDKXbLvlohWBJ-qVzudjTgZ?usp=sharing\">\n",
    "    <img src=\"https://img.shields.io/badge/Google%20Drive-Sample%20Data-blue?logo=google-drive&logoColor=white\" alt=\"Google Drive\">\n",
    "</a>\n",
    "</span>\n",
    "    \n",
    "<span style=\"display: inline-block;\">\n",
    "<a href=\"https://github.com/Harsh-1711/BuzzDetect\">\n",
    "  <img src=\"https://img.shields.io/badge/GitHub-View%20Repository-blue?logo=github\" alt=\"GitHub Repo\">\n",
    "</a>\n",
    "</span>\n",
    "<span style=\"display: inline-block;\">\n",
    "  <a href=\"https://drive.google.com/file/d/1XldGWp5G2Ecby9GLpalsgegvOgMsL_HJ/view?usp=sharing\" target=\"_blank\">\n",
    "    <img src=\"https://img.shields.io/badge/Demo-Video-green?logo=google-drive\" alt=\"Demo Video\">\n",
    "  </a>\n",
    "</span>\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates a complete pipeline for processing hive audio recordings and applying machine learning to detect the presence of the queen bee.\n",
    "It covers audio feature extraction, dataset preparation, model training, evaluation, and inference."
   ],
   "metadata": {
    "id": "jKnuukST4X2J"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Import necessary libraries for the Queen Bee Detection project.\n",
    "\n",
    "- os: For file and directory operations.\n",
    "- numpy: For numerical operations on arrays and matrices.\n",
    "- matplotlib & seaborn: For data visualization.\n",
    "- librosa: For audio processing and feature extraction.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-13T09:04:43.22203Z",
     "iopub.execute_input": "2025-06-13T09:04:43.222358Z",
     "iopub.status.idle": "2025-06-13T09:04:43.227533Z",
     "shell.execute_reply.started": "2025-06-13T09:04:43.222337Z",
     "shell.execute_reply": "2025-06-13T09:04:43.226768Z"
    },
    "trusted": true,
    "id": "Tbue9gj54X2Q",
    "outputId": "bf38d564-877e-4f8a-945e-b3da5676a468",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-12-21T07:06:54.106507Z",
     "start_time": "2025-12-21T07:06:47.320979Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 10:06:48.548533: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-21 10:06:49.324559: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-21 10:06:53.012742: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **1. Data Loading and Exploration**\n",
    "#### ðŸ“Œ Objective:\n",
    "    Load the dataset dataset and plot a graph showing the total no. of dataset for each category.\n",
    "    \n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    Dataset Source:\n",
    "</div>\n",
    "        \n",
    "  - This dataset was originally sourced from https://zenodo.org/records/2667806.\n",
    "  - It contains labeled audio recordings from beehives for Queen Bee detection.\n",
    "  - Modified Dataset - https://www.kaggle.com/datasets/harshkumar1711/beehive-audio-dataset-with-queen-and-without-queen"
   ],
   "metadata": {
    "id": "u1qUEuCM4X2S"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#importing dataset from kaggle\n",
    "\n",
    "for dirname, _, filenames in os.walk('/content/beehive_audio/7'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-13T09:04:49.922122Z",
     "iopub.execute_input": "2025-06-13T09:04:49.922721Z",
     "iopub.status.idle": "2025-06-13T09:05:13.760153Z",
     "shell.execute_reply.started": "2025-06-13T09:04:49.922694Z",
     "shell.execute_reply": "2025-06-13T09:05:13.759365Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "id": "Qc-UQ-Xu4X2U",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "94a2d478-e830-49d2-cbbc-1fa04910e8ef",
    "ExecuteTime": {
     "end_time": "2025-12-21T07:07:08.017394Z",
     "start_time": "2025-12-21T07:07:08.001932Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Load base path\n",
    "base_path = \"./content/beehive_audio/7/Dataset/Bee Hive Audios\"\n",
    "\n",
    "# Include spaces prbboperly using raw string or quotes\n",
    "present_path = os.path.join(base_path, \"QueenBee Present\")\n",
    "absent_path = os.path.join(base_path, \"QueenBee Absent\")\n",
    "external_path= './content/beehive_audio/7/Dataset/External Noise'\n",
    "\n",
    "# Count .wav files\n",
    "present_count = len([f for f in os.listdir(present_path) if f.endswith('.wav')])\n",
    "absent_count = len([f for f in os.listdir(absent_path) if f.endswith('.wav')])\n",
    "external_count = len([f for f in os.listdir(external_path) if f.endswith('.wav')])\n",
    "# Print counts\n",
    "print(f\"QueenBee Present: {present_count} files\")\n",
    "print(f\"QueenBee Absent: {absent_count} files\")\n",
    "print(f\"External Noise: {external_count} files\")\n",
    "\n",
    "# Plot the counts\n",
    "labels = ['QueenBee Present', 'QueenBee Absent','External Noise']\n",
    "counts = [present_count, absent_count, external_count]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.ylim(0, 4300)\n",
    "bars=plt.bar(labels, counts, color=['brown', 'beige','orange'],edgecolor='black')\n",
    "plt.grid(axis=\"y\",linestyle=\"--\",alpha=0.7)\n",
    "for bar in bars:\n",
    "    x = bar.get_x() + bar.get_width()/2\n",
    "    y = bar.get_height()\n",
    "    plt.text(x, y+y ** 0.5, str(y), ha='center', va='bottom', fontsize=10, color='black')\n",
    "plt.title(\"Queen Bee Audio File Count\")\n",
    "plt.ylabel(\"Number of Files\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-13T09:05:15.286055Z",
     "iopub.execute_input": "2025-06-13T09:05:15.286612Z",
     "iopub.status.idle": "2025-06-13T09:05:15.699588Z",
     "shell.execute_reply.started": "2025-06-13T09:05:15.286578Z",
     "shell.execute_reply": "2025-06-13T09:05:15.698698Z"
    },
    "trusted": true,
    "id": "xUuQC_Oo4X2V",
    "outputId": "6eeade4d-6ccd-4fcb-93c5-1522d1035f42",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-12-21T07:07:12.175928Z",
     "start_time": "2025-12-21T07:07:11.719369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueenBee Present: 4000 files\n",
      "QueenBee Absent: 2000 files\n",
      "External Noise: 2000 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu_resolver)\n",
    "    ACCELERATOR = 'TPU'\n",
    "except (ValueError, tf.errors.NotFoundError):\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            try:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            except Exception:\n",
    "                pass\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        ACCELERATOR = f\"{strategy.num_replicas_in_sync}xGPU\"\n",
    "    else:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        ACCELERATOR = 'CPU'\n",
    "\n",
    "print(f\"Using {ACCELERATOR} via tf.distribute strategy: {strategy.__class__.__name__}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **2. Audio Preprocessing and Spectrogram Generation**\n",
    "#### ðŸ“Œ Objective:\n",
    "    This section defines parameters for audio sampling and a function to convert `.wav` audio files into mel spectrogram images. The function performs the following steps:\n",
    "    - Loads and trims the audio.\n",
    "    - Normalizes the signal and ensures a fixed length.\n",
    "    - Generates a mel spectrogram using Librosa.\n",
    "    - Saves the spectrogram as a `.png` image for use in model training.\n",
    "\n",
    "This is a key step in preparing audio data for convolutional neural networks (CNNs), which work better with visual inputs."
   ],
   "metadata": {
    "id": "88mp3Ahc4X2X"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "output_base = \"./content/beehive_audio/7/Dataset/Spectograms\"\n",
    "os.makedirs(os.path.join(output_base, \"present\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_base, \"absent\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_base, \"external\"), exist_ok=True)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-11T12:25:26.936475Z",
     "iopub.execute_input": "2025-06-11T12:25:26.936816Z",
     "iopub.status.idle": "2025-06-11T12:25:26.943065Z",
     "shell.execute_reply.started": "2025-06-11T12:25:26.936791Z",
     "shell.execute_reply": "2025-06-11T12:25:26.942159Z"
    },
    "trusted": true,
    "id": "sggglMUt4X2Z",
    "ExecuteTime": {
     "end_time": "2025-12-21T07:07:25.141481Z",
     "start_time": "2025-12-21T07:07:25.136269Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "SAMPLE_RATE = 22050\n",
    "DURATION = 3  # seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "# Function to process and save spectrograms\n",
    "def preprocess_and_save_spectrogram(audio_path, output_image_path, sr=SAMPLE_RATE, duration=DURATION):\n",
    "\n",
    "    \"\"\"\n",
    "    Load an audio file, convert it into a mel spectrogram, and save it as an image.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    audio_path : str\n",
    "        Path to the input .wav audio file.\n",
    "    output_image_path : str\n",
    "        Path where the output spectrogram image will be saved.\n",
    "    sr : int, optional\n",
    "        Sampling rate for the audio. Default is 22050 Hz.\n",
    "    duration : int, optional\n",
    "        Duration (in seconds) to which the audio will be fixed. Default is 3 seconds.\n",
    "\n",
    "    Steps:\n",
    "    ------\n",
    "    1. Load and trim silence from the audio.\n",
    "    2. Convert to mono and normalize the waveform.\n",
    "    3. Pad or truncate to fixed duration.\n",
    "    4. Generate a mel spectrogram.\n",
    "    5. Convert the power spectrogram to decibels.\n",
    "    6. Save the spectrogram as a `.png` image (suitable for CNN input).\n",
    "\n",
    "    Exceptions:\n",
    "    -----------\n",
    "    If any error occurs during processing, the function will print an error message.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        y, _ = librosa.load(audio_path, sr=sr)\n",
    "        y, _ = librosa.effects.trim(y)\n",
    "        y = librosa.to_mono(y) if y.ndim > 1 else y\n",
    "        y = librosa.util.normalize(y)\n",
    "\n",
    "        max_len = sr * duration\n",
    "        if len(y) > max_len:\n",
    "            y = y[:max_len]\n",
    "        else:\n",
    "            y = np.pad(y, (0, max_len - len(y)))\n",
    "\n",
    "        # Create mel spectrogram\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        # Save as image\n",
    "        plt.figure(figsize=(2.56, 2.56), dpi=100)\n",
    "        librosa.display.specshow(S_dB, sr=sr, cmap='magma')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout(pad=0)\n",
    "        plt.savefig(output_image_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-11T12:25:29.360153Z",
     "iopub.execute_input": "2025-06-11T12:25:29.360435Z",
     "iopub.status.idle": "2025-06-11T12:25:29.369162Z",
     "shell.execute_reply.started": "2025-06-11T12:25:29.360416Z",
     "shell.execute_reply": "2025-06-11T12:25:29.368039Z"
    },
    "trusted": true,
    "id": "JXeFWqI24X2a",
    "ExecuteTime": {
     "end_time": "2025-12-21T07:07:29.583244Z",
     "start_time": "2025-12-21T07:07:29.531157Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Attempting to fix the memory climb on processing Spectograms"
   ],
   "metadata": {
    "id": "JRQsNFO8Oi67"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Clear librosa cache (safe on all versions)\n",
    "librosa.cache.clear()\n",
    "\n",
    "# Non-interactive backend (prevents memory growth)\n",
    "plt.switch_backend(\"Agg\")\n",
    "\n",
    "# Utility helpers so we can resume processing instead of restarting from zero\n",
    "def _compute_progress(files, output_dir):\n",
    "    total = len(files)\n",
    "    processed = sum(\n",
    "        os.path.exists(os.path.join(output_dir, f.replace(\".wav\", \".png\")))\n",
    "        for f in files\n",
    "    )\n",
    "    return total, processed\n",
    "\n",
    "def process_audio_folder(input_dir, output_dir, desc):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    wav_files = sorted([f for f in os.listdir(input_dir) if f.endswith(\".wav\")])\n",
    "    total, processed = _compute_progress(wav_files, output_dir)\n",
    "\n",
    "    with tqdm(total=total, initial=processed, desc=desc, unit=\"file\") as pbar:\n",
    "        for filename in wav_files:\n",
    "            output_path = os.path.join(output_dir, filename.replace(\".wav\", \".png\"))\n",
    "            if os.path.exists(output_path):\n",
    "                continue\n",
    "\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            preprocess_and_save_spectrogram(input_path, output_path)\n",
    "            gc.collect()\n",
    "            pbar.update(1)\n",
    "\n",
    "def process_external_folder(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    audio_pairs = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".wav\"):\n",
    "                audio_pairs.append((\n",
    "                    os.path.join(root, filename),\n",
    "                    os.path.join(output_dir, filename.replace(\".wav\", \".png\"))\n",
    "                ))\n",
    "\n",
    "    total = len(audio_pairs)\n",
    "    processed = sum(os.path.exists(out_path) for _, out_path in audio_pairs)\n",
    "    with tqdm(total=total, initial=processed, desc=\"Processing External\", unit=\"file\") as pbar:\n",
    "        for src, dst in audio_pairs:\n",
    "            if os.path.exists(dst):\n",
    "                continue\n",
    "            preprocess_and_save_spectrogram(src, dst)\n",
    "            gc.collect()\n",
    "            pbar.update(1)\n",
    "\n",
    "process_audio_folder(present_path, os.path.join(output_base, \"present\"), \"Processing Present\")\n",
    "process_audio_folder(absent_path, os.path.join(output_base, \"absent\"), \"Processing Absent\")\n",
    "process_external_folder(external_path, os.path.join(output_base, \"external\"))\n",
    "\n",
    "print(\"âœ… Spectrogram image generation complete.\")\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2WcKOC7N2SH",
    "outputId": "5853baac-2460-4e03-8a78-1121b2437506",
    "ExecuteTime": {
     "end_time": "2025-12-21T07:07:38.146157Z",
     "start_time": "2025-12-21T07:07:37.854778Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Memory(location=None)]: Flushing completely the cache\n",
      "Processing Present: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [00:00<?, ?file/s]\n",
      "Processing Absent: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:00<?, ?file/s]\n",
      "Processing External: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spectrogram image generation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **3. Visualizing Spectrogram Distribution Across Classes**\n",
    "\n",
    "This section analyzes the dataset by counting the number of spectrogram images in each class â€” \"present\" and \"absent\" â€” and visualizes the distribution using a bar chart.\n",
    "\n",
    "    Steps performed:\n",
    "    - Counts `.png` spectrogram files in each class directory.\n",
    "    - Stores and prints the counts.\n",
    "    - Plots a bar graph to visualize class balance.\n",
    "    - Adds numeric labels on top of each bar for clarity.\n",
    "\n",
    "This helps assess whether the dataset is balanced, which is crucial for model performance in classification tasks.\n"
   ],
   "metadata": {
    "id": "rP6wdcRe4X2g"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Spectrogram image path\n",
    "spectrogram_path = \"./content/beehive_audio/7/Dataset/Spectograms\"\n",
    "\n",
    "# Define class folders\n",
    "class_folders = ['present', 'absent']\n",
    "counts = []\n",
    "\n",
    "# Count PNG files in each folder\n",
    "for label in class_folders:\n",
    "    class_path = os.path.join(spectrogram_path, label)\n",
    "    count = len([f for f in os.listdir(class_path) if f.endswith('.png')])\n",
    "    counts.append(count)\n",
    "    print(f\"{label}: {count} spectrograms\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = plt.bar(class_folders, counts, color=['darkorange', 'skyblue'], edgecolor='black')\n",
    "plt.ylim(0,4400)\n",
    "plt.title(\"Number of Spectrogram PNGs per Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Add count labels on top\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval+yval ** 0.5, str(yval), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-13T09:06:13.263923Z",
     "iopub.execute_input": "2025-06-13T09:06:13.26425Z",
     "iopub.status.idle": "2025-06-13T09:06:13.417494Z",
     "shell.execute_reply.started": "2025-06-13T09:06:13.264227Z",
     "shell.execute_reply": "2025-06-13T09:06:13.416775Z"
    },
    "trusted": true,
    "id": "XHS1jgjY4X2g",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c6e218d6-c415-4949-ca4f-c5adccd50885",
    "ExecuteTime": {
     "end_time": "2025-12-21T07:07:52.959894Z",
     "start_time": "2025-12-21T07:07:52.771815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "present: 4000 spectrograms\n",
      "absent: 4000 spectrograms\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **4. Preparing Data Loaders: Train, Validation, and Test Splits**\n",
    "\n",
    "This section prepares the spectrogram dataset for training a CNN using TensorFlow's `ImageDataGenerator`.\n",
    "\n",
    "- **Base Directory**: Points to the location of spectrogram images organized by class.\n",
    "- **Image Preprocessing**: Rescales pixel values to the [0, 1] range.\n",
    "- **Splitting Strategy**:\n",
    "  - **70%** of the data is used for training.\n",
    "  - The remaining **30%** is further split evenly into **15% validation** and **15% testing**.\n",
    "- **Generators Created**:\n",
    "  - `train_gen` for training the model.\n",
    "  - `val_gen` for tuning hyperparameters and monitoring overfitting.\n",
    "  - `test_gen` for final performance evaluation.\n",
    "\n",
    "This setup ensures consistent and reproducible splits with a fixed seed.\n"
   ],
   "metadata": {
    "id": "ba-hdTP_4X2i"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Base directory\n",
    "data_dir = \"./content/beehive_audio/7/Dataset/Spectograms\"\n",
    "# Params\n",
    "IMG_SIZE = (128, 128)\n",
    "BASE_BATCH_SIZE = 32\n",
    "BATCH_SIZE = BASE_BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "print(f\"Batch size per replica: {BASE_BATCH_SIZE}, global batch size: {BATCH_SIZE}\")\n",
    "SEED = 42\n",
    "# ðŸ’¾ Data split: 70% train, 15% val, 15% test\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.30)\n",
    "# 70% Train\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    seed=SEED\n",
    ")\n",
    "# Split remaining 30% into 15% val + 15% test\n",
    "datagen_val_test = ImageDataGenerator(rescale=1./255, validation_split=0.5)\n",
    "val_gen = datagen_val_test.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    seed=SEED\n",
    ")\n",
    "test_gen = datagen_val_test.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    seed=SEED,\n",
    "    shuffle=False\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-11T16:49:28.20264Z",
     "iopub.execute_input": "2025-06-11T16:49:28.202944Z",
     "iopub.status.idle": "2025-06-11T16:49:29.67822Z",
     "shell.execute_reply.started": "2025-06-11T16:49:28.202921Z",
     "shell.execute_reply": "2025-06-11T16:49:29.677456Z"
    },
    "trusted": true,
    "id": "kXXpQ7qQ4X2l",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f26776ad-920d-4249-bb3c-1c8c28d46e78",
    "ExecuteTime": {
     "end_time": "2025-12-21T07:08:00.046490Z",
     "start_time": "2025-12-21T07:07:58.822416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7000 images belonging to 3 classes.\n",
      "Found 5000 images belonging to 3 classes.\n",
      "Found 5000 images belonging to 3 classes.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "Dataset = './content/beehive_audio/7/Dataset/Spectograms'\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "gen = datagen.flow_from_directory(Dataset, class_mode='sparse')\n",
    "print(gen.class_indices)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-11T16:49:46.367186Z",
     "iopub.execute_input": "2025-06-11T16:49:46.367713Z",
     "iopub.status.idle": "2025-06-11T16:49:47.683966Z",
     "shell.execute_reply.started": "2025-06-11T16:49:46.367687Z",
     "shell.execute_reply": "2025-06-11T16:49:47.683433Z"
    },
    "id": "NVmqrZGw4X2l",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "879e2a4d-687f-4cca-cb1e-eec0820305fe",
    "ExecuteTime": {
     "end_time": "2025-12-21T07:08:06.467066Z",
     "start_time": "2025-12-21T07:08:05.810980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 3 classes.\n",
      "{'absent': 0, 'external': 1, 'present': 2}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "print(train_gen.class_indices)\n",
    "print(val_gen.class_indices)\n",
    "print(test_gen.class_indices)"
   ],
   "metadata": {
    "id": "7qp5myn2DBZe",
    "outputId": "d53d7520-52ef-411c-aa0f-ca074e980984",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-12-21T07:08:13.279879Z",
     "start_time": "2025-12-21T07:08:13.272688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'absent': 0, 'external': 1, 'present': 2}\n",
      "{'absent': 0, 'external': 1, 'present': 2}\n",
      "{'absent': 0, 'external': 1, 'present': 2}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, 3, activation='relu', padding='same',\n",
    "                      input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "\n",
    "        # MUST be 3 units for 3 classes\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        # MUST be sparse categorical for integer labels 0/1/2\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# ðŸš€ Train ONCE\n",
    "with strategy.scope():\n",
    "    model = build_model()\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=6\n",
    ")\n"
   ],
   "metadata": {
    "id": "Vf5J4SHgEFxi",
    "outputId": "466bc100-97a7-45de-a059-4dcbd4d8d40f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-12-21T05:35:56.242067Z",
     "start_time": "2025-12-21T04:55:21.223546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001B[1m219/219\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m475s\u001B[0m 2s/step - accuracy: 0.7130 - loss: 0.6063 - val_accuracy: 0.4000 - val_loss: 3.4967\n",
      "Epoch 2/6\n",
      "\u001B[1m219/219\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m432s\u001B[0m 2s/step - accuracy: 0.7633 - loss: 0.4105 - val_accuracy: 0.5064 - val_loss: 2.1012\n",
      "Epoch 3/6\n",
      "\u001B[1m219/219\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m387s\u001B[0m 2s/step - accuracy: 0.7833 - loss: 0.3804 - val_accuracy: 0.6862 - val_loss: 1.2527\n",
      "Epoch 4/6\n",
      "\u001B[1m219/219\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m386s\u001B[0m 2s/step - accuracy: 0.7819 - loss: 0.3663 - val_accuracy: 0.4750 - val_loss: 1.0616\n",
      "Epoch 5/6\n",
      "\u001B[1m219/219\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m377s\u001B[0m 2s/step - accuracy: 0.7881 - loss: 0.3518 - val_accuracy: 0.7932 - val_loss: 0.4019\n",
      "Epoch 6/6\n",
      "\u001B[1m219/219\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m376s\u001B[0m 2s/step - accuracy: 0.7921 - loss: 0.3456 - val_accuracy: 0.4402 - val_loss: 1.6748\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_model(hp):\n",
    "    with strategy.scope():\n",
    "        model = models.Sequential([\n",
    "        layers.Conv2D(\n",
    "            hp.Choice(\"conv1_filters\", [32, 64]),\n",
    "            3, padding=\"same\", activation=\"relu\",\n",
    "            input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(\n",
    "            hp.Choice(\"conv2_filters\", [64, 128]),\n",
    "            3, padding=\"same\", activation=\"relu\"\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(\n",
    "            hp.Choice(\"conv3_filters\", [128, 256]),\n",
    "            3, padding=\"same\", activation=\"relu\"\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "\n",
    "        layers.Dense(\n",
    "            hp.Int(\"dense_units\", min_value=64, max_value=128, step=32),\n",
    "            activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(hp.Float(\"dropout\", 0.3, 0.6, step=0.1)),\n",
    "\n",
    "        layers.Dense(3, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    lr = hp.Choice(\"lr\", [1e-3, 5e-4, 1e-4])\n",
    "    optimizer = optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=1,          # keep small\n",
    "    overwrite=True,\n",
    "    directory=\"queenbee_tuner\",\n",
    "    project_name=\"cnn_multiclass\"\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=5,              # IMPORTANT: small\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-11T16:50:25.433361Z",
     "iopub.execute_input": "2025-06-11T16:50:25.434115Z",
     "iopub.status.idle": "2025-06-11T17:14:29.442443Z",
     "shell.execute_reply.started": "2025-06-11T16:50:25.434082Z",
     "shell.execute_reply": "2025-06-11T17:14:29.441838Z"
    },
    "id": "C0xnUUSF4X2m",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e834ec2f-2281-4095-f9b1-ad9632649c16"
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 49m 41s]\n",
      "val_accuracy: 0.6620000004768372\n",
      "\n",
      "Best val_accuracy So Far: 0.6620000004768372\n",
      "Total elapsed time: 00h 49m 41s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Re-load best model from tuner\n",
    "with strategy.scope():\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Combine train + val correctly (3 classes)\n",
    "datagen_full = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.15\n",
    ")\n",
    "\n",
    "final_train_gen = datagen_full.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',      # MUST be sparse, NOT binary\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "final_val_gen = datagen_full.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',      # MUST be sparse\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Final training (short, controlled)\n",
    "history = best_model.fit(\n",
    "    final_train_gen,\n",
    "    validation_data=final_val_gen,\n",
    "    epochs=5   # keep short, model already tuned\n",
    ")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-11T17:14:50.993682Z",
     "iopub.execute_input": "2025-06-11T17:14:50.994177Z",
     "iopub.status.idle": "2025-06-11T17:18:57.414155Z",
     "shell.execute_reply.started": "2025-06-11T17:14:50.994152Z",
     "shell.execute_reply": "2025-06-11T17:18:57.413551Z"
    },
    "trusted": true,
    "id": "i1IZG9fn4X2p",
    "ExecuteTime": {
     "end_time": "2025-12-21T09:23:58.975279Z",
     "start_time": "2025-12-21T09:23:57.986353Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strategy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ImageDataGenerator\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Re-load best model from tuner\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mstrategy\u001B[49m\u001B[38;5;241m.\u001B[39mscope():\n\u001B[1;32m      5\u001B[0m     best_model \u001B[38;5;241m=\u001B[39m tuner\u001B[38;5;241m.\u001B[39mget_best_models(num_models\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Combine train + val correctly (3 classes)\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'strategy' is not defined"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the fine-tuned model\n",
    "best_model.save(\"./content/beehive_audio/7/Dataset/queenbee_final_tuned_model.h5\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-11T17:19:05.452212Z",
     "iopub.execute_input": "2025-06-11T17:19:05.452494Z",
     "iopub.status.idle": "2025-06-11T17:19:05.759479Z",
     "shell.execute_reply.started": "2025-06-11T17:19:05.452475Z",
     "shell.execute_reply": "2025-06-11T17:19:05.758941Z"
    },
    "trusted": true,
    "id": "LqTpWxQ-4X2r",
    "ExecuteTime": {
     "end_time": "2025-12-21T07:01:09.508571Z",
     "start_time": "2025-12-21T07:01:09.212425Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "source": [
    "#load the fine-tuned model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"./content/beehive_audio/7/Dataset/queenbee_final_tuned_model.h5\") # change the path if you are using your own trained model\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-13T09:07:25.980045Z",
     "iopub.execute_input": "2025-06-13T09:07:25.980669Z",
     "iopub.status.idle": "2025-06-13T09:07:26.385779Z",
     "shell.execute_reply.started": "2025-06-13T09:07:25.980645Z",
     "shell.execute_reply": "2025-06-13T09:07:26.385049Z"
    },
    "trusted": true,
    "id": "UeddtSHb4X2r",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "19764275-cf76-4324-ba3c-983cd4105968",
    "ExecuteTime": {
     "end_time": "2025-12-21T11:11:35.948399Z",
     "start_time": "2025-12-21T11:11:35.570569Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **5.** **Evaluate Metrics**\n",
    "\n",
    "* Accuracy, Precision, Recall, F1, ROC AUC  \n",
    "* Confusion Matrix  \n",
    "* ROC & PR Curves  \n",
    "* Test Set Performance Summary"
   ],
   "metadata": {
    "id": "4AcyjPg44X2r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def run_inference(model, test_gen):\n",
    "    \"\"\"\n",
    "    Runs inference on a multiclass (softmax) model.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): Trained Keras multiclass model.\n",
    "        test_gen (ImageDataGenerator): Test data generator (shuffle=False).\n",
    "\n",
    "    Returns:\n",
    "        y_pred (np.ndarray): Predicted class indices (0, 1, 2).\n",
    "        y_prob (np.ndarray): Predicted class probabilities, shape (N, 3).\n",
    "        y_true (np.ndarray): Ground truth class labels.\n",
    "    \"\"\"\n",
    "    test_gen.reset()\n",
    "\n",
    "    # Predict probabilities: shape (N, 3)\n",
    "    y_prob = model.predict(test_gen, verbose=1)\n",
    "\n",
    "    # Convert probabilities â†’ class labels\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "    # Ground truth\n",
    "    y_true = test_gen.classes\n",
    "\n",
    "    return y_pred, y_prob, y_true\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-13T09:07:35.421869Z",
     "iopub.execute_input": "2025-06-13T09:07:35.422475Z",
     "iopub.status.idle": "2025-06-13T09:07:35.426977Z",
     "shell.execute_reply.started": "2025-06-13T09:07:35.422452Z",
     "shell.execute_reply": "2025-06-13T09:07:35.426179Z"
    },
    "id": "_ieP3tZk4X2r",
    "ExecuteTime": {
     "end_time": "2025-12-21T11:11:40.625991Z",
     "start_time": "2025-12-21T11:11:40.582919Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# ----------------------------\n",
    "# Inference (already validated)\n",
    "# ----------------------------\n",
    "y_pred, y_prob, y_true = run_inference(best_model, test_gen)\n",
    "class_names = list(test_gen.class_indices.keys())\n",
    "\n",
    "# ----------------------------\n",
    "# Summary metrics table\n",
    "# ----------------------------\n",
    "metrics_table = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Macro Precision\", \"Macro Recall\", \"Macro F1\"],\n",
    "    \"Score\": [\n",
    "        accuracy_score(y_true, y_pred),\n",
    "        precision_score(y_true, y_pred, average=\"macro\"),\n",
    "        recall_score(y_true, y_pred, average=\"macro\"),\n",
    "        f1_score(y_true, y_pred, average=\"macro\")\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(metrics_table.style.format({\"Score\": \"{:.4f}\"}))\n",
    "\n",
    "# ----------------------------\n",
    "# Classification report table\n",
    "# ----------------------------\n",
    "report_dict = classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=class_names,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "report_df = (\n",
    "    pd.DataFrame(report_dict)\n",
    "    .transpose()\n",
    "    .iloc[:-3]  # drop accuracy / avg rows for plotting\n",
    ")\n",
    "\n",
    "display(report_df.style.format(\"{:.2f}\"))\n",
    "\n",
    "# ----------------------------\n",
    "# Confusion Matrix (Heatmap)\n",
    "# ----------------------------\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names\n",
    ")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# Per-class metric bar plot\n",
    "# ----------------------------\n",
    "metric_cols = [\"precision\", \"recall\", \"f1-score\"]\n",
    "plot_df = report_df[metric_cols].reset_index().rename(columns={\"index\": \"Class\"})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_df_melted = plot_df.melt(\n",
    "    id_vars=\"Class\",\n",
    "    var_name=\"Metric\",\n",
    "    value_name=\"Score\"\n",
    ")\n",
    "\n",
    "sns.barplot(\n",
    "    data=plot_df_melted,\n",
    "    x=\"Class\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Metric\"\n",
    ")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Per-Class Precision / Recall / F1\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# Prediction distribution\n",
    "# ----------------------------\n",
    "pred_counts = pd.Series(y_pred).value_counts().sort_index()\n",
    "true_counts = pd.Series(y_true).value_counts().sort_index()\n",
    "\n",
    "dist_df = pd.DataFrame({\n",
    "    \"True\": true_counts,\n",
    "    \"Predicted\": pred_counts\n",
    "}, index=class_names)\n",
    "\n",
    "dist_df.plot(\n",
    "    kind=\"bar\",\n",
    "    figsize=(8, 5),\n",
    "    rot=0\n",
    ")\n",
    "plt.title(\"True vs Predicted Class Distribution\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-13T09:07:43.538517Z",
     "iopub.execute_input": "2025-06-13T09:07:43.539159Z",
     "iopub.status.idle": "2025-06-13T09:07:44.001096Z",
     "shell.execute_reply.started": "2025-06-13T09:07:43.539137Z",
     "shell.execute_reply": "2025-06-13T09:07:44.000096Z"
    },
    "id": "sgweG7Ww4X2s",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "outputId": "f676106e-d121-4d6b-ddbc-beffd4e66ebd",
    "ExecuteTime": {
     "end_time": "2025-12-21T11:13:46.460748Z",
     "start_time": "2025-12-21T11:11:43.373792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m122s\u001B[0m 770ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x719d76f23550>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b078b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b078b_level0_col0\" class=\"col_heading level0 col0\" >Metric</th>\n",
       "      <th id=\"T_b078b_level0_col1\" class=\"col_heading level0 col1\" >Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b078b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b078b_row0_col0\" class=\"data row0 col0\" >Accuracy</td>\n",
       "      <td id=\"T_b078b_row0_col1\" class=\"data row0 col1\" >0.7810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b078b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b078b_row1_col0\" class=\"data row1 col0\" >Macro Precision</td>\n",
       "      <td id=\"T_b078b_row1_col1\" class=\"data row1 col1\" >0.8777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b078b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b078b_row2_col0\" class=\"data row2 col0\" >Macro Recall</td>\n",
       "      <td id=\"T_b078b_row2_col1\" class=\"data row2 col1\" >0.6583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b078b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b078b_row3_col0\" class=\"data row3 col0\" >Macro F1</td>\n",
       "      <td id=\"T_b078b_row3_col1\" class=\"data row3 col1\" >0.6110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x719d76f23520>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8817f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8817f_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_8817f_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_8817f_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_8817f_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8817f_level0_row0\" class=\"row_heading level0 row0\" >absent</th>\n",
       "      <td id=\"T_8817f_row0_col0\" class=\"data row0 col0\" >0.65</td>\n",
       "      <td id=\"T_8817f_row0_col1\" class=\"data row0 col1\" >0.98</td>\n",
       "      <td id=\"T_8817f_row0_col2\" class=\"data row0 col2\" >0.78</td>\n",
       "      <td id=\"T_8817f_row0_col3\" class=\"data row0 col3\" >2000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8817f_level0_row1\" class=\"row_heading level0 row1\" >external</th>\n",
       "      <td id=\"T_8817f_row1_col0\" class=\"data row1 col0\" >1.00</td>\n",
       "      <td id=\"T_8817f_row1_col1\" class=\"data row1 col1\" >0.04</td>\n",
       "      <td id=\"T_8817f_row1_col2\" class=\"data row1 col2\" >0.09</td>\n",
       "      <td id=\"T_8817f_row1_col3\" class=\"data row1 col3\" >1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8817f_level0_row2\" class=\"row_heading level0 row2\" >present</th>\n",
       "      <td id=\"T_8817f_row2_col0\" class=\"data row2 col0\" >0.98</td>\n",
       "      <td id=\"T_8817f_row2_col1\" class=\"data row2 col1\" >0.95</td>\n",
       "      <td id=\"T_8817f_row2_col2\" class=\"data row2 col2\" >0.96</td>\n",
       "      <td id=\"T_8817f_row2_col3\" class=\"data row2 col3\" >2000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "ydb46-GL8Nh5"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Added average declarations for multiclass **targetting**",
   "metadata": {
    "id": "6-pSxVIp8EWF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "\n",
    "y_pred, y_prob, y_true = run_inference(model, test_gen)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "prec = precision_score(y_true, y_pred, average=\"macro\")\n",
    "rec  = recall_score(y_true, y_pred, average=\"macro\")\n",
    "f1   = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "# ROC / PR only make sense for binary scores\n",
    "roc_auc = roc_auc_score(y_true == 1, y_prob)\n",
    "pr_auc  = average_precision_score(y_true == 1, y_prob)\n",
    "\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"AU-ROC:    {roc_auc:.4f}\")\n",
    "print(f\"AU-PRC:    {pr_auc:.4f}\")"
   ],
   "metadata": {
    "id": "6gkMKtFm7_oN",
    "outputId": "e0ecac94-5099-4610-f34b-628bbf12fd3d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-12-21T04:47:46.898191Z",
     "start_time": "2025-12-20T22:16:20.125345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m90s\u001B[0m 569ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multi_class must be in ('ovo', 'ovr')",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 15\u001B[0m\n\u001B[1;32m     12\u001B[0m f1   \u001B[38;5;241m=\u001B[39m f1_score(y_true, y_pred, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmacro\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# ROC / PR only make sense for binary scores\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m roc_auc \u001B[38;5;241m=\u001B[39m \u001B[43mroc_auc_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_prob\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m pr_auc  \u001B[38;5;241m=\u001B[39m average_precision_score(y_true \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m, y_prob)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy:  \u001B[39m\u001B[38;5;132;01m{\u001B[39;00macc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:218\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    213\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    214\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    215\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    216\u001B[0m         )\n\u001B[1;32m    217\u001B[0m     ):\n\u001B[0;32m--> 218\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    221\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    223\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    224\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    225\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    226\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    227\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    228\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:679\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[1;32m    672\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    673\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPartial AUC computation not available in \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    674\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass setting, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_fpr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    675\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m set to `None`, received `max_fpr=\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    676\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minstead\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(max_fpr)\n\u001B[1;32m    677\u001B[0m         )\n\u001B[1;32m    678\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m multi_class \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 679\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulti_class must be in (\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124movo\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124movr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    680\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _multiclass_roc_auc_score(\n\u001B[1;32m    681\u001B[0m         y_true, y_score, labels, multi_class, average, sample_weight\n\u001B[1;32m    682\u001B[0m     )\n\u001B[1;32m    683\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mValueError\u001B[0m: multi_class must be in ('ovo', 'ovr')"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m106/157\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”\u001B[0m \u001B[1m41s\u001B[0m 821ms/step"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      2\u001B[0m     accuracy_score, precision_score, recall_score, f1_score,\n\u001B[1;32m      3\u001B[0m     roc_auc_score, average_precision_score\n\u001B[1;32m      4\u001B[0m )\n\u001B[0;32m----> 6\u001B[0m y_pred, y_prob, y_true \u001B[38;5;241m=\u001B[39m \u001B[43mrun_inference\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_gen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m acc \u001B[38;5;241m=\u001B[39m accuracy_score(y_true, y_pred)\n\u001B[1;32m     10\u001B[0m prec \u001B[38;5;241m=\u001B[39m precision_score(y_true, y_pred, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmacro\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[28], line 19\u001B[0m, in \u001B[0;36mrun_inference\u001B[0;34m(model, test_gen)\u001B[0m\n\u001B[1;32m     16\u001B[0m test_gen\u001B[38;5;241m.\u001B[39mreset()\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Predict probabilities: shape (N, 3)\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m y_prob \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_gen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Convert probabilities â†’ class labels\u001B[39;00m\n\u001B[1;32m     22\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(y_prob, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:588\u001B[0m, in \u001B[0;36mTensorFlowTrainer.predict\u001B[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001B[0m\n\u001B[1;32m    586\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_predict_batch_begin(begin_step)\n\u001B[1;32m    587\u001B[0m data \u001B[38;5;241m=\u001B[39m get_data(iterator)\n\u001B[0;32m--> 588\u001B[0m batch_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m outputs \u001B[38;5;241m=\u001B[39m append_to_outputs(batch_outputs, outputs)\n\u001B[1;32m    590\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_predict_batch_end(\n\u001B[1;32m    591\u001B[0m     end_step, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: batch_outputs}\n\u001B[1;32m    592\u001B[0m )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n\u001B[1;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1688\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1686\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1687\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1688\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1689\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1690\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1691\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1692\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1693\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1694\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1695\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1696\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1697\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1698\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1702\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1703\u001B[0m   )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Assumes these already exist and are CORRECT:\n",
    "# y_true : shape (N,)\n",
    "# y_pred : shape (N,)\n",
    "# y_prob : shape (N, 3)\n",
    "# test_gen, best_model\n",
    "# -------------------------------------------------\n",
    "\n",
    "class_names = list(test_gen.class_indices.keys())\n",
    "n_classes = len(class_names)\n",
    "\n",
    "# =================================================\n",
    "# 1. Confusion Matrix\n",
    "# =================================================\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =================================================\n",
    "# 2. ROC Curves (One-vs-Rest)\n",
    "# =================================================\n",
    "y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        label=f\"{class_name} (AUC = {roc_auc:.2f})\"\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", alpha=0.6)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves (One-vs-Rest)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =================================================\n",
    "# 3. Precisionâ€“Recall Curves (One-vs-Rest)\n",
    "# =================================================\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    precision, recall, _ = precision_recall_curve(\n",
    "        y_true_bin[:, i], y_prob[:, i]\n",
    "    )\n",
    "    ap = average_precision_score(\n",
    "        y_true_bin[:, i], y_prob[:, i]\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        recall,\n",
    "        precision,\n",
    "        label=f\"{class_name} (AP = {ap:.2f})\"\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precisionâ€“Recall Curves (One-vs-Rest)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =================================================\n",
    "# 4. Probability Distributions (Per Class)\n",
    "# =================================================\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    sns.kdeplot(\n",
    "        y_prob[y_true == i, i],\n",
    "        label=class_name,\n",
    "        fill=True,\n",
    "        alpha=0.4\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Predicted Probability (True Class)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Predicted Probability Distributions by Class\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-13T09:08:02.363495Z",
     "iopub.execute_input": "2025-06-13T09:08:02.364359Z",
     "iopub.status.idle": "2025-06-13T09:08:02.382588Z",
     "shell.execute_reply.started": "2025-06-13T09:08:02.364329Z",
     "shell.execute_reply": "2025-06-13T09:08:02.381598Z"
    },
    "id": "FCovrxY24X2s",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "outputId": "d6cfb978-6167-4c9e-8eb7-692ac8495908",
    "ExecuteTime": {
     "end_time": "2025-12-21T04:50:40.696795Z",
     "start_time": "2025-12-21T04:50:39.648049Z"
    }
   },
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "source": [
    "print(classification_report(y_true, y_pred, target_names=list(test_gen.class_indices.keys())))\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-11T17:26:58.257988Z",
     "iopub.execute_input": "2025-06-11T17:26:58.258287Z",
     "iopub.status.idle": "2025-06-11T17:26:58.269745Z",
     "shell.execute_reply.started": "2025-06-11T17:26:58.25827Z",
     "shell.execute_reply": "2025-06-11T17:26:58.269174Z"
    },
    "id": "ceZF-KLA4X2u",
    "ExecuteTime": {
     "end_time": "2025-12-21T04:50:43.978877Z",
     "start_time": "2025-12-21T04:50:43.944552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.11      0.00      0.00      2000\n",
      "    external       0.20      0.98      0.33      1000\n",
      "     present       0.00      0.00      0.00      2000\n",
      "\n",
      "    accuracy                           0.20      5000\n",
      "   macro avg       0.10      0.33      0.11      5000\n",
      "weighted avg       0.08      0.20      0.07      5000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Evaluation Commentary\n",
    "The model demonstrates excellent performance with an **overall accuracy of 99%**. Both classes â€” \"absent\" and \"present\" â€” have near-perfect **precision, recall, and F1-scores (0.99)**, indicating:\n",
    "\n",
    "**High precision**: Very few false positives.\n",
    "\n",
    "**High recall**: Nearly all relevant instances were correctly identified.\n",
    "\n",
    "**Balanced performance**: Consistent metrics across both classes, confirmed by the macro and weighted averages."
   ],
   "metadata": {
    "id": "iyNwUsUZ4X2u"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **6. Prediction and Audio Feature Visualization**\n",
    "### ðŸ“Œ Objective:\n",
    "Visualize key audio features from a sound signal to better understand the characteristics of the data.\n",
    "\n",
    "#### Features Plotted:\n",
    "    - Raw audio waveform\n",
    "    - Mel-spectrogram input to CNN\n",
    "    - Model prediction probabilities (Queen Present/Absent)\n",
    "    - Audio statistics (duration, RMS energy, zero-crossing rate, etc.)"
   ],
   "metadata": {
    "id": "RiYBolAH4X2u"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def visualize_audio_prediction(audio_path, model):\n",
    "    \"\"\"\n",
    "    Create essential visualizations for audio CNN prediction\n",
    "    \"\"\"\n",
    "    # Load audio\n",
    "    y, sr = librosa.load(audio_path, sr=SR)\n",
    "\n",
    "    # Create mel-spectrogram\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Get model input (spectrogram image)\n",
    "    input_data = audio_to_spectrogram_image(audio_path, model)\n",
    "\n",
    "    # Get prediction\n",
    "    prediction = model.predict(input_data)\n",
    "    queen_prob = float(prediction[0][0])\n",
    "    label = \"Queen Present\" if queen_prob >= 0.5 else \"Queen Absent\"\n",
    "    confidence = queen_prob if queen_prob >= 0.5 else (1 - queen_prob)\n",
    "\n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'Audio Analysis: {audio_path.split(\"/\")[-1]}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # 1. Raw Waveform\n",
    "    axes[0, 0].plot(np.linspace(0, len(y)/sr, len(y)), y, color='blue', alpha=0.7)\n",
    "    axes[0, 0].set_title('Raw Audio Waveform', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Time (seconds)')\n",
    "    axes[0, 0].set_ylabel('Amplitude')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. Mel-Spectrogram (what CNN sees)\n",
    "    im = axes[0, 1].imshow(S_dB, aspect='auto', origin='lower', cmap='magma')\n",
    "    axes[0, 1].set_title('Mel-Spectrogram (CNN Input)', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Time Frames')\n",
    "    axes[0, 1].set_ylabel('Mel Frequency Bins')\n",
    "    plt.colorbar(im, ax=axes[0, 1], label='Power (dB)')\n",
    "\n",
    "    # 3. Prediction Results\n",
    "    categories = ['Queen Absent', 'Queen Present']\n",
    "    probabilities = [1 - queen_prob, queen_prob]\n",
    "    colors = ['red' if p == max(probabilities) else 'lightcoral' for p in probabilities]\n",
    "\n",
    "    bars = axes[1, 0].bar(categories, probabilities, color=colors, alpha=0.8, edgecolor='black')\n",
    "    axes[1, 0].set_title('Model Predictions', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Probability')\n",
    "    axes[1, 0].set_ylim(0, 1)\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Add probability labels on bars\n",
    "    for bar, prob in zip(bars, probabilities):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                       f'{prob:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    # 4. Audio Statistics\n",
    "    axes[1, 1].axis('off')\n",
    "    duration = len(y) / sr\n",
    "    max_amplitude = np.max(np.abs(y))\n",
    "    rms_energy = np.sqrt(np.mean(y**2))\n",
    "    zero_crossings = np.sum(np.diff(np.sign(y)) != 0) / len(y)\n",
    "\n",
    "    stats_text = f\"\"\"\n",
    "    Audio Statistics:\n",
    "\n",
    "    Duration: {duration:.2f} seconds\n",
    "    Sample Rate: {sr} Hz\n",
    "    Max Amplitude: {max_amplitude:.4f}\n",
    "    RMS Energy: {rms_energy:.4f}\n",
    "    Zero Crossing Rate: {zero_crossings:.4f}\n",
    "\n",
    "    Prediction Results:\n",
    "\n",
    "    Final Prediction: {label}\n",
    "    Confidence: {confidence*100:.2f}%\n",
    "\n",
    "    Queen Present Prob: {queen_prob:.3f}\n",
    "    Queen Absent Prob: {1-queen_prob:.3f}\n",
    "    \"\"\"\n",
    "\n",
    "    axes[1, 1].text(0.1, 0.9, stats_text, transform=axes[1, 1].transAxes,\n",
    "                   fontsize=12, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.8))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'prediction': label,\n",
    "        'confidence': confidence,\n",
    "        'queen_probability': queen_prob,\n",
    "        'duration': duration,\n",
    "        'audio_stats': {\n",
    "            'max_amplitude': max_amplitude,\n",
    "            'rms_energy': rms_energy,\n",
    "            'zero_crossing_rate': zero_crossings\n",
    "        }\n",
    "    }"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-13T09:08:24.204762Z",
     "iopub.execute_input": "2025-06-13T09:08:24.205048Z",
     "iopub.status.idle": "2025-06-13T09:08:24.217774Z",
     "shell.execute_reply.started": "2025-06-13T09:08:24.205028Z",
     "shell.execute_reply": "2025-06-13T09:08:24.21708Z"
    },
    "id": "qqwFwaGb4X2v"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# --- Parameters (must match training setup) ---\n",
    "IMG_SIZE = (128, 128)  # your model's input size\n",
    "SR = 22050  # sampling rate used during training\n",
    "\n",
    "# --- Function to process a .wav file into spectrogram image ---\n",
    "def audio_to_spectrogram_image(audio_path,model=None):\n",
    "    y, sr = librosa.load(audio_path, sr=SR)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Plot to image in memory\n",
    "    fig = plt.figure(figsize=(2, 2), dpi=64)  # ~128x128\n",
    "    librosa.display.specshow(S_dB, sr=sr, cmap='magma')\n",
    "    plt.axis('off')\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "\n",
    "    # Load image and resize\n",
    "    img = Image.open(buf).convert('RGB').resize(IMG_SIZE)\n",
    "    img_array = np.array(img) / 255.0  # Normalize like training\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Shape: (1, 128, 128, 3)\n",
    "    return img_array\n",
    "\n",
    "# --- Predict ---\n",
    "audio_file_path = \"./content/beehive_audio/7/Dataset/Bee Hive Audios/QueenBee Absent/Hive1 31_05_2018_NO_QueenBee____00_00_00_chunk1.wav\"\n",
    "# run_inference(model,test_gen)\n",
    "input_data = audio_to_spectrogram_image(audio_file_path)\n",
    "\n",
    "results = visualize_audio_prediction(audio_file_path, model)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"PREDICTION SUMMARY\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"File: {audio_file_path.split('/')[-1]}\")\n",
    "print(f\"Prediction: {results['prediction']}\")\n",
    "print(f\"Confidence: {results['confidence']*100:.2f}%\")\n",
    "print(f\"Audio Duration: {results['duration']:.2f} seconds\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "audio_file_path = \"./content/beehive_audio/7/Dataset/Bee Hive Audios/QueenBee Present/Hive1 12_06_2018_QueenBee____00_00_00_chunk1.wav\"\n",
    "# run_inference(model,test_gen)\n",
    "input_data = audio_to_spectrogram_image(audio_file_path)\n",
    "\n",
    "results = visualize_audio_prediction(audio_file_path, model)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"PREDICTION SUMMARY\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"File: {audio_file_path.split('/')[-1]}\")\n",
    "print(f\"Prediction: {results['prediction']}\")\n",
    "print(f\"Confidence: {results['confidence']*100:.2f}%\")\n",
    "print(f\"Audio Duration: {results['duration']:.2f} seconds\")\n",
    "print(f\"{'='*50}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-13T09:09:02.726916Z",
     "iopub.execute_input": "2025-06-13T09:09:02.727504Z",
     "iopub.status.idle": "2025-06-13T09:09:23.914004Z",
     "shell.execute_reply.started": "2025-06-13T09:09:02.72748Z",
     "shell.execute_reply": "2025-06-13T09:09:23.913127Z"
    },
    "trusted": true,
    "id": "Y0a38Kbk4X2v",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cfb97630-e2f7-46d9-ebc1-a0e41dac5864"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "trusted": true,
    "id": "iS0mxpVg4X2w"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
